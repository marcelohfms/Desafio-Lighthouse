{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58cf901c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.utils import class_weight, resample\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0ee2400",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treino = pd.read_csv(\"desafio_manutencao_preditiva_treino.csv\")\n",
    "df_teste = pd.read_csv(\"desafio_manutencao_preditiva_teste.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33087837",
   "metadata": {},
   "source": [
    "## Divisão do dataset em treino e validação\n",
    "\n",
    "Como os dados de teste não possuem a variável target, é importante que separemos uma parte do dataset de treino para validar o modelo e garantir que não haja overfitting. Dividiremos então o dataset em treino e validação. Usaremos 25% dos dados para validação."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fef7cc",
   "metadata": {},
   "source": [
    "# Pré-Processamento dos Dados\n",
    "\n",
    "Muitos algoritmos preditivos esperam receber os dados padronizados e codificados. Portanto, é necessário transformar os dados para adequá-los aos modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce154ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separando as variáveis em ids, categóricas e numéricas\n",
    "ids = ['udi', 'product_id']\n",
    "categorical = ['type', 'failure_type']\n",
    "numerical = [col for col in df_treino.columns if col not in ids and col not in categorical]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65bef95",
   "metadata": {},
   "source": [
    "## Encoding das variáveis categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b763c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type            3\n",
       "failure_type    6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Número de classes das variáveis categóricas\n",
    "df_treino[categorical].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dfd070",
   "metadata": {},
   "source": [
    "A variável type possui apenas 3 classes, vamos aplicar a técnica de OneHotEncoding para sua codificação, já a variável target failure_type possui 6 classes distintas. Para que não ocorra um grande aumento de dimensionalidade, vamos aplicar LabelEncoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b5a0cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>udi</th>\n",
       "      <th>product_id</th>\n",
       "      <th>air_temperature_k</th>\n",
       "      <th>process_temperature_k</th>\n",
       "      <th>rotational_speed_rpm</th>\n",
       "      <th>torque_nm</th>\n",
       "      <th>tool_wear_min</th>\n",
       "      <th>failure_type</th>\n",
       "      <th>type_H</th>\n",
       "      <th>type_L</th>\n",
       "      <th>type_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>M14860</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1551</td>\n",
       "      <td>42.8</td>\n",
       "      <td>0</td>\n",
       "      <td>No Failure</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>L47181</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>46.3</td>\n",
       "      <td>3</td>\n",
       "      <td>No Failure</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>L47184</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9</td>\n",
       "      <td>No Failure</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>M14865</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1425</td>\n",
       "      <td>41.9</td>\n",
       "      <td>11</td>\n",
       "      <td>No Failure</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>L47186</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1558</td>\n",
       "      <td>42.4</td>\n",
       "      <td>14</td>\n",
       "      <td>No Failure</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6662</th>\n",
       "      <td>9995</td>\n",
       "      <td>L57174</td>\n",
       "      <td>298.8</td>\n",
       "      <td>308.3</td>\n",
       "      <td>1634</td>\n",
       "      <td>27.9</td>\n",
       "      <td>12</td>\n",
       "      <td>No Failure</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6663</th>\n",
       "      <td>9996</td>\n",
       "      <td>M24855</td>\n",
       "      <td>298.8</td>\n",
       "      <td>308.4</td>\n",
       "      <td>1604</td>\n",
       "      <td>29.5</td>\n",
       "      <td>14</td>\n",
       "      <td>No Failure</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6664</th>\n",
       "      <td>9997</td>\n",
       "      <td>H39410</td>\n",
       "      <td>298.9</td>\n",
       "      <td>308.4</td>\n",
       "      <td>1632</td>\n",
       "      <td>31.8</td>\n",
       "      <td>17</td>\n",
       "      <td>No Failure</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6665</th>\n",
       "      <td>9999</td>\n",
       "      <td>H39412</td>\n",
       "      <td>299.0</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>48.5</td>\n",
       "      <td>25</td>\n",
       "      <td>No Failure</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6666</th>\n",
       "      <td>10000</td>\n",
       "      <td>M24859</td>\n",
       "      <td>299.0</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1500</td>\n",
       "      <td>40.2</td>\n",
       "      <td>30</td>\n",
       "      <td>No Failure</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6667 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        udi product_id  air_temperature_k  process_temperature_k  \\\n",
       "0         1     M14860              298.1                  308.6   \n",
       "1         2     L47181              298.2                  308.7   \n",
       "2         5     L47184              298.2                  308.7   \n",
       "3         6     M14865              298.1                  308.6   \n",
       "4         7     L47186              298.1                  308.6   \n",
       "...     ...        ...                ...                    ...   \n",
       "6662   9995     L57174              298.8                  308.3   \n",
       "6663   9996     M24855              298.8                  308.4   \n",
       "6664   9997     H39410              298.9                  308.4   \n",
       "6665   9999     H39412              299.0                  308.7   \n",
       "6666  10000     M24859              299.0                  308.7   \n",
       "\n",
       "      rotational_speed_rpm  torque_nm  tool_wear_min failure_type  type_H  \\\n",
       "0                     1551       42.8              0   No Failure       0   \n",
       "1                     1408       46.3              3   No Failure       0   \n",
       "2                     1408       40.0              9   No Failure       0   \n",
       "3                     1425       41.9             11   No Failure       0   \n",
       "4                     1558       42.4             14   No Failure       0   \n",
       "...                    ...        ...            ...          ...     ...   \n",
       "6662                  1634       27.9             12   No Failure       0   \n",
       "6663                  1604       29.5             14   No Failure       0   \n",
       "6664                  1632       31.8             17   No Failure       1   \n",
       "6665                  1408       48.5             25   No Failure       1   \n",
       "6666                  1500       40.2             30   No Failure       0   \n",
       "\n",
       "      type_L  type_M  \n",
       "0          0       1  \n",
       "1          1       0  \n",
       "2          1       0  \n",
       "3          0       1  \n",
       "4          1       0  \n",
       "...      ...     ...  \n",
       "6662       1       0  \n",
       "6663       0       1  \n",
       "6664       0       0  \n",
       "6665       0       0  \n",
       "6666       0       1  \n",
       "\n",
       "[6667 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OneHotEncoding\n",
    "df_treino_enc = pd.get_dummies(df_treino, columns=['type'])\n",
    "df_treino_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "689eb4ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>udi</th>\n",
       "      <th>product_id</th>\n",
       "      <th>air_temperature_k</th>\n",
       "      <th>process_temperature_k</th>\n",
       "      <th>rotational_speed_rpm</th>\n",
       "      <th>torque_nm</th>\n",
       "      <th>tool_wear_min</th>\n",
       "      <th>failure_type</th>\n",
       "      <th>type_H</th>\n",
       "      <th>type_L</th>\n",
       "      <th>type_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>M14860</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1551</td>\n",
       "      <td>42.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>L47181</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>46.3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>L47184</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>M14865</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1425</td>\n",
       "      <td>41.9</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>L47186</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1558</td>\n",
       "      <td>42.4</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6662</th>\n",
       "      <td>9995</td>\n",
       "      <td>L57174</td>\n",
       "      <td>298.8</td>\n",
       "      <td>308.3</td>\n",
       "      <td>1634</td>\n",
       "      <td>27.9</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6663</th>\n",
       "      <td>9996</td>\n",
       "      <td>M24855</td>\n",
       "      <td>298.8</td>\n",
       "      <td>308.4</td>\n",
       "      <td>1604</td>\n",
       "      <td>29.5</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6664</th>\n",
       "      <td>9997</td>\n",
       "      <td>H39410</td>\n",
       "      <td>298.9</td>\n",
       "      <td>308.4</td>\n",
       "      <td>1632</td>\n",
       "      <td>31.8</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6665</th>\n",
       "      <td>9999</td>\n",
       "      <td>H39412</td>\n",
       "      <td>299.0</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>48.5</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6666</th>\n",
       "      <td>10000</td>\n",
       "      <td>M24859</td>\n",
       "      <td>299.0</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1500</td>\n",
       "      <td>40.2</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6667 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        udi product_id  air_temperature_k  process_temperature_k  \\\n",
       "0         1     M14860              298.1                  308.6   \n",
       "1         2     L47181              298.2                  308.7   \n",
       "2         5     L47184              298.2                  308.7   \n",
       "3         6     M14865              298.1                  308.6   \n",
       "4         7     L47186              298.1                  308.6   \n",
       "...     ...        ...                ...                    ...   \n",
       "6662   9995     L57174              298.8                  308.3   \n",
       "6663   9996     M24855              298.8                  308.4   \n",
       "6664   9997     H39410              298.9                  308.4   \n",
       "6665   9999     H39412              299.0                  308.7   \n",
       "6666  10000     M24859              299.0                  308.7   \n",
       "\n",
       "      rotational_speed_rpm  torque_nm  tool_wear_min  failure_type  type_H  \\\n",
       "0                     1551       42.8              0             1       0   \n",
       "1                     1408       46.3              3             1       0   \n",
       "2                     1408       40.0              9             1       0   \n",
       "3                     1425       41.9             11             1       0   \n",
       "4                     1558       42.4             14             1       0   \n",
       "...                    ...        ...            ...           ...     ...   \n",
       "6662                  1634       27.9             12             1       0   \n",
       "6663                  1604       29.5             14             1       0   \n",
       "6664                  1632       31.8             17             1       1   \n",
       "6665                  1408       48.5             25             1       1   \n",
       "6666                  1500       40.2             30             1       0   \n",
       "\n",
       "      type_L  type_M  \n",
       "0          0       1  \n",
       "1          1       0  \n",
       "2          1       0  \n",
       "3          0       1  \n",
       "4          1       0  \n",
       "...      ...     ...  \n",
       "6662       1       0  \n",
       "6663       0       1  \n",
       "6664       0       0  \n",
       "6665       0       0  \n",
       "6666       0       1  \n",
       "\n",
       "[6667 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label Encoding\n",
    "le = LabelEncoder()\n",
    "df_treino_enc['failure_type'] = le.fit_transform(df_treino_enc['failure_type'])\n",
    "df_treino_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e669d6fc",
   "metadata": {},
   "source": [
    "## Padronização e normalização das variáveis numéricas\n",
    "\n",
    "Os dados podem ser padronizados ou normalizados. A padronização consiste em deixá-los numa distribuição normal com média 0 e desvio padrão 1. Já a normalização trata de deixar os dados numa escala única, geralmente de 0 a 1 ou de -1 a 1. \n",
    "\n",
    "Para os dados cuja distribuição não é gaussiana (ou normal), a normalização geralmente é uma melhor opção.\n",
    "\n",
    "Para os dados nesse problema, será aplicada a padronização para as variáveis numéricas cuja distribuição é normal e a normalização para a variável tool_wear_min que tem uma distribuição uniforme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "065430da",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = [col for col in numerical if col != 'tool_wear_min']\n",
    "scaler = StandardScaler()\n",
    "df_treino_enc[scale] = scaler.fit_transform(df_treino_enc[scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4020852a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>udi</th>\n",
       "      <th>product_id</th>\n",
       "      <th>air_temperature_k</th>\n",
       "      <th>process_temperature_k</th>\n",
       "      <th>rotational_speed_rpm</th>\n",
       "      <th>torque_nm</th>\n",
       "      <th>tool_wear_min</th>\n",
       "      <th>failure_type</th>\n",
       "      <th>type_H</th>\n",
       "      <th>type_L</th>\n",
       "      <th>type_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>M14860</td>\n",
       "      <td>-0.948838</td>\n",
       "      <td>-0.935907</td>\n",
       "      <td>0.076652</td>\n",
       "      <td>0.275525</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>L47181</td>\n",
       "      <td>-0.898702</td>\n",
       "      <td>-0.868702</td>\n",
       "      <td>-0.730484</td>\n",
       "      <td>0.627282</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>L47184</td>\n",
       "      <td>-0.898702</td>\n",
       "      <td>-0.868702</td>\n",
       "      <td>-0.730484</td>\n",
       "      <td>-0.005881</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>M14865</td>\n",
       "      <td>-0.948838</td>\n",
       "      <td>-0.935907</td>\n",
       "      <td>-0.634531</td>\n",
       "      <td>0.185073</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>L47186</td>\n",
       "      <td>-0.948838</td>\n",
       "      <td>-0.935907</td>\n",
       "      <td>0.116163</td>\n",
       "      <td>0.235324</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6662</th>\n",
       "      <td>9995</td>\n",
       "      <td>L57174</td>\n",
       "      <td>-0.597884</td>\n",
       "      <td>-1.137521</td>\n",
       "      <td>0.545130</td>\n",
       "      <td>-1.221954</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6663</th>\n",
       "      <td>9996</td>\n",
       "      <td>M24855</td>\n",
       "      <td>-0.597884</td>\n",
       "      <td>-1.070317</td>\n",
       "      <td>0.375801</td>\n",
       "      <td>-1.061151</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6664</th>\n",
       "      <td>9997</td>\n",
       "      <td>H39410</td>\n",
       "      <td>-0.547747</td>\n",
       "      <td>-1.070317</td>\n",
       "      <td>0.533841</td>\n",
       "      <td>-0.829996</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6665</th>\n",
       "      <td>9999</td>\n",
       "      <td>H39412</td>\n",
       "      <td>-0.497611</td>\n",
       "      <td>-0.868702</td>\n",
       "      <td>-0.730484</td>\n",
       "      <td>0.848386</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6666</th>\n",
       "      <td>10000</td>\n",
       "      <td>M24859</td>\n",
       "      <td>-0.497611</td>\n",
       "      <td>-0.868702</td>\n",
       "      <td>-0.211207</td>\n",
       "      <td>0.014220</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6667 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        udi product_id  air_temperature_k  process_temperature_k  \\\n",
       "0         1     M14860          -0.948838              -0.935907   \n",
       "1         2     L47181          -0.898702              -0.868702   \n",
       "2         5     L47184          -0.898702              -0.868702   \n",
       "3         6     M14865          -0.948838              -0.935907   \n",
       "4         7     L47186          -0.948838              -0.935907   \n",
       "...     ...        ...                ...                    ...   \n",
       "6662   9995     L57174          -0.597884              -1.137521   \n",
       "6663   9996     M24855          -0.597884              -1.070317   \n",
       "6664   9997     H39410          -0.547747              -1.070317   \n",
       "6665   9999     H39412          -0.497611              -0.868702   \n",
       "6666  10000     M24859          -0.497611              -0.868702   \n",
       "\n",
       "      rotational_speed_rpm  torque_nm  tool_wear_min  failure_type  type_H  \\\n",
       "0                 0.076652   0.275525              0             1       0   \n",
       "1                -0.730484   0.627282              3             1       0   \n",
       "2                -0.730484  -0.005881              9             1       0   \n",
       "3                -0.634531   0.185073             11             1       0   \n",
       "4                 0.116163   0.235324             14             1       0   \n",
       "...                    ...        ...            ...           ...     ...   \n",
       "6662              0.545130  -1.221954             12             1       0   \n",
       "6663              0.375801  -1.061151             14             1       0   \n",
       "6664              0.533841  -0.829996             17             1       1   \n",
       "6665             -0.730484   0.848386             25             1       1   \n",
       "6666             -0.211207   0.014220             30             1       0   \n",
       "\n",
       "      type_L  type_M  \n",
       "0          0       1  \n",
       "1          1       0  \n",
       "2          1       0  \n",
       "3          0       1  \n",
       "4          1       0  \n",
       "...      ...     ...  \n",
       "6662       1       0  \n",
       "6663       0       1  \n",
       "6664       0       0  \n",
       "6665       0       0  \n",
       "6666       0       1  \n",
       "\n",
       "[6667 rows x 11 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_treino_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5bf8374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>udi</th>\n",
       "      <th>product_id</th>\n",
       "      <th>air_temperature_k</th>\n",
       "      <th>process_temperature_k</th>\n",
       "      <th>rotational_speed_rpm</th>\n",
       "      <th>torque_nm</th>\n",
       "      <th>tool_wear_min</th>\n",
       "      <th>failure_type</th>\n",
       "      <th>type_H</th>\n",
       "      <th>type_L</th>\n",
       "      <th>type_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>M14860</td>\n",
       "      <td>-0.948838</td>\n",
       "      <td>-0.935907</td>\n",
       "      <td>0.076652</td>\n",
       "      <td>0.275525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>L47181</td>\n",
       "      <td>-0.898702</td>\n",
       "      <td>-0.868702</td>\n",
       "      <td>-0.730484</td>\n",
       "      <td>0.627282</td>\n",
       "      <td>0.011952</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>L47184</td>\n",
       "      <td>-0.898702</td>\n",
       "      <td>-0.868702</td>\n",
       "      <td>-0.730484</td>\n",
       "      <td>-0.005881</td>\n",
       "      <td>0.035857</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>M14865</td>\n",
       "      <td>-0.948838</td>\n",
       "      <td>-0.935907</td>\n",
       "      <td>-0.634531</td>\n",
       "      <td>0.185073</td>\n",
       "      <td>0.043825</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>L47186</td>\n",
       "      <td>-0.948838</td>\n",
       "      <td>-0.935907</td>\n",
       "      <td>0.116163</td>\n",
       "      <td>0.235324</td>\n",
       "      <td>0.055777</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6662</th>\n",
       "      <td>9995</td>\n",
       "      <td>L57174</td>\n",
       "      <td>-0.597884</td>\n",
       "      <td>-1.137521</td>\n",
       "      <td>0.545130</td>\n",
       "      <td>-1.221954</td>\n",
       "      <td>0.047809</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6663</th>\n",
       "      <td>9996</td>\n",
       "      <td>M24855</td>\n",
       "      <td>-0.597884</td>\n",
       "      <td>-1.070317</td>\n",
       "      <td>0.375801</td>\n",
       "      <td>-1.061151</td>\n",
       "      <td>0.055777</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6664</th>\n",
       "      <td>9997</td>\n",
       "      <td>H39410</td>\n",
       "      <td>-0.547747</td>\n",
       "      <td>-1.070317</td>\n",
       "      <td>0.533841</td>\n",
       "      <td>-0.829996</td>\n",
       "      <td>0.067729</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6665</th>\n",
       "      <td>9999</td>\n",
       "      <td>H39412</td>\n",
       "      <td>-0.497611</td>\n",
       "      <td>-0.868702</td>\n",
       "      <td>-0.730484</td>\n",
       "      <td>0.848386</td>\n",
       "      <td>0.099602</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6666</th>\n",
       "      <td>10000</td>\n",
       "      <td>M24859</td>\n",
       "      <td>-0.497611</td>\n",
       "      <td>-0.868702</td>\n",
       "      <td>-0.211207</td>\n",
       "      <td>0.014220</td>\n",
       "      <td>0.119522</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6667 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        udi product_id  air_temperature_k  process_temperature_k  \\\n",
       "0         1     M14860          -0.948838              -0.935907   \n",
       "1         2     L47181          -0.898702              -0.868702   \n",
       "2         5     L47184          -0.898702              -0.868702   \n",
       "3         6     M14865          -0.948838              -0.935907   \n",
       "4         7     L47186          -0.948838              -0.935907   \n",
       "...     ...        ...                ...                    ...   \n",
       "6662   9995     L57174          -0.597884              -1.137521   \n",
       "6663   9996     M24855          -0.597884              -1.070317   \n",
       "6664   9997     H39410          -0.547747              -1.070317   \n",
       "6665   9999     H39412          -0.497611              -0.868702   \n",
       "6666  10000     M24859          -0.497611              -0.868702   \n",
       "\n",
       "      rotational_speed_rpm  torque_nm  tool_wear_min  failure_type  type_H  \\\n",
       "0                 0.076652   0.275525       0.000000             1       0   \n",
       "1                -0.730484   0.627282       0.011952             1       0   \n",
       "2                -0.730484  -0.005881       0.035857             1       0   \n",
       "3                -0.634531   0.185073       0.043825             1       0   \n",
       "4                 0.116163   0.235324       0.055777             1       0   \n",
       "...                    ...        ...            ...           ...     ...   \n",
       "6662              0.545130  -1.221954       0.047809             1       0   \n",
       "6663              0.375801  -1.061151       0.055777             1       0   \n",
       "6664              0.533841  -0.829996       0.067729             1       1   \n",
       "6665             -0.730484   0.848386       0.099602             1       1   \n",
       "6666             -0.211207   0.014220       0.119522             1       0   \n",
       "\n",
       "      type_L  type_M  \n",
       "0          0       1  \n",
       "1          1       0  \n",
       "2          1       0  \n",
       "3          0       1  \n",
       "4          1       0  \n",
       "...      ...     ...  \n",
       "6662       1       0  \n",
       "6663       0       1  \n",
       "6664       0       0  \n",
       "6665       0       0  \n",
       "6666       0       1  \n",
       "\n",
       "[6667 rows x 11 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize = ['tool_wear_min']\n",
    "normalizer = MinMaxScaler()\n",
    "df_treino_enc[normalize] = normalizer.fit_transform(df_treino_enc[normalize])\n",
    "df_treino_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd7f6a6",
   "metadata": {},
   "source": [
    "Na análise exploratória, vimos que as variáveis rotational_speed_rpm e torque_nm possuíam valores _outliers_, vamos verificar agora quantos valores desse existem no dataset de treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a53bb455",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>udi</th>\n",
       "      <th>product_id</th>\n",
       "      <th>air_temperature_k</th>\n",
       "      <th>process_temperature_k</th>\n",
       "      <th>rotational_speed_rpm</th>\n",
       "      <th>torque_nm</th>\n",
       "      <th>tool_wear_min</th>\n",
       "      <th>failure_type</th>\n",
       "      <th>type_H</th>\n",
       "      <th>type_L</th>\n",
       "      <th>type_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>299</td>\n",
       "      <td>H29712</td>\n",
       "      <td>-1.049111</td>\n",
       "      <td>-1.003112</td>\n",
       "      <td>3.339063</td>\n",
       "      <td>-2.146572</td>\n",
       "      <td>0.501992</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>306</td>\n",
       "      <td>L47485</td>\n",
       "      <td>-1.099247</td>\n",
       "      <td>-1.070317</td>\n",
       "      <td>3.339063</td>\n",
       "      <td>-2.096321</td>\n",
       "      <td>0.589641</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>345</td>\n",
       "      <td>M15204</td>\n",
       "      <td>-1.249656</td>\n",
       "      <td>-1.204726</td>\n",
       "      <td>5.139597</td>\n",
       "      <td>-2.639031</td>\n",
       "      <td>0.115538</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>381</td>\n",
       "      <td>L47560</td>\n",
       "      <td>-1.249656</td>\n",
       "      <td>-1.137521</td>\n",
       "      <td>5.794337</td>\n",
       "      <td>-2.739533</td>\n",
       "      <td>0.505976</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>419</td>\n",
       "      <td>L47598</td>\n",
       "      <td>-1.299793</td>\n",
       "      <td>-1.070317</td>\n",
       "      <td>3.463238</td>\n",
       "      <td>-2.247074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>6526</td>\n",
       "      <td>L53705</td>\n",
       "      <td>0.555252</td>\n",
       "      <td>0.273778</td>\n",
       "      <td>-1.272337</td>\n",
       "      <td>3.370984</td>\n",
       "      <td>0.195219</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>7570</td>\n",
       "      <td>L54749</td>\n",
       "      <td>0.104025</td>\n",
       "      <td>0.677007</td>\n",
       "      <td>-1.594063</td>\n",
       "      <td>3.190081</td>\n",
       "      <td>0.593625</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>7764</td>\n",
       "      <td>L54943</td>\n",
       "      <td>0.204298</td>\n",
       "      <td>1.080236</td>\n",
       "      <td>-1.904500</td>\n",
       "      <td>3.672490</td>\n",
       "      <td>0.011952</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>8583</td>\n",
       "      <td>M23442</td>\n",
       "      <td>-1.249656</td>\n",
       "      <td>-1.271931</td>\n",
       "      <td>-1.148163</td>\n",
       "      <td>3.210181</td>\n",
       "      <td>0.601594</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>9085</td>\n",
       "      <td>L56264</td>\n",
       "      <td>-1.400066</td>\n",
       "      <td>-1.406340</td>\n",
       "      <td>-1.193317</td>\n",
       "      <td>3.551888</td>\n",
       "      <td>0.685259</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      udi product_id  air_temperature_k  process_temperature_k  \\\n",
       "0     299     H29712          -1.049111              -1.003112   \n",
       "1     306     L47485          -1.099247              -1.070317   \n",
       "2     345     M15204          -1.249656              -1.204726   \n",
       "3     381     L47560          -1.249656              -1.137521   \n",
       "4     419     L47598          -1.299793              -1.070317   \n",
       "..    ...        ...                ...                    ...   \n",
       "112  6526     L53705           0.555252               0.273778   \n",
       "113  7570     L54749           0.104025               0.677007   \n",
       "114  7764     L54943           0.204298               1.080236   \n",
       "115  8583     M23442          -1.249656              -1.271931   \n",
       "116  9085     L56264          -1.400066              -1.406340   \n",
       "\n",
       "     rotational_speed_rpm  torque_nm  tool_wear_min  failure_type  type_H  \\\n",
       "0                3.339063  -2.146572       0.501992             1       1   \n",
       "1                3.339063  -2.096321       0.589641             1       0   \n",
       "2                5.139597  -2.639031       0.115538             1       0   \n",
       "3                5.794337  -2.739533       0.505976             3       0   \n",
       "4                3.463238  -2.247074       0.000000             1       0   \n",
       "..                    ...        ...            ...           ...     ...   \n",
       "112             -1.272337   3.370984       0.195219             3       0   \n",
       "113             -1.594063   3.190081       0.593625             3       0   \n",
       "114             -1.904500   3.672490       0.011952             3       0   \n",
       "115             -1.148163   3.210181       0.601594             3       0   \n",
       "116             -1.193317   3.551888       0.685259             3       0   \n",
       "\n",
       "     type_L  type_M  \n",
       "0         0       0  \n",
       "1         1       0  \n",
       "2         0       1  \n",
       "3         1       0  \n",
       "4         1       0  \n",
       "..      ...     ...  \n",
       "112       1       0  \n",
       "113       1       0  \n",
       "114       1       0  \n",
       "115       0       1  \n",
       "116       1       0  \n",
       "\n",
       "[117 rows x 11 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# União de todas as linhas onde uma das duas variáveis possui um outlier\n",
    "outliers = pd.merge(df_treino_enc.loc[abs(df_treino_enc['rotational_speed_rpm']) > 3],\n",
    "                    df_treino_enc.loc[abs(df_treino_enc['torque_nm']) > 3],\n",
    "                    how='outer')\n",
    "outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f52e192f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.017549122543872805"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proporção de outliers\n",
    "len(outliers)/len(df_treino_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c701175e",
   "metadata": {},
   "source": [
    "Como a proporção de outliers é de menos de 2%, não há grande prejuízo em apenas remover essas linhas para que elas não comprometam o treinamento do modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8a2a97f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>udi</th>\n",
       "      <th>product_id</th>\n",
       "      <th>air_temperature_k</th>\n",
       "      <th>process_temperature_k</th>\n",
       "      <th>rotational_speed_rpm</th>\n",
       "      <th>torque_nm</th>\n",
       "      <th>tool_wear_min</th>\n",
       "      <th>failure_type</th>\n",
       "      <th>type_H</th>\n",
       "      <th>type_L</th>\n",
       "      <th>type_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>M14860</td>\n",
       "      <td>-0.948838</td>\n",
       "      <td>-0.935907</td>\n",
       "      <td>0.076652</td>\n",
       "      <td>0.275525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>L47181</td>\n",
       "      <td>-0.898702</td>\n",
       "      <td>-0.868702</td>\n",
       "      <td>-0.730484</td>\n",
       "      <td>0.627282</td>\n",
       "      <td>0.011952</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>L47184</td>\n",
       "      <td>-0.898702</td>\n",
       "      <td>-0.868702</td>\n",
       "      <td>-0.730484</td>\n",
       "      <td>-0.005881</td>\n",
       "      <td>0.035857</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>M14865</td>\n",
       "      <td>-0.948838</td>\n",
       "      <td>-0.935907</td>\n",
       "      <td>-0.634531</td>\n",
       "      <td>0.185073</td>\n",
       "      <td>0.043825</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>L47186</td>\n",
       "      <td>-0.948838</td>\n",
       "      <td>-0.935907</td>\n",
       "      <td>0.116163</td>\n",
       "      <td>0.235324</td>\n",
       "      <td>0.055777</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6662</th>\n",
       "      <td>9995</td>\n",
       "      <td>L57174</td>\n",
       "      <td>-0.597884</td>\n",
       "      <td>-1.137521</td>\n",
       "      <td>0.545130</td>\n",
       "      <td>-1.221954</td>\n",
       "      <td>0.047809</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6663</th>\n",
       "      <td>9996</td>\n",
       "      <td>M24855</td>\n",
       "      <td>-0.597884</td>\n",
       "      <td>-1.070317</td>\n",
       "      <td>0.375801</td>\n",
       "      <td>-1.061151</td>\n",
       "      <td>0.055777</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6664</th>\n",
       "      <td>9997</td>\n",
       "      <td>H39410</td>\n",
       "      <td>-0.547747</td>\n",
       "      <td>-1.070317</td>\n",
       "      <td>0.533841</td>\n",
       "      <td>-0.829996</td>\n",
       "      <td>0.067729</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6665</th>\n",
       "      <td>9999</td>\n",
       "      <td>H39412</td>\n",
       "      <td>-0.497611</td>\n",
       "      <td>-0.868702</td>\n",
       "      <td>-0.730484</td>\n",
       "      <td>0.848386</td>\n",
       "      <td>0.099602</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6666</th>\n",
       "      <td>10000</td>\n",
       "      <td>M24859</td>\n",
       "      <td>-0.497611</td>\n",
       "      <td>-0.868702</td>\n",
       "      <td>-0.211207</td>\n",
       "      <td>0.014220</td>\n",
       "      <td>0.119522</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6550 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        udi product_id  air_temperature_k  process_temperature_k  \\\n",
       "0         1     M14860          -0.948838              -0.935907   \n",
       "1         2     L47181          -0.898702              -0.868702   \n",
       "2         5     L47184          -0.898702              -0.868702   \n",
       "3         6     M14865          -0.948838              -0.935907   \n",
       "4         7     L47186          -0.948838              -0.935907   \n",
       "...     ...        ...                ...                    ...   \n",
       "6662   9995     L57174          -0.597884              -1.137521   \n",
       "6663   9996     M24855          -0.597884              -1.070317   \n",
       "6664   9997     H39410          -0.547747              -1.070317   \n",
       "6665   9999     H39412          -0.497611              -0.868702   \n",
       "6666  10000     M24859          -0.497611              -0.868702   \n",
       "\n",
       "      rotational_speed_rpm  torque_nm  tool_wear_min  failure_type  type_H  \\\n",
       "0                 0.076652   0.275525       0.000000             1       0   \n",
       "1                -0.730484   0.627282       0.011952             1       0   \n",
       "2                -0.730484  -0.005881       0.035857             1       0   \n",
       "3                -0.634531   0.185073       0.043825             1       0   \n",
       "4                 0.116163   0.235324       0.055777             1       0   \n",
       "...                    ...        ...            ...           ...     ...   \n",
       "6662              0.545130  -1.221954       0.047809             1       0   \n",
       "6663              0.375801  -1.061151       0.055777             1       0   \n",
       "6664              0.533841  -0.829996       0.067729             1       1   \n",
       "6665             -0.730484   0.848386       0.099602             1       1   \n",
       "6666             -0.211207   0.014220       0.119522             1       0   \n",
       "\n",
       "      type_L  type_M  \n",
       "0          0       1  \n",
       "1          1       0  \n",
       "2          1       0  \n",
       "3          0       1  \n",
       "4          1       0  \n",
       "...      ...     ...  \n",
       "6662       1       0  \n",
       "6663       0       1  \n",
       "6664       0       0  \n",
       "6665       0       0  \n",
       "6666       0       1  \n",
       "\n",
       "[6550 rows x 11 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_treino_sem_outliers = df_treino_enc.loc[abs(df_treino_enc['rotational_speed_rpm']) < 3]\n",
    "df_treino_sem_outliers = df_treino_sem_outliers.loc[abs(df_treino_sem_outliers['torque_nm']) < 3]\n",
    "df_treino_sem_outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29995548",
   "metadata": {},
   "source": [
    "## Divisão do dataset em treino e validação\n",
    "\n",
    "Como os dados de teste não possuem a variável target, é importante que separemos uma parte do dataset de treino para validar o modelo e garantir que não haja overfitting. Dividiremos então o dataset em treino e validação. Usaremos 25% dos dados para validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "39618fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa X e y\n",
    "target = 'failure_type'\n",
    "variables = ['air_temperature_k', 'process_temperature_k', 'rotational_speed_rpm', 'torque_nm', 'tool_wear_min', 'type_H', \n",
    "             'type_L', 'type_M']\n",
    "\n",
    "y = df_treino_sem_outliers[target]\n",
    "X = df_treino_sem_outliers[variables]\n",
    "\n",
    "# Divisão em Dados de Treino e Validação.\n",
    "X_treino, X_val, y_treino, y_val = train_test_split(X, y, test_size = 0.25, random_state = 101)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc8a0b5",
   "metadata": {},
   "source": [
    "## Balanceamento das classes da variável target\n",
    "\n",
    "A última etapa do pré-processamento é balancear as instâncias da variável target. Como visto na Análise Exploratória, há muito mais máquinas sem falhas do que com os 5 tipos de falhas apresentados. Se o modelo preditivo for alimentado dessa forma, ele aprenderá muito melhor sobre máquinas sem falhas do que sobre máquinas com falhas, portanto, é preciso aplicar alguma técnica de balanceamento de classes.\n",
    "\n",
    "Pode-se aplicar o _oversampling_, que cria mais registros das classes que minoritárias ou o _undersampling_, que remove registros das classes majoritárias. \n",
    "\n",
    "O dataset possui poucos registros - apenas cerca de 6,5 mil - portanto, se aplicado o _undersampling_, teremos ainda menos dados para o treinamento e perderemos características demais sobre os dados.\n",
    "\n",
    "O _oversampling_ também não funcionaria muito bem para esse modelo, visto que a diferença entre as classes é tão grande que seriam criados registros artificias demais para resolver a diferença.\n",
    "\n",
    "A abordagem que faremos será a de converter o problema de classificação multiclasse em um problema de classificação binário, respondendo a pergunta: \"Há ou não falha nas máquinas?\". Após respondido esse primeiro questionamento, abordaremos então, para as máquinas em que há falha, qual o tipo de falha presente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bdc8f368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.countplot(x=y_treino)\n",
    "plt.title('Tipos de falha por máquina');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a0bf7126",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Definindo o y_treino binário - falha ou não falha\n",
    "y_treino_bin, y_val_bin = y_treino.where(y_treino == 1, 0), y_val.where(y_val == 1, 0)\n",
    "\n",
    "# Plot\n",
    "sns.countplot(x=y_treino_bin)\n",
    "plt.title('Falha (0) ou Não Falha (1)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "542c8d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o objeto balanceador\n",
    "smote = SMOTE(random_state = 1337)\n",
    "\n",
    "# Aplica o balanceador\n",
    "X_res, y_res = smote.fit_resample(X_treino, y_treino_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e47070f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=y_res)\n",
    "plt.title('Falha (0) ou Não Falha (1) - depois do oversampling');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a48498",
   "metadata": {},
   "source": [
    "# Criação do Modelo Preditivo - Classificação Binária\n",
    "\n",
    "Após toda a etapa de Análise Exploratória e Pré-Processamento de Dados, podemos finalmente começar a criar e avaliar os modelos preditivos para esse problema. Como o problema é para prever uma classe, um tipo de falha, então é um problema de classificação. Mais especificamente, classificação multiclasse, visto que a variável target possui mais de 2 classes possíveis. No entanto, como mencionado anteriormente, primeiro transformaremos essa classificação multiclasse em classificação binária, e depois faremos a mudança para classificação multiclasse apenas daquelas máquinas em que uma falha for prevista.\n",
    "\n",
    "Entre os algoritmos mais comuns para esse tipo de problema estão:\n",
    "Regressão Logística, KNN, Naive Bayes, Decision Tree, SVM (Support Vector Machines) e Redes Neurais.\n",
    "\n",
    "Criaremos alguns modelos e utilizaremos algumas métricas de avaliação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c1bf1114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a função que treina e avalia o modelo\n",
    "def train_and_score_model(algoritmo, X_treino, y_treino, X_teste, y_teste, nome = None, version = '1'):\n",
    "    # Cria o modelo\n",
    "    modelo = algoritmo\n",
    "    \n",
    "    # Treinamento\n",
    "    start = time.time()\n",
    "    modelo.fit(X_treino, y_treino)\n",
    "    end = time.time()\n",
    "    print('Tempo de Treinamento do Modelo:', end - start)\n",
    "    \n",
    "    # Fazendo as previsões para o dataset de teste\n",
    "    previsoes = modelo.predict(X_teste)\n",
    "    \n",
    "    # Avaliação do modelo\n",
    "    # Matriz de confusão\n",
    "    print('\\nMatriz de confusão\\n', confusion_matrix(y_teste, previsoes))\n",
    "    \n",
    "    # Dicionário de métricas e metadados\n",
    "    dict_model =   {'Modelo': nome,\n",
    "                    'Versão': version,\n",
    "                    'Precision':precision_score(y_teste, previsoes),\n",
    "                    'Recall':recall_score(y_teste, previsoes),\n",
    "                    'F1 Score':f1_score(y_teste, previsoes),\n",
    "                    'Acurácia':accuracy_score(y_teste, previsoes)}\n",
    "        \n",
    "    return modelo, dict_model, previsoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d24a3d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de Treinamento do Modelo: 0.015000343322753906\n",
      "\n",
      "Matriz de confusão\n",
      " [[   7   46]\n",
      " [   3 1582]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Modelo': 'KNN',\n",
       " 'Versão': 'Binary Classification 1',\n",
       " 'Precision': 0.9717444717444718,\n",
       " 'Recall': 0.9981072555205047,\n",
       " 'F1 Score': 0.9847494553376906,\n",
       " 'Acurácia': 0.9700854700854701}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo 1 - KNN\n",
    "modelo1, dict1, previsoes1 = train_and_score_model(KNeighborsClassifier(), X_treino, y_treino_bin, X_val, y_val_bin, nome = 'KNN', \n",
    "                              version = 'Binary Classification 1')\n",
    "dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5b85033a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de Treinamento do Modelo: 0.004999876022338867\n",
      "\n",
      "Matriz de confusão\n",
      " [[  14   39]\n",
      " [  10 1575]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Modelo': 'Naive Bayes',\n",
       " 'Versão': 'Binary Classification 1',\n",
       " 'Precision': 0.9758364312267658,\n",
       " 'Recall': 0.9936908517350158,\n",
       " 'F1 Score': 0.9846827133479212,\n",
       " 'Acurácia': 0.9700854700854701}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo 2 - Naive Bayes\n",
    "modelo2, dict2, previsoes2 = train_and_score_model(GaussianNB(), X_treino, y_treino_bin, X_val, y_val_bin, nome = 'Naive Bayes', \n",
    "                              version = 'Binary Classification 1')\n",
    "dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "06659399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de Treinamento do Modelo: 0.020994186401367188\n",
      "\n",
      "Matriz de confusão\n",
      " [[  34   19]\n",
      " [  20 1565]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Modelo': 'Decision Tree Classifier',\n",
       " 'Versão': 'Binary Classification 1',\n",
       " 'Precision': 0.9880050505050505,\n",
       " 'Recall': 0.9873817034700315,\n",
       " 'F1 Score': 0.9876932786367939,\n",
       " 'Acurácia': 0.9761904761904762}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo 3 - Decision Tree Classifier\n",
    "modelo3, dict3, previsoes3 = train_and_score_model(DecisionTreeClassifier(), X_treino, y_treino_bin, X_val, y_val_bin, nome = 'Decision Tree Classifier', \n",
    "                              version = 'Binary Classification 1')\n",
    "dict3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "218739c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de Treinamento do Modelo: 0.5219972133636475\n",
      "\n",
      "Matriz de confusão\n",
      " [[  24   29]\n",
      " [   5 1580]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Modelo': 'Random Forest Classifier',\n",
       " 'Versão': 'Binary Classification 1',\n",
       " 'Precision': 0.9819763828464885,\n",
       " 'Recall': 0.9968454258675079,\n",
       " 'F1 Score': 0.989355040701315,\n",
       " 'Acurácia': 0.9792429792429792}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo 4 - Decision Tree Classifier\n",
    "modelo4, dict4, previsoes4 = train_and_score_model(RandomForestClassifier(), X_treino, y_treino_bin, X_val, y_val_bin, nome = 'Random Forest Classifier', \n",
    "                              version = 'Binary Classification 1')\n",
    "dict4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "50ab2b5e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de Treinamento do Modelo: 0.11899614334106445\n",
      "\n",
      "Matriz de confusão\n",
      " [[   2   51]\n",
      " [   1 1584]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Modelo': 'SVM Classifier',\n",
       " 'Versão': 'Binary Classification 1',\n",
       " 'Precision': 0.9688073394495413,\n",
       " 'Recall': 0.9993690851735015,\n",
       " 'F1 Score': 0.9838509316770186,\n",
       " 'Acurácia': 0.9682539682539683}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo 5 - SVM Classifier\n",
    "modelo5, dict5, previsoes5 = train_and_score_model(svm.SVC(), X_treino, y_treino_bin, X_val, y_val_bin, nome = 'SVM Classifier', \n",
    "                                      version = 'Binary Classification 1')\n",
    "dict5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b980db05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de Treinamento do Modelo: 0.11899542808532715\n",
      "\n",
      "Matriz de confusão\n",
      " [[   2   51]\n",
      " [   1 1584]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Modelo': 'XGBoost Classifier',\n",
       " 'Versão': 'Binary Classification 1',\n",
       " 'Precision': 0.9688073394495413,\n",
       " 'Recall': 0.9993690851735015,\n",
       " 'F1 Score': 0.9838509316770186,\n",
       " 'Acurácia': 0.9682539682539683}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo 6 - XGBoost Classifier\n",
    "modelo6, dict6, previsoes = train_and_score_model(svm.SVC(), X_treino, y_treino_bin, X_val, y_val_bin, nome = 'XGBoost Classifier', \n",
    "                              version = 'Binary Classification 1')\n",
    "dict6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "82afacc0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dict1</th>\n",
       "      <th>dict2</th>\n",
       "      <th>dict3</th>\n",
       "      <th>dict4</th>\n",
       "      <th>dict5</th>\n",
       "      <th>dict6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Modelo</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>SVM Classifier</td>\n",
       "      <td>XGBoost Classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Versão</th>\n",
       "      <td>Binary Classification 1</td>\n",
       "      <td>Binary Classification 1</td>\n",
       "      <td>Binary Classification 1</td>\n",
       "      <td>Binary Classification 1</td>\n",
       "      <td>Binary Classification 1</td>\n",
       "      <td>Binary Classification 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.971744</td>\n",
       "      <td>0.975836</td>\n",
       "      <td>0.988005</td>\n",
       "      <td>0.981976</td>\n",
       "      <td>0.968807</td>\n",
       "      <td>0.968807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.998107</td>\n",
       "      <td>0.993691</td>\n",
       "      <td>0.987382</td>\n",
       "      <td>0.996845</td>\n",
       "      <td>0.999369</td>\n",
       "      <td>0.999369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.984749</td>\n",
       "      <td>0.984683</td>\n",
       "      <td>0.987693</td>\n",
       "      <td>0.989355</td>\n",
       "      <td>0.983851</td>\n",
       "      <td>0.983851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acurácia</th>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.97619</td>\n",
       "      <td>0.979243</td>\n",
       "      <td>0.968254</td>\n",
       "      <td>0.968254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             dict1                    dict2  \\\n",
       "Modelo                         KNN              Naive Bayes   \n",
       "Versão     Binary Classification 1  Binary Classification 1   \n",
       "Precision                 0.971744                 0.975836   \n",
       "Recall                    0.998107                 0.993691   \n",
       "F1 Score                  0.984749                 0.984683   \n",
       "Acurácia                  0.970085                 0.970085   \n",
       "\n",
       "                              dict3                     dict4  \\\n",
       "Modelo     Decision Tree Classifier  Random Forest Classifier   \n",
       "Versão      Binary Classification 1   Binary Classification 1   \n",
       "Precision                  0.988005                  0.981976   \n",
       "Recall                     0.987382                  0.996845   \n",
       "F1 Score                   0.987693                  0.989355   \n",
       "Acurácia                    0.97619                  0.979243   \n",
       "\n",
       "                             dict5                    dict6  \n",
       "Modelo              SVM Classifier       XGBoost Classifier  \n",
       "Versão     Binary Classification 1  Binary Classification 1  \n",
       "Precision                 0.968807                 0.968807  \n",
       "Recall                    0.999369                 0.999369  \n",
       "F1 Score                  0.983851                 0.983851  \n",
       "Acurácia                  0.968254                 0.968254  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatena todos os dicionários em um dataframe do Pandas\n",
    "resumo_bin1 = pd.DataFrame({'dict1':pd.Series(dict1),\n",
    "                           'dict2':pd.Series(dict2),\n",
    "                           'dict3':pd.Series(dict3),\n",
    "                           'dict4':pd.Series(dict4),\n",
    "                           'dict5':pd.Series(dict5),\n",
    "                           'dict6':pd.Series(dict6)})\n",
    "\n",
    "resumo_bin1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4058c484",
   "metadata": {},
   "source": [
    "## Repetindo os modelos com o balanceamento de classes (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5408f73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de Treinamento do Modelo: 0.030996322631835938\n",
      "\n",
      "Matriz de confusão\n",
      " [[  34   19]\n",
      " [  95 1490]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Modelo': 'KNN',\n",
       " 'Versão': 'Binary Classification 2',\n",
       " 'Precision': 0.9874088800530152,\n",
       " 'Recall': 0.9400630914826499,\n",
       " 'F1 Score': 0.9631544925662574,\n",
       " 'Acurácia': 0.9304029304029304}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo 1 - KNN - com SMOTE\n",
    "modelo1, dict1, previsoes1 = train_and_score_model(KNeighborsClassifier(), X_res, y_res, X_val, y_val_bin, nome = 'KNN', \n",
    "                                          version = 'Binary Classification 2')\n",
    "dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aa628f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de Treinamento do Modelo: 0.00701141357421875\n",
      "\n",
      "Matriz de confusão\n",
      " [[  43   10]\n",
      " [ 392 1193]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Modelo': 'Naive Bayes',\n",
       " 'Versão': 'Binary Classification 2',\n",
       " 'Precision': 0.9916874480465503,\n",
       " 'Recall': 0.7526813880126183,\n",
       " 'F1 Score': 0.8558106169296986,\n",
       " 'Acurácia': 0.7545787545787546}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo 2 - Naive Bayes - com SMOTE\n",
    "modelo2, dict2, previsoes2 = train_and_score_model(GaussianNB(), X_res, y_res, X_val, y_val_bin, nome = 'Naive Bayes', \n",
    "                                          version = 'Binary Classification 2')\n",
    "dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "763bd13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de Treinamento do Modelo: 0.046993255615234375\n",
      "\n",
      "Matriz de confusão\n",
      " [[  42   11]\n",
      " [  55 1530]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Modelo': 'Decision Tree Classifier',\n",
       " 'Versão': 'Binary Classification 2',\n",
       " 'Precision': 0.9928617780661908,\n",
       " 'Recall': 0.9652996845425867,\n",
       " 'F1 Score': 0.9788867562380038,\n",
       " 'Acurácia': 0.9597069597069597}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo 3 - Decision Tree - com SMOTE\n",
    "modelo3, dict3, previsoes3 = train_and_score_model(DecisionTreeClassifier(), X_res, y_res, X_val, y_val_bin, nome = 'Decision Tree Classifier', \n",
    "                                          version = 'Binary Classification 2')\n",
    "dict3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8e83ca28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de Treinamento do Modelo: 1.4349942207336426\n",
      "\n",
      "Matriz de confusão\n",
      " [[  39   14]\n",
      " [  31 1554]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Modelo': 'Random Forest Classifier',\n",
       " 'Versão': 'Binary Classification 2',\n",
       " 'Precision': 0.9910714285714286,\n",
       " 'Recall': 0.9804416403785489,\n",
       " 'F1 Score': 0.9857278782112274,\n",
       " 'Acurácia': 0.9725274725274725}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo 4 - Random Forest - com SMOTE\n",
    "modelo4, dict4, previsoes4 = train_and_score_model(RandomForestClassifier(), X_res, y_res, X_val, y_val_bin, nome = 'Random Forest Classifier', \n",
    "                                          version = 'Binary Classification 2')\n",
    "dict4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1ad66d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de Treinamento do Modelo: 1.170994520187378\n",
      "\n",
      "Matriz de confusão\n",
      " [[  37   16]\n",
      " [  29 1556]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Modelo': 'SVM Classifier',\n",
       " 'Versão': 'Binary Classification 2',\n",
       " 'Precision': 0.989821882951654,\n",
       " 'Recall': 0.9817034700315458,\n",
       " 'F1 Score': 0.9857459613557175,\n",
       " 'Acurácia': 0.9725274725274725}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo 5 - SVM Classifier - com SMOTE\n",
    "modelo5, dict5, previsoes5 = train_and_score_model(RandomForestClassifier(), X_res, y_res, X_val, y_val_bin, nome = 'SVM Classifier', \n",
    "                                          version = 'Binary Classification 2')\n",
    "dict5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "63bec297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de Treinamento do Modelo: 0.26198410987854004\n",
      "\n",
      "Matriz de confusão\n",
      " [[  41   12]\n",
      " [  31 1554]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Modelo': 'XGBoost Classifier',\n",
       " 'Versão': 'Binary Classification 2',\n",
       " 'Precision': 0.9923371647509579,\n",
       " 'Recall': 0.9804416403785489,\n",
       " 'F1 Score': 0.9863535385591876,\n",
       " 'Acurácia': 0.9737484737484737}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo 6 - XGBoost Classifier - com SMOTE\n",
    "modelo6, dict6, previsoes6 = train_and_score_model(XGBClassifier(), X_res, y_res, X_val, y_val_bin, nome = 'XGBoost Classifier', \n",
    "                                          version = 'Binary Classification 2')\n",
    "dict6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "81e15857",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dict1</th>\n",
       "      <th>dict2</th>\n",
       "      <th>dict3</th>\n",
       "      <th>dict4</th>\n",
       "      <th>dict5</th>\n",
       "      <th>dict6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Modelo</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>SVM Classifier</td>\n",
       "      <td>XGBoost Classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Versão</th>\n",
       "      <td>Binary Classification 2</td>\n",
       "      <td>Binary Classification 2</td>\n",
       "      <td>Binary Classification 2</td>\n",
       "      <td>Binary Classification 2</td>\n",
       "      <td>Binary Classification 2</td>\n",
       "      <td>Binary Classification 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.987409</td>\n",
       "      <td>0.991687</td>\n",
       "      <td>0.992862</td>\n",
       "      <td>0.991071</td>\n",
       "      <td>0.989822</td>\n",
       "      <td>0.992337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.940063</td>\n",
       "      <td>0.752681</td>\n",
       "      <td>0.9653</td>\n",
       "      <td>0.980442</td>\n",
       "      <td>0.981703</td>\n",
       "      <td>0.980442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.963154</td>\n",
       "      <td>0.855811</td>\n",
       "      <td>0.978887</td>\n",
       "      <td>0.985728</td>\n",
       "      <td>0.985746</td>\n",
       "      <td>0.986354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acurácia</th>\n",
       "      <td>0.930403</td>\n",
       "      <td>0.754579</td>\n",
       "      <td>0.959707</td>\n",
       "      <td>0.972527</td>\n",
       "      <td>0.972527</td>\n",
       "      <td>0.973748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             dict1                    dict2  \\\n",
       "Modelo                         KNN              Naive Bayes   \n",
       "Versão     Binary Classification 2  Binary Classification 2   \n",
       "Precision                 0.987409                 0.991687   \n",
       "Recall                    0.940063                 0.752681   \n",
       "F1 Score                  0.963154                 0.855811   \n",
       "Acurácia                  0.930403                 0.754579   \n",
       "\n",
       "                              dict3                     dict4  \\\n",
       "Modelo     Decision Tree Classifier  Random Forest Classifier   \n",
       "Versão      Binary Classification 2   Binary Classification 2   \n",
       "Precision                  0.992862                  0.991071   \n",
       "Recall                       0.9653                  0.980442   \n",
       "F1 Score                   0.978887                  0.985728   \n",
       "Acurácia                   0.959707                  0.972527   \n",
       "\n",
       "                             dict5                    dict6  \n",
       "Modelo              SVM Classifier       XGBoost Classifier  \n",
       "Versão     Binary Classification 2  Binary Classification 2  \n",
       "Precision                 0.989822                 0.992337  \n",
       "Recall                    0.981703                 0.980442  \n",
       "F1 Score                  0.985746                 0.986354  \n",
       "Acurácia                  0.972527                 0.973748  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatena todos os dicionários em um dataframe do Pandas\n",
    "resumo_bin2 = pd.DataFrame({'dict1':pd.Series(dict1),\n",
    "                           'dict2':pd.Series(dict2),\n",
    "                           'dict3':pd.Series(dict3),\n",
    "                           'dict4':pd.Series(dict4),\n",
    "                           'dict5':pd.Series(dict5),\n",
    "                           'dict6':pd.Series(dict6)})\n",
    "\n",
    "resumo_bin2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f1af1eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dict1</th>\n",
       "      <th>dict2</th>\n",
       "      <th>dict3</th>\n",
       "      <th>dict4</th>\n",
       "      <th>dict5</th>\n",
       "      <th>dict6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Modelo</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>SVM Classifier</td>\n",
       "      <td>XGBoost Classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Versão</th>\n",
       "      <td>Binary Classification 1</td>\n",
       "      <td>Binary Classification 1</td>\n",
       "      <td>Binary Classification 1</td>\n",
       "      <td>Binary Classification 1</td>\n",
       "      <td>Binary Classification 1</td>\n",
       "      <td>Binary Classification 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.971744</td>\n",
       "      <td>0.975836</td>\n",
       "      <td>0.988005</td>\n",
       "      <td>0.981976</td>\n",
       "      <td>0.968807</td>\n",
       "      <td>0.968807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.998107</td>\n",
       "      <td>0.993691</td>\n",
       "      <td>0.987382</td>\n",
       "      <td>0.996845</td>\n",
       "      <td>0.999369</td>\n",
       "      <td>0.999369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.984749</td>\n",
       "      <td>0.984683</td>\n",
       "      <td>0.987693</td>\n",
       "      <td>0.989355</td>\n",
       "      <td>0.983851</td>\n",
       "      <td>0.983851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acurácia</th>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.97619</td>\n",
       "      <td>0.979243</td>\n",
       "      <td>0.968254</td>\n",
       "      <td>0.968254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             dict1                    dict2  \\\n",
       "Modelo                         KNN              Naive Bayes   \n",
       "Versão     Binary Classification 1  Binary Classification 1   \n",
       "Precision                 0.971744                 0.975836   \n",
       "Recall                    0.998107                 0.993691   \n",
       "F1 Score                  0.984749                 0.984683   \n",
       "Acurácia                  0.970085                 0.970085   \n",
       "\n",
       "                              dict3                     dict4  \\\n",
       "Modelo     Decision Tree Classifier  Random Forest Classifier   \n",
       "Versão      Binary Classification 1   Binary Classification 1   \n",
       "Precision                  0.988005                  0.981976   \n",
       "Recall                     0.987382                  0.996845   \n",
       "F1 Score                   0.987693                  0.989355   \n",
       "Acurácia                    0.97619                  0.979243   \n",
       "\n",
       "                             dict5                    dict6  \n",
       "Modelo              SVM Classifier       XGBoost Classifier  \n",
       "Versão     Binary Classification 1  Binary Classification 1  \n",
       "Precision                 0.968807                 0.968807  \n",
       "Recall                    0.999369                 0.999369  \n",
       "F1 Score                  0.983851                 0.983851  \n",
       "Acurácia                  0.968254                 0.968254  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumo_bin1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041ea186",
   "metadata": {},
   "source": [
    "## Avaliando as métricas\n",
    "\n",
    "Para avaliar as métricas é necessário definir: qual a classe positiva e qual a classe negativa do problema?\n",
    "\n",
    "Classe positiva: Máquinas sem falha (1)\n",
    "Classe negativa: Máquinas com falha (0)\n",
    "\n",
    "**Precision**: Essa métrica responde à pergunta: que proporção das previsões positivas são realmente positivas? Para esse problema, significa quantas máquinas que foram previstas como sem falhas realmente não possuem falhas. É necessário otimizar essa métrica se o problema requerer um baixo número de **falsos positivos**. Estes significariam máquinas que têm falhas mas foram previstas como se não tivessem. Como nosso problema é de manutenção preditiva, esse tipo de falha é muito mais grave do que prever falhas nas máquinas que não a possuem, ou falsos negativos.\n",
    "\n",
    "**Recall**: Responde à pergunta: que proporção dos verdadeiros positivos estão corretamente classificados? Para esse problema, significa as máquinas que não possuem falhas e foram classificadas corretamente. É necessário otimizar essa métrica se o problema requerer um baixo número de **falsos negativos**. Estes significariam máquinas que não possuem falhas mas foram previstas como se tivessem. Como nosso problema é de manutenção preditiva, esse tipo de falha é menos grave do que prever falsos positivos.\n",
    "\n",
    "**F1 Score**: É a média harmônica entre precision e recall. Fortemente afetado caso uma das duas métricas seja muito baixa. É necessário otimizar essa métrica quando o problema requerer um bom equilíbrio de falsos positivos e negativos.\n",
    "\n",
    "**Acurácia**: É simplesmente o percentual de acerto do modelo. \n",
    "\n",
    "Considerando nosso problema, Precision será nossa métrica base para a classificação binária. \n",
    "Posteriormente, na avaliação da classificação das falhas, utilizaremos a métrica de ROC AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813d7b04",
   "metadata": {},
   "source": [
    "# Criação do Modelo Preditivo - Classificação Multiclasse\n",
    "\n",
    "O melhor modelo encontrado para a classificação binária foi o Decision Tree com aplicação de SMOTE, com Precision de 0.992862. Seguido pelo modelo XGBoost Classifier, também com aplicação de SMOTE e Precision de 0.992337.\n",
    "\n",
    "Agora, faremos a classificação do tipo de falha para todas as previsoes dos casos em que há falha nas máquinas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9ba3bca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsões para o dataset de treino completo (antes do train_test_split)\n",
    "previsoes_modelo_binario = modelo3.predict(X)\n",
    "\n",
    "# Dataset das máquinas com falha prevista \n",
    "X_falha = X[previsoes_modelo_binario == 0]\n",
    "y_falha = y[previsoes_modelo_binario == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7f475379",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot das falhas\n",
    "sns.countplot(x=y_falha)\n",
    "plt.title('Tipo de falha nas máquinas');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b09764c",
   "metadata": {},
   "source": [
    "Nesse caso já possuímos um dataset com classes melhor balanceadas, não precisamos de _oversampling_. Como o dataset possui pouquíssimos dados, faremos a divisão em treino e validação em 80/20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9d3f15fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão em Dados de Treino e Validação.\n",
    "X_falha_treino, X_falha_val, y_falha_treino, y_falha_val = train_test_split(X_falha, y_falha, test_size = 0.25, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "10277491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a função que treina e avalia o modelo multiclasse\n",
    "def train_and_score_multiclass_model(algoritmo, X_treino, y_treino, X_teste, y_teste, nome = None, version = '1', auc = False):\n",
    "    # Cria o modelo\n",
    "    modelo = algoritmo\n",
    "    \n",
    "    # Treinamento\n",
    "    start = time.time()\n",
    "    modelo.fit(X_treino, y_treino)\n",
    "    end = time.time()\n",
    "    print('Tempo de Treinamento do Modelo:', end - start)\n",
    "    \n",
    "    # Fazendo as previsões para o dataset de teste\n",
    "    previsoes = modelo.predict(X_teste)\n",
    "    \n",
    "    # Avaliação do modelo\n",
    "    # Matriz de confusão\n",
    "    print('\\nMatriz de confusão\\n', confusion_matrix(y_teste, previsoes))\n",
    "    \n",
    "    # Dicionário de métricas e metadados\n",
    "    dict_model =   {'Modelo': nome,\n",
    "                    'Versão': version,\n",
    "                    'Precision':precision_score(y_teste, previsoes, average = 'weighted', zero_division=0),\n",
    "                    'Recall':recall_score(y_teste, previsoes, average = 'weighted', zero_division=0),\n",
    "                    'F1 Score':f1_score(y_teste, previsoes, average = 'weighted', zero_division=0),\n",
    "                    'Acurácia':accuracy_score(y_teste, previsoes)}\n",
    "    \n",
    "    if auc:\n",
    "        dict_model['ROC AUC'] = roc_auc_score(y_teste, previsoes, multi_class='ovr')\n",
    "        \n",
    "    return modelo, dict_model, previsoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "26efaa0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de Treinamento do Modelo: 0.003000020980834961\n",
      "\n",
      "Matriz de confusão\n",
      " [[16  0  2  0  0  0]\n",
      " [ 2  9  1  0  0  2]\n",
      " [ 2  0  8  0  0  0]\n",
      " [ 2  0  1  5  0  0]\n",
      " [ 1  1  0  0  0  0]\n",
      " [ 1  5  0  0  0  3]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Modelo': 'KNN',\n",
       " 'Versão': 'Multiclass Classification 1',\n",
       " 'Precision': 0.6633879781420764,\n",
       " 'Recall': 0.6721311475409836,\n",
       " 'F1 Score': 0.6506173306625539,\n",
       " 'Acurácia': 0.6721311475409836}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo 1 - KNN - Multiclasse\n",
    "modelo1_multi, dict1, previsoes1 = train_and_score_multiclass_model(KNeighborsClassifier(), X_falha_treino, y_falha_treino, \n",
    "                                                                       X_falha_val, y_falha_val,\n",
    "                                                                       nome = 'KNN',\n",
    "                                                                       version = 'Multiclass Classification 1')\n",
    "dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bca94286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de Treinamento do Modelo: 0.0029997825622558594\n",
      "\n",
      "Matriz de confusão\n",
      " [[14  0  4  0  0  0]\n",
      " [ 2  5  5  1  0  1]\n",
      " [ 0  0  9  0  1  0]\n",
      " [ 0  1  2  5  0  0]\n",
      " [ 0  0  1  0  1  0]\n",
      " [ 0  1  3  0  0  5]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Modelo': 'Naive Bayes',\n",
       " 'Versão': 'Multiclass Classification 1',\n",
       " 'Precision': 0.7322404371584699,\n",
       " 'Recall': 0.639344262295082,\n",
       " 'F1 Score': 0.6475180236028839,\n",
       " 'Acurácia': 0.639344262295082}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo 2 - Naive Bayes - Multiclasse\n",
    "modelo2_multi, dict2, previsoes2 = train_and_score_multiclass_model(GaussianNB(), X_falha_treino, y_falha_treino, \n",
    "                                                                       X_falha_val, y_falha_val,\n",
    "                                                                       nome = 'Naive Bayes',\n",
    "                                                                       version = 'Multiclass Classification 1')\n",
    "dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3e03b252",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de Treinamento do Modelo: 0.004003286361694336\n",
      "\n",
      "Matriz de confusão\n",
      " [[16  0  1  1  0  0]\n",
      " [ 1  8  0  0  2  3]\n",
      " [ 1  0  9  0  0  0]\n",
      " [ 2  0  1  5  0  0]\n",
      " [ 0  0  0  0  2  0]\n",
      " [ 0  4  0  0  1  4]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Modelo': 'Decision Tree Classifier',\n",
       " 'Versão': 'Multiclass Classification 1',\n",
       " 'Precision': 0.7299127102405789,\n",
       " 'Recall': 0.7213114754098361,\n",
       " 'F1 Score': 0.716423783291773,\n",
       " 'Acurácia': 0.7213114754098361}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo 3 - Decision Tree - Multiclasse\n",
    "modelo3_multi, dict3, previsoes3 = train_and_score_multiclass_model(DecisionTreeClassifier(), X_falha_treino, y_falha_treino, \n",
    "                                                                       X_falha_val, y_falha_val,\n",
    "                                                                       nome = 'Decision Tree Classifier',\n",
    "                                                                       version = 'Multiclass Classification 1')\n",
    "dict3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d67c9eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de Treinamento do Modelo: 0.1880030632019043\n",
      "\n",
      "Matriz de confusão\n",
      " [[17  0  1  0  0  0]\n",
      " [ 0 12  0  1  0  1]\n",
      " [ 0  0 10  0  0  0]\n",
      " [ 0  0  1  7  0  0]\n",
      " [ 0  2  0  0  0  0]\n",
      " [ 0  5  0  0  1  3]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Modelo': 'Random Forest Classifier',\n",
       " 'Versão': 'Multiclass Classification 1',\n",
       " 'Precision': 0.8020563704342824,\n",
       " 'Recall': 0.8032786885245902,\n",
       " 'F1 Score': 0.7854473395457002,\n",
       " 'Acurácia': 0.8032786885245902}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo 4 - Decision Tree - Multiclasse\n",
    "modelo4_multi, dict4, previsoes4 = train_and_score_multiclass_model(RandomForestClassifier(), X_falha_treino, y_falha_treino, \n",
    "                                                                       X_falha_val, y_falha_val,\n",
    "                                                                       nome = 'Random Forest Classifier',\n",
    "                                                                       version = 'Multiclass Classification 1')\n",
    "dict4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3c07325f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de Treinamento do Modelo: 0.005003452301025391\n",
      "\n",
      "Matriz de confusão\n",
      " [[18  0  0  0  0  0]\n",
      " [ 2 10  1  0  0  1]\n",
      " [ 2  0  8  0  0  0]\n",
      " [ 1  0  3  4  0  0]\n",
      " [ 0  2  0  0  0  0]\n",
      " [ 1  6  0  0  0  2]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Modelo': 'SVM Classifier',\n",
       " 'Versão': 'Multiclass Classification 1',\n",
       " 'Precision': 0.6876138433515483,\n",
       " 'Recall': 0.6885245901639344,\n",
       " 'F1 Score': 0.6522070825349515,\n",
       " 'Acurácia': 0.6885245901639344}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo 5 - SVM Classifier - Multiclasse\n",
    "modelo5_multi, dict5, previsoes5 = train_and_score_multiclass_model(svm.SVC(), X_falha_treino, y_falha_treino, \n",
    "                                                                       X_falha_val, y_falha_val,\n",
    "                                                                       nome = 'SVM Classifier',\n",
    "                                                                       version = 'Multiclass Classification 1')\n",
    "dict5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f76a8c80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de Treinamento do Modelo: 0.10199832916259766\n",
      "\n",
      "Matriz de confusão\n",
      " [[17  0  1  0  0  0]\n",
      " [ 0  8  1  1  2  2]\n",
      " [ 0  0 10  0  0  0]\n",
      " [ 0  0  1  7  0  0]\n",
      " [ 0  1  0  0  1  0]\n",
      " [ 0  6  0  0  1  2]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Modelo': 'XGBoost Classifier',\n",
       " 'Versão': 'Multiclass Classification 1',\n",
       " 'Precision': 0.7403110550651535,\n",
       " 'Recall': 0.7377049180327869,\n",
       " 'F1 Score': 0.7269082266649056,\n",
       " 'Acurácia': 0.7377049180327869}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo 6 - SVM Classifier - Multiclasse\n",
    "modelo6_multi, dict6, previsoes6 = train_and_score_multiclass_model(XGBClassifier(), X_falha_treino, y_falha_treino, \n",
    "                                                                       X_falha_val, y_falha_val,\n",
    "                                                                       nome = 'XGBoost Classifier',\n",
    "                                                                       version = 'Multiclass Classification 1')\n",
    "dict6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "eaab7dfe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dict1</th>\n",
       "      <th>dict2</th>\n",
       "      <th>dict3</th>\n",
       "      <th>dict4</th>\n",
       "      <th>dict5</th>\n",
       "      <th>dict6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Modelo</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>SVM Classifier</td>\n",
       "      <td>XGBoost Classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Versão</th>\n",
       "      <td>Multiclass Classification 1</td>\n",
       "      <td>Multiclass Classification 1</td>\n",
       "      <td>Multiclass Classification 1</td>\n",
       "      <td>Multiclass Classification 1</td>\n",
       "      <td>Multiclass Classification 1</td>\n",
       "      <td>Multiclass Classification 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.73224</td>\n",
       "      <td>0.73224</td>\n",
       "      <td>0.729913</td>\n",
       "      <td>0.802056</td>\n",
       "      <td>0.687614</td>\n",
       "      <td>0.740311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.639344</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>0.721311</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>0.737705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.647518</td>\n",
       "      <td>0.647518</td>\n",
       "      <td>0.716424</td>\n",
       "      <td>0.785447</td>\n",
       "      <td>0.652207</td>\n",
       "      <td>0.726908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acurácia</th>\n",
       "      <td>0.639344</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>0.721311</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>0.737705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 dict1                        dict2  \\\n",
       "Modelo                     Naive Bayes                  Naive Bayes   \n",
       "Versão     Multiclass Classification 1  Multiclass Classification 1   \n",
       "Precision                      0.73224                      0.73224   \n",
       "Recall                        0.639344                     0.639344   \n",
       "F1 Score                      0.647518                     0.647518   \n",
       "Acurácia                      0.639344                     0.639344   \n",
       "\n",
       "                                 dict3                        dict4  \\\n",
       "Modelo        Decision Tree Classifier     Random Forest Classifier   \n",
       "Versão     Multiclass Classification 1  Multiclass Classification 1   \n",
       "Precision                     0.729913                     0.802056   \n",
       "Recall                        0.721311                     0.803279   \n",
       "F1 Score                      0.716424                     0.785447   \n",
       "Acurácia                      0.721311                     0.803279   \n",
       "\n",
       "                                 dict5                        dict6  \n",
       "Modelo                  SVM Classifier           XGBoost Classifier  \n",
       "Versão     Multiclass Classification 1  Multiclass Classification 1  \n",
       "Precision                     0.687614                     0.740311  \n",
       "Recall                        0.688525                     0.737705  \n",
       "F1 Score                      0.652207                     0.726908  \n",
       "Acurácia                      0.688525                     0.737705  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumo_multi1 = pd.DataFrame({'dict1':pd.Series(dict1),\n",
    "                           'dict2':pd.Series(dict2),\n",
    "                           'dict3':pd.Series(dict3),\n",
    "                           'dict4':pd.Series(dict4),\n",
    "                           'dict5':pd.Series(dict5),\n",
    "                           'dict6':pd.Series(dict6)})\n",
    "\n",
    "resumo_multi1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993f845b",
   "metadata": {},
   "source": [
    "Dentre os modelos utilizados para a classificação multiclasse, o Random Forest foi o que melhor respondeu. Vamos utilizar esse modelo como base e fazer um GridSearchCV para encontrar os melhores hiperparâmetros para ele e tentar melhorar a resposta final do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d0233b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "?RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "32ac1061",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo4_multi.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9bb66e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV executou em 5897.80 segundos para todas as combinações de candidatos a parâmetros do modelo.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.30959868, 0.51120243, 0.77119765, 1.01400032, 1.32159672,\n",
       "        0.26460352, 0.51119556, 0.87999935, 1.01439519, 1.25679469,\n",
       "        0.25499749, 0.51479373, 0.78839779, 1.02199526, 1.26219759,\n",
       "        0.25420027, 0.50780053, 0.75219383, 1.04119668, 1.27639465,\n",
       "        0.26059732, 0.50199456, 0.76259608, 1.01359982, 1.25839386,\n",
       "        0.2895947 , 0.56679945, 0.87979264, 1.14119711, 1.42579489,\n",
       "        0.28539982, 0.5697916 , 0.85379596, 1.17299676, 1.42799358,\n",
       "        0.29140034, 0.56539512, 0.85899606, 1.13079505, 1.41759601,\n",
       "        0.30719471, 0.57119637, 0.85419836, 1.14219708, 1.42019653,\n",
       "        0.28959455, 0.55919771, 0.89839993, 1.13459911, 1.41919241,\n",
       "        0.53540316, 0.89439726, 1.51279554, 1.62639656, 1.59759746,\n",
       "        0.31679578, 0.64059434, 0.98339567, 1.27779784, 1.62859583,\n",
       "        0.31739573, 0.63079414, 0.94859619, 1.25399876, 1.59019361,\n",
       "        0.32419357, 0.63419747, 0.97399378, 1.26399322, 1.56779485,\n",
       "        0.31399541, 0.63719673, 0.94199419, 1.25979557, 1.60519633,\n",
       "        0.35159378, 0.7547967 , 1.15719242, 1.53599191, 1.72479715,\n",
       "        0.35639882, 0.72579565, 1.03779778, 1.39099674, 1.73119159,\n",
       "        0.34339395, 0.69539413, 1.03079643, 1.40599637, 1.71399479,\n",
       "        0.34319468, 0.6835979 , 1.03399329, 1.3785996 , 1.73659744,\n",
       "        0.34459772, 0.68739529, 1.02899394, 1.36299791, 1.7093925 ,\n",
       "        0.37599621, 0.79459858, 1.11659608, 1.50899634, 1.88299994,\n",
       "        0.37920108, 0.74759598, 1.15099697, 1.48459573, 1.88479681,\n",
       "        0.36979351, 0.73779669, 1.14539714, 1.46659851, 1.86939788,\n",
       "        0.36999707, 0.74079318, 1.09979582, 1.54219933, 1.85159712,\n",
       "        0.36899457, 0.72659545, 1.08259397, 1.4997942 , 1.82399411,\n",
       "        0.39939647, 0.80519419, 1.20019059, 1.61239762, 2.01019702,\n",
       "        0.39379673, 0.79439497, 1.17819548, 1.57099504, 1.9925983 ,\n",
       "        0.39359684, 0.78559618, 1.17819357, 1.56719356, 1.95299497,\n",
       "        0.42159686, 0.77039356, 1.15679641, 1.5383925 , 1.93039346,\n",
       "        0.38879714, 0.79739766, 1.17159648, 1.5337966 , 1.89739561,\n",
       "        0.42359734, 0.83039651, 1.26039343, 1.68139596, 2.09159727,\n",
       "        0.40579386, 0.81559577, 1.2251955 , 1.65919509, 2.03099523,\n",
       "        0.40519938, 0.80059581, 1.21419568, 1.61059642, 2.01759815,\n",
       "        0.39619393, 0.79059472, 1.21219726, 1.58459573, 1.99079142,\n",
       "        0.39339581, 0.78899622, 1.17839518, 1.56379428, 1.95979381,\n",
       "        0.44839702, 0.86839609, 1.28599501, 1.70779901, 2.1467988 ,\n",
       "        0.41619601, 0.84179511, 1.24699507, 1.66659594, 2.12359967,\n",
       "        0.41159644, 0.82179503, 1.23439517, 1.64519157, 2.05080037,\n",
       "        0.40259342, 0.8057982 , 1.21399546, 1.64439731, 2.02099686,\n",
       "        0.40639639, 0.79299455, 1.2035924 , 1.63779569, 1.99999666,\n",
       "        0.43959451, 0.90859241, 1.33459969, 1.79119859, 2.23439713,\n",
       "        0.43419785, 0.8569963 , 1.29599514, 1.71220021, 2.27500091,\n",
       "        0.46199327, 0.90779662, 1.32859054, 1.69319253, 2.09359937,\n",
       "        0.41899552, 0.81779156, 1.260394  , 1.65019403, 2.06239963,\n",
       "        0.40879388, 0.82139463, 1.23159533, 1.62139955, 2.03919806,\n",
       "        0.30060024, 0.56319718, 0.82399788, 1.09299774, 1.3523973 ,\n",
       "        0.27439585, 0.53979831, 0.84479718, 1.0859983 , 1.38459501,\n",
       "        0.27019792, 0.54259491, 0.81619396, 1.12179661, 1.35619864,\n",
       "        0.28120155, 0.54439878, 0.8209991 , 1.07739692, 1.36279693,\n",
       "        0.27599988, 0.55040159, 0.82119856, 1.08699832, 1.35579586,\n",
       "        0.35      , 0.62839699, 0.94859638, 1.2447978 , 1.57139535,\n",
       "        0.31019702, 0.6233964 , 0.98959551, 1.25340137, 1.5513979 ,\n",
       "        0.31239843, 0.62319593, 0.99559712, 1.24640007, 1.55919857,\n",
       "        0.3127923 , 0.62419591, 0.95379829, 1.24959574, 1.56159859,\n",
       "        0.31799822, 0.62359672, 0.91959534, 1.26519647, 1.55759263,\n",
       "        0.3515976 , 0.70839949, 1.04999986, 1.41139774, 1.7663981 ,\n",
       "        0.34979596, 0.71519465, 1.08679852, 1.41459222, 1.77539158,\n",
       "        0.35239682, 0.69659624, 1.04359603, 1.40619373, 1.75039597,\n",
       "        0.34439778, 0.69679732, 1.04879818, 1.42999659, 1.72839665,\n",
       "        0.34759951, 0.69199843, 1.03719397, 1.39659214, 1.73779702,\n",
       "        0.38979378, 0.77859592, 1.16859465, 1.55879316, 1.91839433,\n",
       "        0.38859515, 0.75879469, 1.13779664, 1.51719751, 1.89399805,\n",
       "        0.38419609, 0.75299635, 1.16959939, 1.50319118, 1.88419609,\n",
       "        0.38299341, 0.748599  , 1.12099676, 1.49199271, 1.85259199,\n",
       "        0.37679501, 0.7687933 , 1.12139363, 1.49220014, 1.84799395,\n",
       "        0.41799731, 0.8109982 , 1.20919547, 1.62719431, 2.06619596,\n",
       "        0.39439578, 0.81579185, 1.20859451, 1.58719792, 1.99159603,\n",
       "        0.39119811, 0.78239708, 1.18299561, 1.59879189, 1.96579418,\n",
       "        0.3909955 , 0.78199935, 1.17119017, 1.55719557, 1.93999681,\n",
       "        0.395997  , 0.76939487, 1.15259399, 1.57339272, 1.92459998,\n",
       "        0.41959701, 0.83619809, 1.26139755, 1.66899762, 2.08839984,\n",
       "        0.41279626, 0.85279422, 1.31599188, 1.79559479, 2.09199653,\n",
       "        0.41159611, 0.81599183, 1.21019669, 1.62219477, 2.05759687,\n",
       "        0.39799142, 0.79699435, 1.19839697, 1.59179654, 1.99499741,\n",
       "        0.39379325, 0.79159503, 1.18559527, 1.60019555, 1.99299679,\n",
       "        0.4277925 , 0.8563971 , 1.27859817, 1.71679931, 2.14139729,\n",
       "        0.4165925 , 0.83519683, 1.28100042, 1.67719717, 2.0907959 ,\n",
       "        0.41059432, 0.83499694, 1.23939619, 1.63479362, 2.08919663,\n",
       "        0.40759563, 0.81499548, 1.21539364, 1.61519413, 2.02059498,\n",
       "        0.42759571, 0.81139569, 1.19419584, 1.58759713, 2.03319407,\n",
       "        0.43779869, 0.86439624, 1.29599981, 1.73499522, 2.15659814,\n",
       "        0.4207942 , 0.84559522, 1.28979392, 1.68759513, 2.10739255,\n",
       "        0.41039715, 0.82499785, 1.23619609, 1.64439607, 2.05619869,\n",
       "        0.43279195, 0.81979766, 1.21659961, 1.617594  , 2.01939449,\n",
       "        0.41159701, 0.79499555, 1.2109951 , 1.6091969 , 2.04879861,\n",
       "        0.44659452, 0.87719574, 1.32859955, 1.77139893, 2.20199771,\n",
       "        0.4319943 , 0.85379639, 1.30359144, 1.69839373, 2.1215992 ,\n",
       "        0.42019587, 0.83979373, 1.24879408, 1.67059317, 2.07179465,\n",
       "        0.43719559, 0.82719493, 1.22779655, 1.63679562, 2.04639239,\n",
       "        0.40559564, 0.83079572, 1.21119609, 1.62239618, 2.05539784,\n",
       "        0.2425961 , 0.48079638, 0.71839352, 0.95279393, 1.18519592,\n",
       "        0.23939614, 0.47279868, 0.73059649, 0.9508009 , 1.17859421,\n",
       "        0.24139576, 0.47920036, 0.71959534, 1.02319546, 1.19419322,\n",
       "        0.24719706, 0.48320022, 0.7085959 , 0.94739842, 1.18559537,\n",
       "        0.24499826, 0.47479792, 0.71939869, 0.94819527, 1.17439814,\n",
       "        0.27739964, 0.57999544, 0.85859609, 1.11600018, 1.3987968 ,\n",
       "        0.27759519, 0.55459156, 0.83759608, 1.11039929, 1.3941968 ,\n",
       "        0.29479661, 0.55979748, 0.83039255, 1.12839475, 1.39959345,\n",
       "        0.28239379, 0.55319462, 0.83539801, 1.10659246, 1.39239984,\n",
       "        0.27919459, 0.55859408, 0.84179792, 1.10739841, 1.39799638,\n",
       "        0.33039699, 0.66359034, 1.06419377, 1.4031971 , 1.67839327,\n",
       "        0.32379351, 0.63699703, 0.95739627, 1.27839599, 1.58879652,\n",
       "        0.32279558, 0.67519679, 0.95219707, 1.27959518, 1.59799495,\n",
       "        0.31719451, 0.64019475, 0.95279574, 1.28039436, 1.6193944 ,\n",
       "        0.32319584, 0.63359237, 0.97619491, 1.26519504, 1.59719572,\n",
       "        0.36019554, 0.72039552, 1.07619982, 1.44099832, 1.79299927,\n",
       "        0.36379828, 0.70999641, 1.1065969 , 1.43639221, 1.7867928 ,\n",
       "        0.36119509, 0.71239605, 1.07759476, 1.42839408, 1.77319326,\n",
       "        0.35239453, 0.71119523, 1.09359832, 1.42219663, 1.77439837,\n",
       "        0.35319419, 0.71499491, 1.07779603, 1.44019556, 1.81719298,\n",
       "        0.40899434, 0.8013989 , 1.23299541, 1.59719353, 2.00879831,\n",
       "        0.39439559, 0.81139593, 1.19799471, 1.57159467, 2.03779702,\n",
       "        0.39839659, 0.79739757, 1.19559302, 1.59339247, 1.9659955 ,\n",
       "        0.399998  , 0.78779287, 1.1777945 , 1.56279206, 2.00779071,\n",
       "        0.39539762, 0.78839641, 1.16759677, 1.56919665, 1.95459528,\n",
       "        0.43259621, 0.88919778, 1.29959869, 1.76179643, 2.15739756,\n",
       "        0.43299413, 0.85119596, 1.30259762, 1.70439329, 2.14279828,\n",
       "        0.42959867, 0.87759218, 1.29479604, 1.70499191, 2.12319918,\n",
       "        0.4159956 , 0.82839465, 1.26799588, 1.6757987 , 2.11519637,\n",
       "        0.41739569, 0.83399529, 1.26319699, 1.66139278, 2.07899456,\n",
       "        0.455795  , 0.91419549, 1.36399794, 1.85359483, 2.28039646,\n",
       "        0.44759521, 0.89839745, 1.36859488, 1.81339145, 2.25659776,\n",
       "        0.45119219, 0.88579402, 1.32599616, 1.7853972 , 2.21019664,\n",
       "        0.44379463, 0.8875988 , 1.34499507, 1.80259886, 2.21119947,\n",
       "        0.45319681, 0.87999563, 1.32739325, 1.76279302, 2.21299601,\n",
       "        0.47379746, 0.96599493, 1.42859874, 1.90539994, 2.39420009,\n",
       "        0.47379637, 0.93279657, 1.39239616, 1.87919283, 2.48799386,\n",
       "        0.49778953, 0.98359618, 1.38179555, 1.87839599, 2.31679907,\n",
       "        0.45659256, 0.94359512, 1.37759075, 1.8391953 , 2.27659488,\n",
       "        0.45759602, 0.90079446, 1.3539979 , 1.80239239, 2.29079714,\n",
       "        0.50899415, 1.00219874, 1.54079652, 2.02439804, 2.55519967,\n",
       "        0.49439564, 1.01859517, 1.47759604, 1.98019681, 2.46099768,\n",
       "        0.4823967 , 0.96519551, 1.44199777, 1.96739335, 2.43520007,\n",
       "        0.48719578, 0.95339537, 1.44699354, 1.95979705, 2.38699541,\n",
       "        0.50539455, 0.94879642, 1.42819328, 1.90099831, 2.38399987,\n",
       "        0.26439619, 0.52459407, 0.78779736, 1.04839854, 1.36440024,\n",
       "        0.2639957 , 0.52339416, 0.78459792, 1.04139543, 1.30759487,\n",
       "        0.2693964 , 0.52459798, 0.80759869, 1.04799628, 1.30759854,\n",
       "        0.26379666, 0.52639198, 0.77919827, 1.1135911 , 1.31079688,\n",
       "        0.27760005, 0.52659888, 0.78959661, 1.04819341, 1.31760025,\n",
       "        0.32839384, 0.63119392, 0.94679489, 1.2533947 , 1.59999871,\n",
       "        0.31859646, 0.62519536, 0.94019604, 1.26859522, 1.5773984 ,\n",
       "        0.3201962 , 0.62419305, 0.93619552, 1.24299707, 1.57219796,\n",
       "        0.32819829, 0.64559703, 0.93719172, 1.24799705, 1.56519465,\n",
       "        0.31339464, 0.63099589, 0.92260046, 1.24479604, 1.5627954 ,\n",
       "        0.36719327, 0.73459573, 1.13079238, 1.46999621, 1.843398  ,\n",
       "        0.36579332, 0.73119884, 1.08819618, 1.45299459, 1.83059921,\n",
       "        0.36079378, 0.75999355, 1.08879313, 1.43479824, 1.82219653,\n",
       "        0.35759435, 0.72659564, 1.09579344, 1.44259367, 1.80739398,\n",
       "        0.38579488, 0.73119497, 1.07759466, 1.44739566, 1.80799198,\n",
       "        0.41459656, 0.8197927 , 1.25239773, 1.65279117, 2.07639675,\n",
       "        0.41059418, 0.81579843, 1.23399687, 1.62179556, 2.04259439,\n",
       "        0.40839748, 0.81239405, 1.22159796, 1.64099607, 2.0179935 ,\n",
       "        0.40539365, 0.81399741, 1.20179925, 1.60819311, 2.00259376,\n",
       "        0.40419493, 0.81079688, 1.23759871, 1.70299692, 2.13418775,\n",
       "        0.4445961 , 0.8925961 , 1.33479481, 1.77459784, 2.25859513,\n",
       "        0.43959556, 0.8889987 , 1.32079306, 1.76419744, 2.18959775,\n",
       "        0.43459744, 0.87719445, 1.30499272, 1.80139594, 2.17879777,\n",
       "        0.43419528, 0.86599622, 1.3023984 , 1.72420025, 2.14699554,\n",
       "        0.43539586, 0.8673955 , 1.30799799, 1.7111949 , 2.14819789,\n",
       "        0.46799417, 0.93239512, 1.39999437, 1.86679974, 2.3653976 ,\n",
       "        0.46639638, 0.93379459, 1.39619632, 1.85719419, 2.34199424,\n",
       "        0.45399718, 0.91619473, 1.3958005 , 1.83359489, 2.28819351,\n",
       "        0.45859256, 0.91179595, 1.36599731, 1.81239514, 2.28539891,\n",
       "        0.45099521, 0.90319648, 1.34499478, 1.79219799, 2.25719962,\n",
       "        0.48839936, 0.96419449, 1.49119577, 1.96799674, 2.4133985 ,\n",
       "        0.4811944 , 0.96139774, 1.44719296, 1.90779729, 2.39480076,\n",
       "        0.47319636, 0.93619246, 1.40119643, 1.87799606, 2.35739455,\n",
       "        0.46699872, 0.93699694, 1.41940017, 1.84299679, 2.29619308,\n",
       "        0.45559759, 0.93819919, 1.38059468, 1.83779163, 2.31159239,\n",
       "        0.49359727, 0.99099727, 1.4891973 , 1.98959837, 2.48979969,\n",
       "        0.48459411, 0.96139545, 1.4671905 , 1.93999772, 2.39899764,\n",
       "        0.47779627, 0.95219679, 1.42459855, 1.87859273, 2.39039717,\n",
       "        0.4687963 , 0.93199224, 1.39279637, 2.04999442, 2.35539699,\n",
       "        0.45639768, 0.9175952 , 1.40479741, 1.83939734, 2.30239511,\n",
       "        0.50959754, 1.01739841, 1.52459803, 2.02819762, 2.57880201,\n",
       "        0.48679738, 0.9725956 , 1.47839675, 1.9671937 , 2.44859848,\n",
       "        0.47659202, 0.96299672, 1.48619385, 2.05059896, 2.46279984,\n",
       "        0.47719378, 0.95759859, 1.41939745, 1.89319367, 2.38719883,\n",
       "        0.46419663, 0.9421936 , 1.39059505, 1.85719242, 2.32079282]),\n",
       " 'std_fit_time': array([0.03052141, 0.00827854, 0.01016506, 0.01832211, 0.07045653,\n",
       "        0.01074601, 0.00966363, 0.11865125, 0.01596854, 0.02158254,\n",
       "        0.00576209, 0.00844785, 0.02806441, 0.01002246, 0.00893302,\n",
       "        0.00754485, 0.00365383, 0.00685199, 0.05476229, 0.01533065,\n",
       "        0.01187849, 0.00517601, 0.00930867, 0.01711985, 0.00989084,\n",
       "        0.00449749, 0.00664574, 0.04264335, 0.01184113, 0.03046773,\n",
       "        0.00615181, 0.01123001, 0.01292045, 0.05107646, 0.00761733,\n",
       "        0.00733691, 0.01351772, 0.01496734, 0.01405024, 0.02453389,\n",
       "        0.01860451, 0.02345116, 0.01274993, 0.00982808, 0.01975244,\n",
       "        0.00371679, 0.00538239, 0.05288822, 0.00602309, 0.01937384,\n",
       "        0.21976553, 0.06123417, 0.10354284, 0.25151971, 0.03167003,\n",
       "        0.00598004, 0.00618378, 0.06682895, 0.01273497, 0.08071575,\n",
       "        0.00574904, 0.0066752 , 0.01312303, 0.00712404, 0.03331972,\n",
       "        0.00594863, 0.00868294, 0.04789905, 0.01832041, 0.01773732,\n",
       "        0.00701813, 0.00643161, 0.01344575, 0.01710549, 0.03926285,\n",
       "        0.01348274, 0.02454173, 0.01686518, 0.01046887, 0.0133616 ,\n",
       "        0.02138064, 0.04927437, 0.00960101, 0.01049081, 0.01915766,\n",
       "        0.00412828, 0.00568043, 0.03303375, 0.05016118, 0.01605168,\n",
       "        0.00676316, 0.0077103 , 0.02154794, 0.0172997 , 0.07315746,\n",
       "        0.01157071, 0.00714246, 0.01598682, 0.0110822 , 0.02768464,\n",
       "        0.0041482 , 0.04277083, 0.01234104, 0.01226563, 0.02893976,\n",
       "        0.00574363, 0.00300566, 0.02918935, 0.02595339, 0.06291298,\n",
       "        0.00371167, 0.01271867, 0.03724444, 0.01735999, 0.01778268,\n",
       "        0.00832072, 0.02638118, 0.01116207, 0.07339876, 0.0184921 ,\n",
       "        0.00712827, 0.00977084, 0.00954073, 0.05237077, 0.00944683,\n",
       "        0.00450115, 0.01195708, 0.01449602, 0.04610077, 0.03144018,\n",
       "        0.00614326, 0.00542475, 0.01641062, 0.01844666, 0.06642382,\n",
       "        0.00135815, 0.01103733, 0.02348372, 0.0187966 , 0.01633558,\n",
       "        0.02764826, 0.00997179, 0.00980739, 0.01227239, 0.01519972,\n",
       "        0.00563662, 0.03626006, 0.0720547 , 0.01412038, 0.01705751,\n",
       "        0.00972953, 0.00781392, 0.03954374, 0.01439013, 0.02508096,\n",
       "        0.00552762, 0.00786188, 0.01831269, 0.05269318, 0.03531012,\n",
       "        0.01045604, 0.00717395, 0.01154512, 0.01103287, 0.01846455,\n",
       "        0.00716594, 0.01190951, 0.05684873, 0.0367935 , 0.02869978,\n",
       "        0.00749944, 0.00981794, 0.01818132, 0.02067164, 0.02771533,\n",
       "        0.02207967, 0.02294136, 0.01880349, 0.02124859, 0.02589731,\n",
       "        0.00439845, 0.02102519, 0.02229756, 0.02059822, 0.05189453,\n",
       "        0.00956311, 0.02309575, 0.01357372, 0.03108928, 0.02628576,\n",
       "        0.00427196, 0.01729257, 0.01955499, 0.04007529, 0.02425927,\n",
       "        0.01054012, 0.01181198, 0.0115007 , 0.05645051, 0.03335987,\n",
       "        0.00719889, 0.06730421, 0.01442834, 0.02782534, 0.02038265,\n",
       "        0.00998793, 0.01567234, 0.03183903, 0.04117182, 0.09671688,\n",
       "        0.00572472, 0.02550255, 0.06124011, 0.02322409, 0.03400414,\n",
       "        0.01084299, 0.01364439, 0.05502727, 0.04644237, 0.03150186,\n",
       "        0.01337959, 0.0166442 , 0.04788306, 0.02469562, 0.04919314,\n",
       "        0.02723008, 0.03702818, 0.01171275, 0.01190135, 0.00863782,\n",
       "        0.00412406, 0.01032121, 0.03997132, 0.00638659, 0.02331344,\n",
       "        0.00402318, 0.00649674, 0.00810922, 0.05023296, 0.02159122,\n",
       "        0.00945491, 0.00377659, 0.01010094, 0.00801427, 0.01651017,\n",
       "        0.0050605 , 0.01262888, 0.01337938, 0.01402931, 0.02099193,\n",
       "        0.01963611, 0.00771096, 0.01608368, 0.00962063, 0.01030749,\n",
       "        0.00248149, 0.00900475, 0.04418196, 0.01635467, 0.01184224,\n",
       "        0.00516428, 0.00773179, 0.05544875, 0.01746432, 0.02322277,\n",
       "        0.00541557, 0.0146869 , 0.02018473, 0.01664651, 0.01409211,\n",
       "        0.00822074, 0.01309379, 0.01345517, 0.06202737, 0.02802059,\n",
       "        0.00900306, 0.00640335, 0.01682734, 0.01988765, 0.02206074,\n",
       "        0.00679418, 0.0280097 , 0.03840238, 0.0084986 , 0.02861145,\n",
       "        0.00989338, 0.00900033, 0.01948263, 0.02434657, 0.01606868,\n",
       "        0.00706114, 0.01256063, 0.01535277, 0.04639065, 0.01580572,\n",
       "        0.00307171, 0.00777255, 0.01743905, 0.02851647, 0.02088601,\n",
       "        0.00563864, 0.00591674, 0.03340831, 0.04352445, 0.01890899,\n",
       "        0.00939377, 0.0071389 , 0.00688473, 0.00893218, 0.0120505 ,\n",
       "        0.00552909, 0.00583041, 0.03998272, 0.01581752, 0.01619376,\n",
       "        0.00802672, 0.01434829, 0.01353427, 0.02848004, 0.01089208,\n",
       "        0.00945265, 0.04155104, 0.00361301, 0.02136793, 0.0197372 ,\n",
       "        0.00797929, 0.0076936 , 0.00584363, 0.01809413, 0.08383856,\n",
       "        0.00475778, 0.01997548, 0.01874601, 0.01202632, 0.02608406,\n",
       "        0.00549219, 0.00909014, 0.00481563, 0.04052303, 0.02963087,\n",
       "        0.00839337, 0.01136733, 0.00818538, 0.01483705, 0.0211933 ,\n",
       "        0.01362536, 0.00842874, 0.01063251, 0.05226859, 0.01354631,\n",
       "        0.0060847 , 0.01384697, 0.01879924, 0.01288365, 0.01678608,\n",
       "        0.00705592, 0.0401757 , 0.05577354, 0.01375095, 0.06633916,\n",
       "        0.01001391, 0.01760511, 0.01121722, 0.02088499, 0.07610101,\n",
       "        0.00532937, 0.00846577, 0.0084481 , 0.0142494 , 0.02959563,\n",
       "        0.00495586, 0.01403815, 0.0171745 , 0.06851403, 0.0214214 ,\n",
       "        0.00823117, 0.01092981, 0.00975093, 0.03045215, 0.02616338,\n",
       "        0.00615376, 0.01000939, 0.04891811, 0.01429069, 0.02734666,\n",
       "        0.00776156, 0.01992985, 0.022097  , 0.01030203, 0.05882206,\n",
       "        0.00758327, 0.00610038, 0.017289  , 0.0256599 , 0.01556677,\n",
       "        0.02501811, 0.02630944, 0.01302802, 0.00804115, 0.07945082,\n",
       "        0.00934721, 0.00458832, 0.01640605, 0.01992095, 0.02333738,\n",
       "        0.00534605, 0.00688901, 0.0565332 , 0.0164507 , 0.02212357,\n",
       "        0.00854615, 0.00914013, 0.0153052 , 0.01431701, 0.02316676,\n",
       "        0.02358675, 0.0108534 , 0.01757893, 0.01293943, 0.02059517,\n",
       "        0.0101919 , 0.01195042, 0.02126063, 0.01695573, 0.07469969,\n",
       "        0.0121785 , 0.01489271, 0.02434191, 0.01882217, 0.0105274 ,\n",
       "        0.00551347, 0.0142029 , 0.05270016, 0.02419123, 0.0188098 ,\n",
       "        0.00183388, 0.01373146, 0.01045559, 0.01293853, 0.00762241,\n",
       "        0.02111039, 0.00725158, 0.01856627, 0.02271084, 0.03821239,\n",
       "        0.00689167, 0.03827277, 0.02600254, 0.01539814, 0.06155532,\n",
       "        0.00484142, 0.01514525, 0.00714566, 0.01559068, 0.00751962,\n",
       "        0.00431629, 0.00828185, 0.01958479, 0.01641491, 0.01868465,\n",
       "        0.00588815, 0.00591128, 0.02021551, 0.1172707 , 0.00945761,\n",
       "        0.0061129 , 0.00687978, 0.01634128, 0.01059671, 0.01298996,\n",
       "        0.01052733, 0.00370618, 0.01528208, 0.01249777, 0.01328897,\n",
       "        0.00257786, 0.02759884, 0.03368405, 0.01756326, 0.02845129,\n",
       "        0.00492332, 0.01189312, 0.01546038, 0.01560097, 0.02594145,\n",
       "        0.01042114, 0.00727961, 0.0061847 , 0.06620785, 0.02048139,\n",
       "        0.00564728, 0.00652208, 0.00773975, 0.01853099, 0.01899263,\n",
       "        0.00673946, 0.00685867, 0.01116003, 0.00595064, 0.02109125,\n",
       "        0.01970332, 0.02391192, 0.01244626, 0.01966468, 0.11097198,\n",
       "        0.0077319 , 0.00494273, 0.00960404, 0.01494763, 0.01717574,\n",
       "        0.00890839, 0.06374892, 0.01068606, 0.01066938, 0.03491345,\n",
       "        0.00583922, 0.0083516 , 0.01190672, 0.01912771, 0.05851042,\n",
       "        0.00775975, 0.01331827, 0.0459325 , 0.00908328, 0.02494043,\n",
       "        0.00754907, 0.01149937, 0.00939144, 0.02027779, 0.02532206,\n",
       "        0.00679371, 0.00959198, 0.03925568, 0.02092333, 0.01801341,\n",
       "        0.00600875, 0.00553449, 0.00488125, 0.01083706, 0.01321327,\n",
       "        0.00471769, 0.00478806, 0.05661601, 0.0169156 , 0.02159503,\n",
       "        0.00563837, 0.00948592, 0.00998492, 0.0547404 , 0.04408055,\n",
       "        0.00753742, 0.00966916, 0.06077627, 0.01024237, 0.0342449 ,\n",
       "        0.00377375, 0.01650212, 0.02438062, 0.00917626, 0.05622495,\n",
       "        0.00932854, 0.01570299, 0.01703543, 0.01523521, 0.01987291,\n",
       "        0.00751177, 0.01076019, 0.00949739, 0.02107364, 0.05912608,\n",
       "        0.00417691, 0.01783852, 0.01001529, 0.01053308, 0.01385011,\n",
       "        0.00717393, 0.02467282, 0.01849328, 0.04318967, 0.01494909,\n",
       "        0.00920639, 0.01202279, 0.01516428, 0.01785241, 0.01975095,\n",
       "        0.01015679, 0.03656683, 0.00994967, 0.02542538, 0.03142728,\n",
       "        0.0050219 , 0.01024964, 0.02613765, 0.03128337, 0.04538302,\n",
       "        0.0104021 , 0.01080888, 0.02853369, 0.0114973 , 0.03103564,\n",
       "        0.00591306, 0.0196913 , 0.03769329, 0.04899201, 0.01681302,\n",
       "        0.00717201, 0.02083647, 0.02729445, 0.02791257, 0.04951043,\n",
       "        0.01274733, 0.01114146, 0.02558446, 0.01949123, 0.02362754,\n",
       "        0.01016836, 0.01541088, 0.01821751, 0.07754556, 0.03368074,\n",
       "        0.0144263 , 0.01889667, 0.01547367, 0.03962566, 0.03214568,\n",
       "        0.00837596, 0.04408884, 0.01483847, 0.03469197, 0.03668017,\n",
       "        0.00930537, 0.01511755, 0.02160404, 0.05408048, 0.09816627,\n",
       "        0.00936504, 0.03561513, 0.01500014, 0.02311283, 0.03051241,\n",
       "        0.00854695, 0.03932316, 0.04337815, 0.02945612, 0.05296115,\n",
       "        0.01354312, 0.02311146, 0.01782039, 0.02837432, 0.03921015,\n",
       "        0.0083202 , 0.02156241, 0.04558282, 0.04791378, 0.07390797,\n",
       "        0.01163567, 0.05015059, 0.05678527, 0.0494422 , 0.05831849,\n",
       "        0.01925098, 0.02415154, 0.03656663, 0.08016825, 0.07560005,\n",
       "        0.01719704, 0.02696623, 0.04240775, 0.07321702, 0.07608643,\n",
       "        0.0224414 , 0.03384397, 0.04504596, 0.04670038, 0.08265874,\n",
       "        0.00224658, 0.01025039, 0.00982857, 0.01430458, 0.06498278,\n",
       "        0.00756231, 0.00801045, 0.01570666, 0.01341277, 0.0084058 ,\n",
       "        0.00449849, 0.00508144, 0.02371235, 0.00880695, 0.01248181,\n",
       "        0.00299263, 0.01366051, 0.00757559, 0.06344076, 0.02772348,\n",
       "        0.01634143, 0.0091309 , 0.00523741, 0.02052414, 0.03582344,\n",
       "        0.02284245, 0.00856791, 0.01908333, 0.00512055, 0.04778927,\n",
       "        0.00445702, 0.00337072, 0.00648856, 0.01359119, 0.02028368,\n",
       "        0.00479397, 0.00553063, 0.00471039, 0.00922812, 0.01732599,\n",
       "        0.01290518, 0.0278374 , 0.01328844, 0.01793467, 0.0226736 ,\n",
       "        0.00542697, 0.0078216 , 0.01766843, 0.0106267 , 0.01175507,\n",
       "        0.00507649, 0.00686108, 0.03530131, 0.01627345, 0.01479918,\n",
       "        0.00624261, 0.01783729, 0.00823124, 0.0117494 , 0.02227589,\n",
       "        0.00444473, 0.04024659, 0.00974451, 0.00570454, 0.01455499,\n",
       "        0.0018538 , 0.01601216, 0.01966052, 0.00917653, 0.02019472,\n",
       "        0.02319989, 0.03121919, 0.01629028, 0.03373592, 0.01946635,\n",
       "        0.00241565, 0.01075872, 0.06218987, 0.00530912, 0.04989957,\n",
       "        0.00688851, 0.00955808, 0.01565932, 0.00813485, 0.01901267,\n",
       "        0.00454202, 0.00890993, 0.02040435, 0.04642245, 0.01946129,\n",
       "        0.00954174, 0.00726434, 0.01709321, 0.02443548, 0.02710608,\n",
       "        0.01268806, 0.00893042, 0.0430827 , 0.06052907, 0.05013409,\n",
       "        0.00677109, 0.01300339, 0.01047722, 0.02846007, 0.06255912,\n",
       "        0.00888862, 0.01129885, 0.01961116, 0.02290087, 0.01676679,\n",
       "        0.00560728, 0.0111972 , 0.00905569, 0.06081403, 0.01902887,\n",
       "        0.00487594, 0.00505847, 0.0119743 , 0.01153164, 0.01021984,\n",
       "        0.00426889, 0.01217346, 0.0451297 , 0.01914674, 0.02489634,\n",
       "        0.01188338, 0.00893732, 0.018621  , 0.0160185 , 0.06232121,\n",
       "        0.01194313, 0.02177738, 0.0057057 , 0.02611906, 0.05513665,\n",
       "        0.00632486, 0.006645  , 0.0563131 , 0.02399074, 0.02518333,\n",
       "        0.00683079, 0.00865934, 0.01321979, 0.01166927, 0.02767064,\n",
       "        0.01006117, 0.01092176, 0.01594121, 0.0175489 , 0.02779148,\n",
       "        0.00985186, 0.00116529, 0.0311541 , 0.04046048, 0.02872195,\n",
       "        0.01282751, 0.00717315, 0.0313588 , 0.02008569, 0.02421894,\n",
       "        0.00788416, 0.00611102, 0.02429075, 0.01699663, 0.01933817,\n",
       "        0.00944689, 0.01724168, 0.04180689, 0.02113928, 0.02066644,\n",
       "        0.00585065, 0.02054467, 0.01709558, 0.01757023, 0.0772502 ,\n",
       "        0.00930832, 0.01337104, 0.01200474, 0.01818445, 0.02233843,\n",
       "        0.01358706, 0.01436219, 0.0487689 , 0.02507888, 0.02460193,\n",
       "        0.01022623, 0.00897927, 0.02732666, 0.00844944, 0.06616474,\n",
       "        0.01101644, 0.00925015, 0.02221269, 0.05075035, 0.03009702,\n",
       "        0.00492339, 0.0129394 , 0.06041058, 0.01802991, 0.02350526,\n",
       "        0.01613305, 0.01627939, 0.01900262, 0.02462802, 0.02563155,\n",
       "        0.0021345 , 0.01486634, 0.02852171, 0.03344946, 0.02817281,\n",
       "        0.00440748, 0.01378183, 0.0290089 , 0.03077816, 0.08794584,\n",
       "        0.00511396, 0.01781692, 0.03009822, 0.01591873, 0.07400011,\n",
       "        0.00397186, 0.01158446, 0.02358813, 0.01663113, 0.01999498]),\n",
       " 'mean_score_time': array([0.01999931, 0.03019958, 0.0446013 , 0.05839911, 0.07700176,\n",
       "        0.01640129, 0.03000102, 0.05779996, 0.05820122, 0.07120113,\n",
       "        0.0157999 , 0.03059921, 0.04739957, 0.05920086, 0.07380128,\n",
       "        0.0160006 , 0.03040128, 0.04420061, 0.06240191, 0.07600183,\n",
       "        0.0158    , 0.03100166, 0.04380083, 0.05899887, 0.07120075,\n",
       "        0.01700034, 0.03199964, 0.04740224, 0.06140013, 0.07300324,\n",
       "        0.01679931, 0.03059993, 0.04480128, 0.06740332, 0.07660136,\n",
       "        0.0171999 , 0.03080077, 0.04680037, 0.06020241, 0.07300234,\n",
       "        0.01820445, 0.03160205, 0.04460254, 0.06020017, 0.07580085,\n",
       "        0.01680026, 0.03040233, 0.04620333, 0.05999999, 0.07280097,\n",
       "        0.04000115, 0.04980297, 0.10020328, 0.08800459, 0.07640181,\n",
       "        0.01700258, 0.03260303, 0.04760141, 0.06439886, 0.07880077,\n",
       "        0.01680288, 0.03060217, 0.04680562, 0.06040192, 0.08000016,\n",
       "        0.01700048, 0.03179994, 0.04820361, 0.06080375, 0.07920165,\n",
       "        0.01660051, 0.03160071, 0.04640431, 0.06120167, 0.0780036 ,\n",
       "        0.01760178, 0.03500061, 0.05000238, 0.06680217, 0.08000231,\n",
       "        0.01760216, 0.0331995 , 0.04879913, 0.06340661, 0.08300304,\n",
       "        0.01740298, 0.03240266, 0.0486033 , 0.0640018 , 0.0774035 ,\n",
       "        0.01720495, 0.03320279, 0.04780259, 0.06439881, 0.08259883,\n",
       "        0.01780252, 0.03380213, 0.04760194, 0.063201  , 0.07780175,\n",
       "        0.01800332, 0.03400235, 0.04860229, 0.06600046, 0.08059883,\n",
       "        0.01780005, 0.03340235, 0.05180082, 0.06740475, 0.09040155,\n",
       "        0.01860085, 0.03260078, 0.04980292, 0.06640077, 0.11060343,\n",
       "        0.01800232, 0.03360071, 0.04980259, 0.06980486, 0.08359938,\n",
       "        0.01740165, 0.03320069, 0.04940295, 0.06700058, 0.08240252,\n",
       "        0.01800265, 0.03480229, 0.05120392, 0.06820269, 0.08560009,\n",
       "        0.01760163, 0.03420119, 0.05160394, 0.06900153, 0.08360004,\n",
       "        0.01800241, 0.03520422, 0.0508008 , 0.07020082, 0.08720269,\n",
       "        0.0210012 , 0.03460288, 0.0515985 , 0.06560302, 0.08200254,\n",
       "        0.01740203, 0.03660116, 0.05120425, 0.06980076, 0.08300095,\n",
       "        0.01820316, 0.03600283, 0.05120287, 0.07100182, 0.0844027 ,\n",
       "        0.01840539, 0.03580294, 0.05100465, 0.07100163, 0.08400202,\n",
       "        0.01880178, 0.03500304, 0.05140171, 0.06739922, 0.08400373,\n",
       "        0.01820235, 0.03400407, 0.05340242, 0.06860228, 0.08360262,\n",
       "        0.01800184, 0.03380237, 0.05100245, 0.09540243, 0.0826005 ,\n",
       "        0.01960139, 0.03699913, 0.0532023 , 0.06880078, 0.08600125,\n",
       "        0.01860275, 0.03580294, 0.05260339, 0.07000232, 0.08620119,\n",
       "        0.01920152, 0.03460207, 0.052601  , 0.06840186, 0.08500061,\n",
       "        0.01860404, 0.03500342, 0.05100226, 0.06759772, 0.08500013,\n",
       "        0.01760139, 0.03480444, 0.05060387, 0.0668015 , 0.08320451,\n",
       "        0.01960216, 0.03720741, 0.05360198, 0.07260118, 0.08740277,\n",
       "        0.01879945, 0.03620272, 0.05340238, 0.06979928, 0.09060082,\n",
       "        0.01920614, 0.03699913, 0.05600796, 0.07140093, 0.08560033,\n",
       "        0.01860213, 0.03560247, 0.05280128, 0.06720214, 0.0871995 ,\n",
       "        0.01900249, 0.03500013, 0.05300326, 0.06760349, 0.08700132,\n",
       "        0.01899958, 0.02999988, 0.04579825, 0.05940161, 0.09979849,\n",
       "        0.0160018 , 0.03000031, 0.04360085, 0.05879908, 0.07420197,\n",
       "        0.01660185, 0.02960248, 0.04440298, 0.05920339, 0.07459984,\n",
       "        0.01600013, 0.02979927, 0.04480152, 0.0596034 , 0.07439947,\n",
       "        0.01639953, 0.03059959, 0.04459958, 0.05860262, 0.07280064,\n",
       "        0.01820273, 0.0312007 , 0.04480195, 0.0610014 , 0.07579837,\n",
       "        0.01720357, 0.03120327, 0.04760327, 0.06019964, 0.07580032,\n",
       "        0.01640224, 0.03100047, 0.04640307, 0.06080194, 0.07460217,\n",
       "        0.01680455, 0.03040051, 0.0494019 , 0.06080122, 0.07520046,\n",
       "        0.01660047, 0.03160057, 0.04500036, 0.0650023 , 0.07460184,\n",
       "        0.0182025 , 0.03119984, 0.04679956, 0.06220078, 0.07860093,\n",
       "        0.01720381, 0.03260274, 0.04800062, 0.06340132, 0.07860084,\n",
       "        0.0170033 , 0.03240418, 0.0476016 , 0.09140306, 0.0770021 ,\n",
       "        0.01700106, 0.03199997, 0.05020032, 0.06360135, 0.07780385,\n",
       "        0.01760049, 0.03220148, 0.04859953, 0.06420093, 0.07700081,\n",
       "        0.01760197, 0.03380089, 0.05120149, 0.06420274, 0.07980347,\n",
       "        0.0176023 , 0.03320704, 0.04760094, 0.06560116, 0.07900147,\n",
       "        0.01800179, 0.03260427, 0.04940162, 0.06520362, 0.07860103,\n",
       "        0.01780081, 0.03380094, 0.05000176, 0.06380334, 0.07920322,\n",
       "        0.0180038 , 0.03500462, 0.05000486, 0.06560278, 0.08020258,\n",
       "        0.01820288, 0.03380151, 0.0502038 , 0.06660414, 0.08300247,\n",
       "        0.01820307, 0.0332016 , 0.04980421, 0.06620178, 0.08220119,\n",
       "        0.01820159, 0.03360157, 0.05080314, 0.0692028 , 0.08120055,\n",
       "        0.01820297, 0.03360167, 0.04980159, 0.06540165, 0.0819994 ,\n",
       "        0.01860509, 0.03420277, 0.04940023, 0.06540332, 0.08060126,\n",
       "        0.0182023 , 0.03500385, 0.054002  , 0.0666028 , 0.08420119,\n",
       "        0.01840115, 0.0360034 , 0.05440793, 0.07180495, 0.08480306,\n",
       "        0.01860132, 0.0340064 , 0.05000052, 0.06660514, 0.08360162,\n",
       "        0.01820269, 0.03360271, 0.05000257, 0.06560411, 0.08200126,\n",
       "        0.01800394, 0.03440351, 0.049402  , 0.06640105, 0.08260159,\n",
       "        0.01900616, 0.03520098, 0.0510035 , 0.06860123, 0.08520112,\n",
       "        0.01800337, 0.03440285, 0.05300093, 0.06800213, 0.08660297,\n",
       "        0.01880302, 0.03580194, 0.05120239, 0.06740298, 0.08179955,\n",
       "        0.01860218, 0.03460083, 0.05080419, 0.06640115, 0.08340344,\n",
       "        0.01840606, 0.03420143, 0.04980321, 0.06920295, 0.08380075,\n",
       "        0.01800284, 0.03579984, 0.05300064, 0.09620104, 0.08479953,\n",
       "        0.01800385, 0.03440371, 0.05260406, 0.06700091, 0.08440323,\n",
       "        0.01860361, 0.0348    , 0.05020075, 0.07020307, 0.08420429,\n",
       "        0.01860285, 0.03380098, 0.05160046, 0.06640334, 0.0842041 ,\n",
       "        0.01840162, 0.03420367, 0.05040269, 0.06680136, 0.08200073,\n",
       "        0.01880155, 0.03520164, 0.05340309, 0.06900296, 0.08600125,\n",
       "        0.01840272, 0.0352026 , 0.05280151, 0.06940179, 0.08359976,\n",
       "        0.01860428, 0.03440413, 0.05100307, 0.06760235, 0.08400221,\n",
       "        0.02160187, 0.03420324, 0.05060058, 0.06620188, 0.08320298,\n",
       "        0.0182013 , 0.03400183, 0.04980164, 0.06680088, 0.08620138,\n",
       "        0.01580019, 0.02880158, 0.04260206, 0.05700121, 0.06940012,\n",
       "        0.01640205, 0.02940311, 0.04260063, 0.05660057, 0.07160234,\n",
       "        0.01660018, 0.02879944, 0.04560423, 0.05860176, 0.07060094,\n",
       "        0.01519871, 0.02920046, 0.04400082, 0.05740175, 0.07219968,\n",
       "        0.01540184, 0.02899971, 0.04420147, 0.05680046, 0.07020226,\n",
       "        0.01620026, 0.03020167, 0.04480114, 0.05940123, 0.07240081,\n",
       "        0.01619878, 0.03000269, 0.04660139, 0.05760059, 0.07440133,\n",
       "        0.01580267, 0.03020129, 0.0450027 , 0.06059961, 0.0738009 ,\n",
       "        0.0162014 , 0.03060417, 0.04400105, 0.0590034 , 0.07239919,\n",
       "        0.01600285, 0.03060379, 0.046802  , 0.05800076, 0.07320204,\n",
       "        0.01700416, 0.03280315, 0.05080605, 0.06420755, 0.07760034,\n",
       "        0.01680336, 0.03120313, 0.04660034, 0.06100135, 0.07519989,\n",
       "        0.0164022 , 0.0334013 , 0.04500504, 0.05900106, 0.07540116,\n",
       "        0.01700292, 0.03140202, 0.04580307, 0.06100416, 0.07720327,\n",
       "        0.01680202, 0.03180423, 0.04939985, 0.0622005 , 0.07780237,\n",
       "        0.01740346, 0.03220191, 0.0478003 , 0.06460133, 0.08000164,\n",
       "        0.01739993, 0.03300152, 0.0486022 , 0.06380253, 0.0790041 ,\n",
       "        0.01780272, 0.03140163, 0.04800076, 0.06240344, 0.07960076,\n",
       "        0.01700187, 0.03180175, 0.04760146, 0.06579995, 0.07720218,\n",
       "        0.01680441, 0.03160324, 0.04700432, 0.0624033 , 0.0820013 ,\n",
       "        0.01740375, 0.03360109, 0.05080066, 0.06920342, 0.08200092,\n",
       "        0.01780286, 0.03340235, 0.04840198, 0.06520219, 0.08040123,\n",
       "        0.01700163, 0.03340039, 0.05020061, 0.06360264, 0.07920322,\n",
       "        0.01780214, 0.03360205, 0.05020123, 0.06760168, 0.08040295,\n",
       "        0.01720119, 0.03320322, 0.04900298, 0.06640043, 0.08180013,\n",
       "        0.01780086, 0.03560357, 0.05180106, 0.06640272, 0.08500147,\n",
       "        0.01820207, 0.03500395, 0.05100136, 0.07100425, 0.08499904,\n",
       "        0.01840043, 0.03460283, 0.05120168, 0.06600142, 0.08420091,\n",
       "        0.01900167, 0.03420177, 0.05000024, 0.06560006, 0.0880033 ,\n",
       "        0.01860452, 0.03340325, 0.04960227, 0.06740394, 0.08500204,\n",
       "        0.01840305, 0.0346004 , 0.05120287, 0.07300487, 0.0854003 ,\n",
       "        0.01920133, 0.03520341, 0.05460062, 0.06800394, 0.08599977,\n",
       "        0.01820364, 0.03440213, 0.05140061, 0.06900167, 0.08720012,\n",
       "        0.01800256, 0.03480196, 0.05160213, 0.06920123, 0.08399963,\n",
       "        0.01880479, 0.03440342, 0.05020247, 0.06700244, 0.08580003,\n",
       "        0.01840229, 0.03880324, 0.05399971, 0.06900501, 0.08680124,\n",
       "        0.01840148, 0.03500223, 0.05240216, 0.07160401, 0.08960423,\n",
       "        0.01960378, 0.03780537, 0.0564024 , 0.07060175, 0.08660331,\n",
       "        0.01840243, 0.03680339, 0.05360289, 0.06920247, 0.08540168,\n",
       "        0.01860318, 0.03560233, 0.05380278, 0.07020235, 0.08660073,\n",
       "        0.02000208, 0.0372014 , 0.05460243, 0.0728035 , 0.09040284,\n",
       "        0.01880202, 0.03940244, 0.0540041 , 0.07180386, 0.08900471,\n",
       "        0.01920295, 0.03600249, 0.05360317, 0.07140274, 0.08900046,\n",
       "        0.01920218, 0.03560238, 0.0530035 , 0.0730032 , 0.09120021,\n",
       "        0.01900139, 0.03720236, 0.05380206, 0.07020059, 0.08800006,\n",
       "        0.01540203, 0.03020062, 0.04320359, 0.05799885, 0.07239923,\n",
       "        0.01580224, 0.02980218, 0.04520445, 0.0588027 , 0.0714004 ,\n",
       "        0.015801  , 0.02979913, 0.04379997, 0.05800018, 0.0752017 ,\n",
       "        0.0160006 , 0.03000402, 0.04459953, 0.06080236, 0.07240391,\n",
       "        0.0162014 , 0.02960105, 0.04440122, 0.06040459, 0.0711997 ,\n",
       "        0.0166038 , 0.03040309, 0.04500251, 0.0598042 , 0.07560148,\n",
       "        0.01660061, 0.03100386, 0.04500203, 0.06160364, 0.07459936,\n",
       "        0.01640224, 0.03080163, 0.04460201, 0.06100602, 0.07519922,\n",
       "        0.0167995 , 0.03060212, 0.046803  , 0.06040077, 0.07480116,\n",
       "        0.01620173, 0.0306006 , 0.0453989 , 0.06279993, 0.07500052,\n",
       "        0.01860266, 0.03160253, 0.04760118, 0.06180158, 0.07780161,\n",
       "        0.01660328, 0.0320025 , 0.0488039 , 0.06300035, 0.07880044,\n",
       "        0.0172049 , 0.03700261, 0.04720192, 0.06380138, 0.0778029 ,\n",
       "        0.01680255, 0.03200188, 0.04980135, 0.06360097, 0.0788012 ,\n",
       "        0.01780286, 0.03300161, 0.04680281, 0.06180043, 0.07960238,\n",
       "        0.01740274, 0.03420234, 0.05220275, 0.06340132, 0.08440032,\n",
       "        0.01940365, 0.03360062, 0.05040102, 0.06760159, 0.08080373,\n",
       "        0.01760235, 0.03400536, 0.04880157, 0.06860247, 0.08180156,\n",
       "        0.01720304, 0.03360267, 0.04880242, 0.06540265, 0.08100162,\n",
       "        0.0182024 , 0.03300076, 0.04840117, 0.06820207, 0.085004  ,\n",
       "        0.0180038 , 0.03500152, 0.05120039, 0.06920161, 0.08120184,\n",
       "        0.01900449, 0.03740087, 0.05060282, 0.06720428, 0.0834023 ,\n",
       "        0.01860237, 0.03420277, 0.05120206, 0.06959991, 0.08180079,\n",
       "        0.01860275, 0.03500319, 0.05060019, 0.06560302, 0.08220325,\n",
       "        0.01780233, 0.03480144, 0.05060043, 0.06800141, 0.0832037 ,\n",
       "        0.01900282, 0.03920178, 0.0516017 , 0.06880178, 0.08940239,\n",
       "        0.01900077, 0.03500457, 0.0518012 , 0.0672029 , 0.11440182,\n",
       "        0.01920323, 0.03460093, 0.05300193, 0.06760111, 0.08340197,\n",
       "        0.01820517, 0.03460164, 0.05380158, 0.06880054, 0.09460344,\n",
       "        0.0178019 , 0.03460302, 0.05060148, 0.06680002, 0.085603  ,\n",
       "        0.01920114, 0.0350029 , 0.05300379, 0.07259998, 0.08740144,\n",
       "        0.01860366, 0.03560262, 0.05400133, 0.06840477, 0.0893991 ,\n",
       "        0.01840229, 0.03620572, 0.05380235, 0.07200089, 0.08520007,\n",
       "        0.01900067, 0.04000263, 0.05240245, 0.06940022, 0.08580046,\n",
       "        0.01840057, 0.03540049, 0.05160279, 0.06880355, 0.08880396,\n",
       "        0.01920271, 0.03540349, 0.05240426, 0.07060337, 0.08700199,\n",
       "        0.01860375, 0.03580041, 0.05360494, 0.06940145, 0.09200253,\n",
       "        0.01900225, 0.03479972, 0.05180287, 0.06920352, 0.08740187,\n",
       "        0.01940103, 0.03640232, 0.05100245, 0.07180514, 0.08440146,\n",
       "        0.01860127, 0.03500185, 0.05120034, 0.06940136, 0.08400202,\n",
       "        0.01900177, 0.0368032 , 0.05540328, 0.0700038 , 0.08880229,\n",
       "        0.02020445, 0.0358026 , 0.05360274, 0.07160296, 0.08740253,\n",
       "        0.01880293, 0.03600249, 0.05440598, 0.07319603, 0.0879993 ,\n",
       "        0.0188025 , 0.03720326, 0.05240412, 0.06980433, 0.08960142,\n",
       "        0.0182023 , 0.03520231, 0.05360227, 0.06920276, 0.08720188]),\n",
       " 'std_score_time': array([3.34572800e-03, 1.93941356e-03, 1.19872349e-03, 7.99477764e-04,\n",
       "        3.68651648e-03, 1.02053549e-03, 1.64214853e-06, 2.61570038e-02,\n",
       "        1.59950265e-03, 9.80825317e-04, 4.00018877e-04, 1.85536113e-03,\n",
       "        4.62914243e-03, 1.32606795e-03, 2.31578246e-03, 1.09732815e-03,\n",
       "        1.49584807e-03, 1.16835567e-03, 5.85444606e-03, 6.06520857e-03,\n",
       "        3.99829365e-04, 2.09921847e-03, 1.16797984e-03, 1.67414329e-03,\n",
       "        9.78277254e-04, 8.93509710e-04, 1.89660189e-03, 1.02213930e-03,\n",
       "        2.86874954e-03, 1.09902351e-03, 1.16582873e-03, 1.19860248e-03,\n",
       "        1.16524917e-03, 1.49645182e-02, 3.00629898e-03, 9.79783320e-04,\n",
       "        1.16694836e-03, 2.31351263e-03, 1.47116645e-03, 1.41452760e-06,\n",
       "        2.48417365e-03, 1.02190002e-03, 8.00631436e-04, 1.16570467e-03,\n",
       "        3.37183741e-03, 7.47147691e-04, 4.90839101e-04, 2.85449750e-03,\n",
       "        1.09471659e-03, 1.32659757e-03, 2.34163150e-02, 1.11970757e-02,\n",
       "        2.70659771e-02, 3.15318958e-02, 2.33332634e-03, 1.09445253e-03,\n",
       "        1.02034844e-03, 2.05897413e-03, 2.15398559e-03, 2.92565317e-03,\n",
       "        4.00713975e-04, 4.90330433e-04, 1.59502319e-03, 4.90660964e-04,\n",
       "        3.34639771e-03, 1.09501759e-03, 1.16620682e-03, 1.32692516e-03,\n",
       "        7.49762781e-04, 2.13454884e-03, 4.90973814e-04, 1.01880549e-03,\n",
       "        4.88380505e-04, 2.13741403e-03, 3.28702610e-03, 1.19898374e-03,\n",
       "        6.36671188e-04, 1.41492553e-03, 2.04431196e-03, 2.60915713e-03,\n",
       "        1.19688903e-03, 1.93748111e-03, 1.93920705e-03, 1.49419866e-03,\n",
       "        3.34540091e-03, 1.02021706e-03, 4.90837920e-04, 2.41480282e-03,\n",
       "        2.09439846e-03, 1.35818275e-03, 4.01051840e-04, 1.93859270e-03,\n",
       "        7.48559766e-04, 1.19955820e-03, 3.61571145e-03, 1.46695978e-03,\n",
       "        2.13464181e-03, 1.01992685e-03, 1.71974784e-03, 7.47835277e-04,\n",
       "        6.30675984e-04, 8.95381644e-04, 4.91989465e-04, 1.89805956e-03,\n",
       "        1.49525502e-03, 7.44367828e-04, 4.89768417e-04, 4.06914100e-03,\n",
       "        2.57362238e-03, 1.83360316e-02, 1.02105965e-03, 4.90976292e-04,\n",
       "        1.72143438e-03, 1.74179973e-03, 5.57078046e-02, 1.09406398e-03,\n",
       "        8.01340650e-04, 3.71002710e-03, 1.83403465e-03, 3.92874801e-03,\n",
       "        4.91673645e-04, 9.79337001e-04, 1.62352375e-03, 2.75586656e-03,\n",
       "        2.41635233e-03, 9.24621555e-07, 7.47973424e-04, 2.04065352e-03,\n",
       "        3.54523250e-03, 1.85353352e-03, 4.90302706e-04, 9.79073533e-04,\n",
       "        1.01919807e-03, 2.75612652e-03, 2.57414080e-03, 8.94258233e-04,\n",
       "        1.93757171e-03, 1.94092002e-03, 4.06829699e-03, 5.81013020e-03,\n",
       "        4.14938323e-03, 2.15573077e-03, 3.00564632e-03, 1.35619955e-03,\n",
       "        1.41353926e-03, 4.90680649e-04, 2.24464551e-03, 3.05743922e-03,\n",
       "        3.12388106e-03, 2.36744956e-03, 4.00832237e-04, 1.78725891e-03,\n",
       "        9.81108851e-04, 2.89847771e-03, 1.01870176e-03, 4.91479401e-04,\n",
       "        1.93881753e-03, 1.41259789e-03, 4.33821092e-03, 2.19073222e-03,\n",
       "        7.48420348e-04, 1.89712893e-03, 1.85509077e-03, 2.41672250e-03,\n",
       "        2.19473667e-03, 7.49088129e-04, 8.95803901e-04, 3.44222221e-03,\n",
       "        1.74225193e-03, 2.41676871e-03, 1.09475660e-03, 9.79832865e-04,\n",
       "        1.67334228e-03, 5.33242249e-02, 1.02012492e-03, 1.19902429e-03,\n",
       "        1.41397641e-03, 1.93945760e-03, 1.93852104e-03, 2.27980945e-03,\n",
       "        4.90002249e-04, 1.16497106e-03, 1.85218430e-03, 3.63262893e-03,\n",
       "        2.99401544e-03, 1.16597648e-03, 1.01937642e-03, 2.57628940e-03,\n",
       "        2.72886949e-03, 2.96611978e-03, 1.20079553e-03, 1.67448405e-03,\n",
       "        1.89936553e-03, 2.05828234e-03, 2.19151632e-03, 4.91167147e-04,\n",
       "        1.32864851e-03, 7.99784695e-04, 1.72102360e-03, 1.94040452e-03,\n",
       "        7.98750856e-04, 2.32205846e-03, 1.95772783e-03, 3.43925343e-03,\n",
       "        3.38338157e-03, 1.46875757e-03, 7.47496071e-04, 1.49578490e-03,\n",
       "        2.71191315e-03, 4.22410537e-03, 7.48814567e-04, 1.09546518e-03,\n",
       "        3.16277460e-03, 2.15403871e-03, 3.25895858e-03, 4.89398699e-04,\n",
       "        7.99012773e-04, 3.18749187e-03, 9.79998198e-04, 2.78469892e-03,\n",
       "        1.67205972e-03, 6.33091460e-04, 1.41269676e-03, 1.49650450e-03,\n",
       "        4.28837850e-03, 5.51527094e-03, 1.09419226e-03, 1.72138381e-03,\n",
       "        3.00808138e-03, 5.46527255e-02, 6.35276701e-04, 6.30832720e-04,\n",
       "        4.89823724e-04, 1.83303209e-03, 3.12317486e-03, 8.01350451e-04,\n",
       "        4.89846632e-04, 1.20330407e-03, 3.92151428e-03, 3.00428454e-03,\n",
       "        1.04033586e-06, 1.59833482e-03, 1.72258588e-03, 1.85522798e-03,\n",
       "        2.72732025e-03, 7.98393426e-04, 1.35230138e-03, 2.41593331e-03,\n",
       "        1.96182589e-03, 1.60047522e-03, 9.82064382e-04, 1.59993179e-03,\n",
       "        4.00545966e-04, 3.03260094e-03, 2.63740233e-03, 9.80013031e-04,\n",
       "        1.16602726e-03, 2.80164351e-03, 1.16284488e-03, 2.39908000e-03,\n",
       "        8.00133490e-04, 1.09715066e-03, 2.49745789e-03, 1.47158819e-03,\n",
       "        1.19926570e-03, 1.17094070e-03, 4.90760377e-04, 4.22813346e-03,\n",
       "        2.31443527e-03, 2.78570176e-03, 7.99644478e-04, 1.35654622e-03,\n",
       "        6.33167326e-04, 6.10285064e-03, 2.41810739e-03, 1.16782895e-03,\n",
       "        3.97850008e-04, 7.47156836e-04, 1.59856762e-03, 2.33208143e-03,\n",
       "        9.80258874e-04, 1.02056838e-03, 1.78840753e-03, 1.49491190e-03,\n",
       "        2.49806268e-03, 6.31594873e-04, 1.35788692e-03, 1.62396817e-03,\n",
       "        5.43075222e-02, 1.78829848e-03, 1.09458228e-03, 1.09497400e-03,\n",
       "        3.18777463e-03, 1.85482398e-03, 1.16863305e-03, 1.19958739e-03,\n",
       "        1.46916622e-03, 2.24308224e-03, 1.83174261e-03, 1.16215302e-06,\n",
       "        7.99538289e-04, 1.16716953e-03, 1.16717784e-03, 9.81478284e-04,\n",
       "        7.51071035e-04, 1.35549551e-03, 1.47722601e-03, 8.01539795e-04,\n",
       "        1.62373992e-03, 1.09441537e-03, 2.64203933e-06, 4.92072091e-04,\n",
       "        1.35842463e-03, 1.93947368e-03, 4.90291646e-04, 7.48713696e-04,\n",
       "        9.76669464e-04, 2.89671632e-03, 1.16867627e-03, 1.16289681e-03,\n",
       "        6.31735970e-04, 2.28217399e-03, 1.67229685e-03, 2.05847363e-03,\n",
       "        1.93924882e-03, 3.96685116e-04, 7.48316527e-04, 1.59913746e-03,\n",
       "        1.19972406e-03, 1.78827235e-03, 1.46999863e-03, 3.98803823e-04,\n",
       "        9.79861505e-04, 1.16395968e-03, 3.54318727e-03, 9.79621121e-04,\n",
       "        4.89925976e-04, 2.47925120e-03, 7.25092824e-03, 9.82163366e-04,\n",
       "        9.79921886e-04, 1.20012917e-03, 1.16602221e-03, 1.85382913e-03,\n",
       "        2.52992176e-03, 1.49624104e-03, 2.48052551e-03, 1.19935709e-03,\n",
       "        8.00513244e-04, 1.85686741e-03, 3.98039914e-04, 2.09805734e-03,\n",
       "        6.10039603e-03, 8.02924803e-04, 1.93950857e-03, 1.01894523e-03,\n",
       "        2.83044877e-03, 2.57510523e-03, 2.31239728e-03, 1.46866717e-03,\n",
       "        1.35578478e-03, 1.09602173e-03, 1.09441012e-03, 1.01854492e-03,\n",
       "        1.74273360e-03, 9.78712636e-04, 4.91147898e-04, 8.94152548e-04,\n",
       "        7.99668021e-04, 1.26602621e-03, 1.09649888e-03, 4.88075906e-04,\n",
       "        1.35760562e-03, 2.05950538e-03, 2.57546038e-03, 6.36189457e-04,\n",
       "        1.72009685e-03, 6.32185507e-04, 3.44062572e-03, 4.11886178e-03,\n",
       "        2.86102295e-07, 1.35553673e-03, 4.55812331e-03, 2.96793641e-03,\n",
       "        2.86871430e-03, 1.46853037e-03, 3.25215336e-03, 1.93754079e-03,\n",
       "        2.41763820e-03, 1.32561960e-03, 1.02074180e-03, 1.19999455e-03,\n",
       "        1.46761391e-03, 1.85546473e-03, 1.85275085e-03, 4.93269927e-04,\n",
       "        9.78102478e-04, 7.47935832e-04, 3.96865811e-03, 3.48662872e-03,\n",
       "        4.91072826e-06, 2.13423858e-03, 1.09445323e-03, 5.40067930e-02,\n",
       "        1.60217389e-03, 1.52736830e-06, 4.90059715e-04, 1.62844926e-03,\n",
       "        1.26523515e-03, 2.57701499e-03, 8.00635140e-04, 1.16576487e-03,\n",
       "        1.16830526e-03, 3.92050358e-03, 2.99631756e-03, 1.19924632e-03,\n",
       "        1.59947879e-03, 1.95870341e-03, 1.62394860e-03, 2.22688640e-03,\n",
       "        1.49700788e-03, 1.47076232e-03, 1.49501999e-03, 1.16549317e-03,\n",
       "        1.54815786e-03, 7.46446903e-04, 1.16546957e-03, 2.49985661e-03,\n",
       "        1.67280227e-03, 2.60703562e-03, 7.98154324e-04, 1.16653209e-03,\n",
       "        3.96996419e-03, 4.12856506e-03, 2.15441598e-03, 8.01802653e-04,\n",
       "        4.89909388e-04, 1.67245902e-03, 1.74690206e-03, 2.68728159e-03,\n",
       "        4.45518713e-03, 7.49557533e-04, 1.01849693e-03, 7.48659720e-04,\n",
       "        1.32670678e-03, 9.78995778e-04, 6.30154151e-04, 7.48661010e-04,\n",
       "        1.72097786e-03, 4.79258670e-03, 1.16633531e-03, 4.00378943e-04,\n",
       "        1.20306155e-03, 1.26395332e-03, 4.88873012e-04, 1.02215445e-03,\n",
       "        4.91429416e-04, 4.89106798e-04, 1.35626947e-03, 2.33031611e-03,\n",
       "        1.35449165e-03, 3.99548755e-04, 1.74587694e-03, 2.65453632e-03,\n",
       "        1.74304628e-03, 3.99355632e-04, 4.00949442e-04, 1.09515436e-03,\n",
       "        1.85382878e-03, 3.54428284e-03, 4.88910721e-04, 1.09432117e-03,\n",
       "        2.13469242e-03, 1.72045692e-03, 7.48359539e-04, 9.79919658e-04,\n",
       "        7.47437644e-04, 2.22862457e-03, 1.85164984e-03, 1.85467195e-03,\n",
       "        9.78469414e-04, 1.09710722e-03, 2.33253938e-03, 4.90158276e-04,\n",
       "        2.15381262e-03, 7.47583031e-04, 7.48367788e-04, 2.09842052e-03,\n",
       "        1.74131762e-03, 1.60066656e-03, 9.78422496e-04, 8.00757659e-04,\n",
       "        1.09675933e-03, 2.09730683e-03, 1.19839704e-03, 1.09658519e-03,\n",
       "        1.62666812e-03, 1.93983387e-03, 1.26561329e-03, 1.46975778e-03,\n",
       "        8.96608646e-04, 2.04021321e-03, 5.26674556e-03, 3.48880675e-03,\n",
       "        3.98070453e-03, 7.47401392e-04, 3.99783885e-04, 2.05738489e-03,\n",
       "        1.78843197e-03, 9.78441840e-04, 4.90019018e-04, 4.41038229e-03,\n",
       "        6.35807386e-04, 6.34068832e-04, 1.85305820e-03, 1.09623814e-03,\n",
       "        1.35545395e-03, 7.47637708e-04, 1.26795005e-03, 2.47990749e-03,\n",
       "        7.46791196e-04, 1.72123892e-03, 5.94974113e-03, 2.56009620e-03,\n",
       "        3.42928258e-03, 7.96629202e-04, 9.80562796e-04, 1.93737755e-03,\n",
       "        3.77309685e-03, 3.03367067e-03, 7.98872554e-04, 8.92820918e-04,\n",
       "        1.62513054e-03, 1.93920204e-03, 1.67399678e-03, 7.46999492e-04,\n",
       "        4.90952914e-04, 8.93509771e-04, 1.02118949e-03, 1.74430466e-03,\n",
       "        1.88938263e-06, 7.49935890e-04, 1.35577791e-03, 2.31268916e-03,\n",
       "        7.47666395e-04, 4.00400659e-04, 4.91363295e-04, 1.42082131e-03,\n",
       "        2.41605044e-03, 4.55967113e-03, 4.90543978e-04, 1.74555612e-03,\n",
       "        2.78606185e-03, 3.65470705e-03, 3.52082409e-03, 7.48178814e-04,\n",
       "        7.99349844e-04, 1.01964034e-03, 1.93959618e-03, 3.26154543e-03,\n",
       "        1.37375453e-06, 1.95802451e-03, 2.99408485e-03, 1.02163789e-03,\n",
       "        9.80523329e-04, 7.46646989e-04, 1.35695421e-03, 1.46980290e-03,\n",
       "        5.31636012e-03, 1.85567944e-03, 9.79570138e-04, 7.48444150e-04,\n",
       "        6.32337684e-04, 1.85438404e-03, 4.30614198e-03, 3.99739373e-04,\n",
       "        2.41709730e-03, 2.31525103e-03, 1.02159222e-03, 8.91221469e-04,\n",
       "        3.99352956e-04, 1.41451753e-03, 2.68376447e-03, 3.89486546e-03,\n",
       "        3.15903298e-03, 1.01816613e-03, 2.24391574e-03, 9.79162976e-04,\n",
       "        1.54889862e-03, 1.32675781e-03, 1.67183220e-03, 9.80221965e-04,\n",
       "        6.32336404e-04, 1.62385201e-03, 7.34873549e-03, 1.02077005e-03,\n",
       "        8.00564610e-04, 1.02067545e-03, 2.41702727e-03, 5.32777671e-03,\n",
       "        8.00671839e-04, 4.88543663e-04, 7.49197244e-04, 1.26392202e-03,\n",
       "        2.41628816e-03, 1.16498572e-03, 1.16733498e-03, 2.15239351e-03,\n",
       "        1.89851532e-03, 2.96555895e-03, 7.48035298e-04, 1.02189390e-03,\n",
       "        1.62268610e-03, 8.93884118e-04, 3.65344740e-03, 6.33993860e-04,\n",
       "        7.46037343e-04, 2.79797839e-03, 3.31108206e-03, 2.09667104e-03,\n",
       "        7.50513316e-04, 7.99908618e-04, 1.16739054e-03, 1.54902086e-03,\n",
       "        2.92578406e-03, 4.91382633e-04, 2.31468160e-03, 3.52075645e-03,\n",
       "        6.32654614e-04, 1.71886087e-03, 8.01399071e-04, 6.33917781e-04,\n",
       "        1.85363855e-03, 3.61309363e-03, 2.87277527e-03, 4.89662947e-04,\n",
       "        2.31726612e-03, 3.72115940e-03, 2.65216676e-03, 3.61280583e-03,\n",
       "        4.91752028e-04, 1.16457068e-03, 3.19993015e-03, 3.65385907e-03,\n",
       "        3.71935584e-03, 4.88015811e-04, 1.49490455e-03, 1.59890301e-03,\n",
       "        5.42097127e-03, 2.72869526e-03, 8.91057719e-04, 1.32737389e-03,\n",
       "        8.00277756e-04, 2.31606927e-03, 3.49839036e-03, 3.98565833e-04,\n",
       "        2.94225058e-03, 2.19238676e-03, 9.76761950e-04, 2.82609891e-03,\n",
       "        1.60133934e-03, 8.93885792e-04, 1.62440402e-03, 1.62476905e-03,\n",
       "        2.09748952e-03, 9.78459687e-04, 1.49877256e-03, 1.54982111e-03,\n",
       "        3.90134763e-03, 5.88089958e-03, 6.31808076e-04, 1.16724421e-03,\n",
       "        2.92544069e-03, 1.93851899e-03, 3.73883814e-03, 4.90999928e-04,\n",
       "        1.93814983e-03, 3.99114895e-04, 1.41296637e-03, 1.74079207e-03,\n",
       "        4.00475275e-04, 1.16599331e-03, 1.32582669e-03, 2.39973323e-03,\n",
       "        2.80177620e-03, 4.00212424e-04, 1.16546873e-03, 1.46858851e-03,\n",
       "        1.67294232e-03, 3.48507548e-03, 1.09419049e-03, 1.55009727e-03,\n",
       "        2.05847344e-03, 4.95545914e-03, 2.06101981e-03, 9.79443982e-04,\n",
       "        8.00228431e-04, 1.20030859e-03, 3.07414149e-03, 7.48323409e-04,\n",
       "        1.20325123e-03, 4.91869985e-04, 6.30450613e-04, 1.60098102e-03,\n",
       "        3.66608641e-03, 7.99655985e-04, 1.09475901e-03, 1.09545597e-03,\n",
       "        1.62401789e-03, 2.49743748e-03, 8.00373592e-04, 7.48291311e-04,\n",
       "        7.98992497e-04, 4.15034653e-03, 2.99563594e-03, 1.16677121e-03,\n",
       "        7.99375885e-04, 2.70986781e-03, 1.01748160e-03, 1.83163985e-03,\n",
       "        4.00427109e-04, 8.01110514e-04, 4.92364104e-04, 3.54260619e-03,\n",
       "        1.26429258e-03, 1.35695282e-03, 4.90392386e-04, 1.01934952e-03,\n",
       "        1.16600261e-03, 1.93867177e-03, 4.90994857e-04, 1.09480119e-03,\n",
       "        2.63956794e-03, 1.41381275e-03, 2.31470734e-03, 9.81489742e-04,\n",
       "        5.93477941e-03, 1.59915857e-03, 2.40104443e-03, 7.45406817e-04,\n",
       "        3.99355974e-04, 1.54846675e-03, 3.18604485e-03, 1.62556544e-03,\n",
       "        1.72075770e-03, 1.16412654e-03, 1.78829883e-03, 1.59833641e-03,\n",
       "        9.78538995e-04, 2.72828674e-03, 4.92051833e-04, 2.63730023e-03,\n",
       "        2.78706255e-03, 4.90972911e-04, 1.49540899e-03, 1.19874583e-03,\n",
       "        7.98612054e-04, 3.38180548e-03, 2.65432320e-03, 3.06299735e-03,\n",
       "        8.00032598e-04, 8.98806794e-04, 1.16735156e-03, 7.81429116e-03,\n",
       "        3.96959171e-03, 4.00926412e-04, 1.20050361e-03, 1.16561528e-03,\n",
       "        1.35742550e-03, 3.03260127e-03, 9.80330331e-04, 1.09554026e-03,\n",
       "        1.01958307e-03, 1.32679940e-03, 1.78814274e-03, 6.32344300e-04,\n",
       "        1.78939133e-03, 2.31419348e-03, 3.65348829e-03, 7.46659639e-04,\n",
       "        1.26372895e-03, 5.95202225e-03, 1.19877819e-03, 2.40073504e-03,\n",
       "        2.57537514e-03, 1.19928616e-03, 9.78801550e-04, 2.22846120e-03,\n",
       "        5.56648207e-03, 7.48163801e-04, 1.02035845e-03, 1.41384187e-03,\n",
       "        1.49487911e-03, 1.02114344e-03, 2.56144426e-03, 1.16725911e-03,\n",
       "        1.93707756e-03, 2.05833849e-03, 2.44824171e-03, 3.18835497e-03,\n",
       "        6.33918545e-04, 5.15316102e-03, 2.15328150e-03, 2.31704756e-03,\n",
       "        1.04961863e-02, 1.26425445e-03, 8.95275008e-04, 1.32892153e-03,\n",
       "        9.81499089e-04, 5.63451341e-02, 1.16629407e-03, 1.02009570e-03,\n",
       "        2.00090611e-03, 1.85604056e-03, 1.62559511e-03, 4.03765169e-04,\n",
       "        1.20022883e-03, 9.79288360e-04, 7.47789505e-04, 2.12117917e-02,\n",
       "        4.00260945e-04, 4.88540685e-04, 1.01936604e-03, 3.99307849e-04,\n",
       "        1.95717193e-03, 1.16501839e-03, 2.47955322e-06, 1.09337453e-03,\n",
       "        2.32918738e-03, 1.85324750e-03, 4.90447766e-04, 1.02027355e-03,\n",
       "        2.28114895e-03, 1.01848780e-03, 2.05861267e-03, 4.90312973e-04,\n",
       "        1.72042762e-03, 2.31521473e-03, 4.24198529e-03, 2.63889012e-03,\n",
       "        1.54813312e-03, 9.52830791e-03, 2.41543978e-03, 2.49898263e-03,\n",
       "        2.78400488e-03, 8.00300403e-04, 1.35399161e-03, 1.62544717e-03,\n",
       "        1.60086233e-03, 4.06716728e-03, 7.47440428e-04, 1.02030084e-03,\n",
       "        1.35614272e-03, 2.24462492e-03, 3.28313747e-03, 8.01541228e-04,\n",
       "        1.16625388e-03, 2.24704292e-03, 1.35948645e-03, 9.27204664e-03,\n",
       "        1.09554210e-03, 7.46457321e-04, 1.94003325e-03, 1.46988716e-03,\n",
       "        5.35049200e-03, 1.35382318e-03, 1.85334067e-03, 1.09601939e-03,\n",
       "        4.31000664e-03, 2.06095484e-03, 7.99286879e-04, 8.94256516e-04,\n",
       "        1.46916727e-03, 3.49945516e-03, 1.78981817e-03, 1.95095754e-06,\n",
       "        1.32956014e-03, 2.33141035e-03, 2.00195345e-03, 4.66635133e-03,\n",
       "        2.92668046e-03, 7.47119227e-04, 2.05727850e-03, 3.25975573e-03,\n",
       "        2.33136541e-03, 7.48788025e-04, 1.09589105e-03, 1.62911975e-03,\n",
       "        1.83156760e-03, 2.45024943e-03, 9.80806785e-04, 2.39784052e-03,\n",
       "        1.01742330e-03, 1.94241103e-03, 6.53312661e-03, 3.98397631e-04,\n",
       "        1.16592690e-03, 2.86904629e-03, 3.42784714e-03, 2.13516435e-03]),\n",
       " 'param_bootstrap': masked_array(data=[True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "                    3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "                    3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, 3, 3, 3, 3, 3, 3,\n",
       "                    3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "                    3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "                    3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_leaf': masked_array(data=[1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 7, 7, 7,\n",
       "                    7, 7, 9, 9, 9, 9, 9, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 5,\n",
       "                    5, 5, 5, 5, 7, 7, 7, 7, 7, 9, 9, 9, 9, 9, 1, 1, 1, 1,\n",
       "                    1, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 7, 7, 7, 7, 7, 9, 9,\n",
       "                    9, 9, 9, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5,\n",
       "                    7, 7, 7, 7, 7, 9, 9, 9, 9, 9, 1, 1, 1, 1, 1, 3, 3, 3,\n",
       "                    3, 3, 5, 5, 5, 5, 5, 7, 7, 7, 7, 7, 9, 9, 9, 9, 9, 1,\n",
       "                    1, 1, 1, 1, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 7, 7, 7, 7,\n",
       "                    7, 9, 9, 9, 9, 9, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 5, 5,\n",
       "                    5, 5, 5, 7, 7, 7, 7, 7, 9, 9, 9, 9, 9, 1, 1, 1, 1, 1,\n",
       "                    3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 7, 7, 7, 7, 7, 9, 9, 9,\n",
       "                    9, 9, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 7,\n",
       "                    7, 7, 7, 7, 9, 9, 9, 9, 9, 1, 1, 1, 1, 1, 3, 3, 3, 3,\n",
       "                    3, 5, 5, 5, 5, 5, 7, 7, 7, 7, 7, 9, 9, 9, 9, 9, 1, 1,\n",
       "                    1, 1, 1, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 7, 7, 7, 7, 7,\n",
       "                    9, 9, 9, 9, 9, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 5, 5, 5,\n",
       "                    5, 5, 7, 7, 7, 7, 7, 9, 9, 9, 9, 9, 1, 1, 1, 1, 1, 3,\n",
       "                    3, 3, 3, 3, 5, 5, 5, 5, 5, 7, 7, 7, 7, 7, 9, 9, 9, 9,\n",
       "                    9, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 7, 7,\n",
       "                    7, 7, 7, 9, 9, 9, 9, 9, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3,\n",
       "                    5, 5, 5, 5, 5, 7, 7, 7, 7, 7, 9, 9, 9, 9, 9, 1, 1, 1,\n",
       "                    1, 1, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 7, 7, 7, 7, 7, 9,\n",
       "                    9, 9, 9, 9, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 5, 5, 5, 5,\n",
       "                    5, 7, 7, 7, 7, 7, 9, 9, 9, 9, 9, 1, 1, 1, 1, 1, 3, 3,\n",
       "                    3, 3, 3, 5, 5, 5, 5, 5, 7, 7, 7, 7, 7, 9, 9, 9, 9, 9,\n",
       "                    1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 7, 7, 7,\n",
       "                    7, 7, 9, 9, 9, 9, 9, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 5,\n",
       "                    5, 5, 5, 5, 7, 7, 7, 7, 7, 9, 9, 9, 9, 9, 1, 1, 1, 1,\n",
       "                    1, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 7, 7, 7, 7, 7, 9, 9,\n",
       "                    9, 9, 9, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5,\n",
       "                    7, 7, 7, 7, 7, 9, 9, 9, 9, 9, 1, 1, 1, 1, 1, 3, 3, 3,\n",
       "                    3, 3, 5, 5, 5, 5, 5, 7, 7, 7, 7, 7, 9, 9, 9, 9, 9, 1,\n",
       "                    1, 1, 1, 1, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 7, 7, 7, 7,\n",
       "                    7, 9, 9, 9, 9, 9, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 5, 5,\n",
       "                    5, 5, 5, 7, 7, 7, 7, 7, 9, 9, 9, 9, 9, 1, 1, 1, 1, 1,\n",
       "                    3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 7, 7, 7, 7, 7, 9, 9, 9,\n",
       "                    9, 9, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 7,\n",
       "                    7, 7, 7, 7, 9, 9, 9, 9, 9, 1, 1, 1, 1, 1, 3, 3, 3, 3,\n",
       "                    3, 5, 5, 5, 5, 5, 7, 7, 7, 7, 7, 9, 9, 9, 9, 9, 1, 1,\n",
       "                    1, 1, 1, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 7, 7, 7, 7, 7,\n",
       "                    9, 9, 9, 9, 9, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 5, 5, 5,\n",
       "                    5, 5, 7, 7, 7, 7, 7, 9, 9, 9, 9, 9, 1, 1, 1, 1, 1, 3,\n",
       "                    3, 3, 3, 3, 5, 5, 5, 5, 5, 7, 7, 7, 7, 7, 9, 9, 9, 9,\n",
       "                    9, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 7, 7,\n",
       "                    7, 7, 7, 9, 9, 9, 9, 9, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3,\n",
       "                    5, 5, 5, 5, 5, 7, 7, 7, 7, 7, 9, 9, 9, 9, 9, 1, 1, 1,\n",
       "                    1, 1, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 7, 7, 7, 7, 7, 9,\n",
       "                    9, 9, 9, 9, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 5, 5, 5, 5,\n",
       "                    5, 7, 7, 7, 7, 7, 9, 9, 9, 9, 9, 1, 1, 1, 1, 1, 3, 3,\n",
       "                    3, 3, 3, 5, 5, 5, 5, 5, 7, 7, 7, 7, 7, 9, 9, 9, 9, 9],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[100, 200, 300, 400, 500, 100, 200, 300, 400, 500, 100,\n",
       "                    200, 300, 400, 500, 100, 200, 300, 400, 500, 100, 200,\n",
       "                    300, 400, 500, 100, 200, 300, 400, 500, 100, 200, 300,\n",
       "                    400, 500, 100, 200, 300, 400, 500, 100, 200, 300, 400,\n",
       "                    500, 100, 200, 300, 400, 500, 100, 200, 300, 400, 500,\n",
       "                    100, 200, 300, 400, 500, 100, 200, 300, 400, 500, 100,\n",
       "                    200, 300, 400, 500, 100, 200, 300, 400, 500, 100, 200,\n",
       "                    300, 400, 500, 100, 200, 300, 400, 500, 100, 200, 300,\n",
       "                    400, 500, 100, 200, 300, 400, 500, 100, 200, 300, 400,\n",
       "                    500, 100, 200, 300, 400, 500, 100, 200, 300, 400, 500,\n",
       "                    100, 200, 300, 400, 500, 100, 200, 300, 400, 500, 100,\n",
       "                    200, 300, 400, 500, 100, 200, 300, 400, 500, 100, 200,\n",
       "                    300, 400, 500, 100, 200, 300, 400, 500, 100, 200, 300,\n",
       "                    400, 500, 100, 200, 300, 400, 500, 100, 200, 300, 400,\n",
       "                    500, 100, 200, 300, 400, 500, 100, 200, 300, 400, 500,\n",
       "                    100, 200, 300, 400, 500, 100, 200, 300, 400, 500, 100,\n",
       "                    200, 300, 400, 500, 100, 200, 300, 400, 500, 100, 200,\n",
       "                    300, 400, 500, 100, 200, 300, 400, 500, 100, 200, 300,\n",
       "                    400, 500, 100, 200, 300, 400, 500, 100, 200, 300, 400,\n",
       "                    500, 100, 200, 300, 400, 500, 100, 200, 300, 400, 500,\n",
       "                    100, 200, 300, 400, 500, 100, 200, 300, 400, 500, 100,\n",
       "                    200, 300, 400, 500, 100, 200, 300, 400, 500, 100, 200,\n",
       "                    300, 400, 500, 100, 200, 300, 400, 500, 100, 200, 300,\n",
       "                    400, 500, 100, 200, 300, 400, 500, 100, 200, 300, 400,\n",
       "                    500, 100, 200, 300, 400, 500, 100, 200, 300, 400, 500,\n",
       "                    100, 200, 300, 400, 500, 100, 200, 300, 400, 500, 100,\n",
       "                    200, 300, 400, 500, 100, 200, 300, 400, 500, 100, 200,\n",
       "                    300, 400, 500, 100, 200, 300, 400, 500, 100, 200, 300,\n",
       "                    400, 500, 100, 200, 300, 400, 500, 100, 200, 300, 400,\n",
       "                    500, 100, 200, 300, 400, 500, 100, 200, 300, 400, 500,\n",
       "                    100, 200, 300, 400, 500, 100, 200, 300, 400, 500, 100,\n",
       "                    200, 300, 400, 500, 100, 200, 300, 400, 500, 100, 200,\n",
       "                    300, 400, 500, 100, 200, 300, 400, 500, 100, 200, 300,\n",
       "                    400, 500, 100, 200, 300, 400, 500, 100, 200, 300, 400,\n",
       "                    500, 100, 200, 300, 400, 500, 100, 200, 300, 400, 500,\n",
       "                    100, 200, 300, 400, 500, 100, 200, 300, 400, 500, 100,\n",
       "                    200, 300, 400, 500, 100, 200, 300, 400, 500, 100, 200,\n",
       "                    300, 400, 500, 100, 200, 300, 400, 500, 100, 200, 300,\n",
       "                    400, 500, 100, 200, 300, 400, 500, 100, 200, 300, 400,\n",
       "                    500, 100, 200, 300, 400, 500, 100, 200, 300, 400, 500,\n",
       "                    100, 200, 300, 400, 500, 100, 200, 300, 400, 500, 100,\n",
       "                    200, 300, 400, 500, 100, 200, 300, 400, 500, 100, 200,\n",
       "                    300, 400, 500, 100, 200, 300, 400, 500, 100, 200, 300,\n",
       "                    400, 500, 100, 200, 300, 400, 500, 100, 200, 300, 400,\n",
       "                    500, 100, 200, 300, 400, 500, 100, 200, 300, 400, 500,\n",
       "                    100, 200, 300, 400, 500, 100, 200, 300, 400, 500, 100,\n",
       "                    200, 300, 400, 500, 100, 200, 300, 400, 500, 100, 200,\n",
       "                    300, 400, 500, 100, 200, 300, 400, 500, 100, 200, 300,\n",
       "                    400, 500, 100, 200, 300, 400, 500, 100, 200, 300, 400,\n",
       "                    500, 100, 200, 300, 400, 500, 100, 200, 300, 400, 500,\n",
       "                    100, 200, 300, 400, 500, 100, 200, 300, 400, 500, 100,\n",
       "                    200, 300, 400, 500, 100, 200, 300, 400, 500, 100, 200,\n",
       "                    300, 400, 500, 100, 200, 300, 400, 500, 100, 200, 300,\n",
       "                    400, 500, 100, 200, 300, 400, 500, 100, 200, 300, 400,\n",
       "                    500, 100, 200, 300, 400, 500, 100, 200, 300, 400, 500,\n",
       "                    100, 200, 300, 400, 500, 100, 200, 300, 400, 500, 100,\n",
       "                    200, 300, 400, 500, 100, 200, 300, 400, 500, 100, 200,\n",
       "                    300, 400, 500, 100, 200, 300, 400, 500, 100, 200, 300,\n",
       "                    400, 500, 100, 200, 300, 400, 500, 100, 200, 300, 400,\n",
       "                    500, 100, 200, 300, 400, 500, 100, 200, 300, 400, 500,\n",
       "                    100, 200, 300, 400, 500, 100, 200, 300, 400, 500, 100,\n",
       "                    200, 300, 400, 500, 100, 200, 300, 400, 500, 100, 200,\n",
       "                    300, 400, 500, 100, 200, 300, 400, 500, 100, 200, 300,\n",
       "                    400, 500, 100, 200, 300, 400, 500, 100, 200, 300, 400,\n",
       "                    500, 100, 200, 300, 400, 500, 100, 200, 300, 400, 500,\n",
       "                    100, 200, 300, 400, 500, 100, 200, 300, 400, 500, 100,\n",
       "                    200, 300, 400, 500, 100, 200, 300, 400, 500, 100, 200,\n",
       "                    300, 400, 500, 100, 200, 300, 400, 500, 100, 200, 300,\n",
       "                    400, 500, 100, 200, 300, 400, 500, 100, 200, 300, 400,\n",
       "                    500, 100, 200, 300, 400, 500, 100, 200, 300, 400, 500,\n",
       "                    100, 200, 300, 400, 500, 100, 200, 300, 400, 500, 100,\n",
       "                    200, 300, 400, 500, 100, 200, 300, 400, 500, 100, 200,\n",
       "                    300, 400, 500, 100, 200, 300, 400, 500, 100, 200, 300,\n",
       "                    400, 500, 100, 200, 300, 400, 500, 100, 200, 300, 400,\n",
       "                    500, 100, 200, 300, 400, 500, 100, 200, 300, 400, 500,\n",
       "                    100, 200, 300, 400, 500, 100, 200, 300, 400, 500, 100,\n",
       "                    200, 300, 400, 500, 100, 200, 300, 400, 500, 100, 200,\n",
       "                    300, 400, 500, 100, 200, 300, 400, 500, 100, 200, 300,\n",
       "                    400, 500, 100, 200, 300, 400, 500, 100, 200, 300, 400,\n",
       "                    500, 100, 200, 300, 400, 500, 100, 200, 300, 400, 500,\n",
       "                    100, 200, 300, 400, 500, 100, 200, 300, 400, 500, 100,\n",
       "                    200, 300, 400, 500, 100, 200, 300, 400, 500],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 7,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 100},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 200},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 300},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 9,\n",
       "   'n_estimators': 500}],\n",
       " 'split0_test_score': array([0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97022901, 0.97022901, 0.97022901, 0.97099237, 0.97022901,\n",
       "        0.97022901, 0.96946565, 0.96946565, 0.97022901, 0.97022901,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.97022901,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97175573, 0.97175573, 0.97099237, 0.97099237, 0.97099237,\n",
       "        0.97175573, 0.97099237, 0.97175573, 0.97099237, 0.97099237,\n",
       "        0.97022901, 0.97022901, 0.97022901, 0.97022901, 0.97099237,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97251908, 0.97251908, 0.97328244, 0.97328244, 0.97328244,\n",
       "        0.97251908, 0.97251908, 0.97251908, 0.97328244, 0.97251908,\n",
       "        0.97099237, 0.97251908, 0.97251908, 0.97099237, 0.97099237,\n",
       "        0.97022901, 0.96946565, 0.97099237, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.9740458 , 0.97480916, 0.97480916, 0.9740458 , 0.9740458 ,\n",
       "        0.97251908, 0.97328244, 0.97251908, 0.97328244, 0.9740458 ,\n",
       "        0.97251908, 0.97251908, 0.97251908, 0.97251908, 0.97251908,\n",
       "        0.97251908, 0.97022901, 0.96946565, 0.97022901, 0.97099237,\n",
       "        0.97099237, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97480916, 0.97480916, 0.97480916, 0.97480916, 0.97480916,\n",
       "        0.97328244, 0.9740458 , 0.9740458 , 0.9740458 , 0.97328244,\n",
       "        0.9740458 , 0.97251908, 0.97328244, 0.97328244, 0.97328244,\n",
       "        0.97022901, 0.97022901, 0.97099237, 0.97022901, 0.97099237,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.9740458 , 0.97480916, 0.97480916, 0.9740458 , 0.97557252,\n",
       "        0.9740458 , 0.97251908, 0.97328244, 0.97480916, 0.9740458 ,\n",
       "        0.97251908, 0.97328244, 0.97328244, 0.97328244, 0.97328244,\n",
       "        0.97175573, 0.97022901, 0.97099237, 0.97099237, 0.97099237,\n",
       "        0.96946565, 0.97022901, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97480916, 0.97328244, 0.97480916, 0.97480916, 0.97557252,\n",
       "        0.9740458 , 0.9740458 , 0.97480916, 0.97480916, 0.97480916,\n",
       "        0.97328244, 0.97328244, 0.97251908, 0.97328244, 0.97251908,\n",
       "        0.97099237, 0.97175573, 0.97175573, 0.97022901, 0.97099237,\n",
       "        0.96946565, 0.96946565, 0.97022901, 0.96946565, 0.97022901,\n",
       "        0.9740458 , 0.9740458 , 0.97328244, 0.9740458 , 0.97480916,\n",
       "        0.97480916, 0.97557252, 0.9740458 , 0.97557252, 0.9740458 ,\n",
       "        0.97328244, 0.97328244, 0.97328244, 0.97328244, 0.97328244,\n",
       "        0.97175573, 0.97175573, 0.97099237, 0.97099237, 0.97022901,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.97022901, 0.97022901, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97099237, 0.97099237, 0.97099237, 0.97099237, 0.97099237,\n",
       "        0.97099237, 0.97175573, 0.97099237, 0.97099237, 0.97099237,\n",
       "        0.97022901, 0.97099237, 0.97022901, 0.97099237, 0.97022901,\n",
       "        0.97022901, 0.96946565, 0.97099237, 0.97099237, 0.97099237,\n",
       "        0.96946565, 0.97022901, 0.97099237, 0.96946565, 0.96946565,\n",
       "        0.97175573, 0.97251908, 0.97175573, 0.97175573, 0.97251908,\n",
       "        0.97251908, 0.97251908, 0.97328244, 0.97099237, 0.97099237,\n",
       "        0.97328244, 0.97251908, 0.97099237, 0.97099237, 0.97251908,\n",
       "        0.97099237, 0.97175573, 0.97099237, 0.97099237, 0.97099237,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.97022901, 0.97099237,\n",
       "        0.9740458 , 0.9740458 , 0.97328244, 0.97328244, 0.97480916,\n",
       "        0.97328244, 0.97328244, 0.97328244, 0.97251908, 0.97328244,\n",
       "        0.97251908, 0.97251908, 0.97251908, 0.97251908, 0.97251908,\n",
       "        0.97099237, 0.97099237, 0.97099237, 0.97099237, 0.97099237,\n",
       "        0.97099237, 0.97099237, 0.96946565, 0.97099237, 0.97022901,\n",
       "        0.97328244, 0.9740458 , 0.9740458 , 0.97328244, 0.9740458 ,\n",
       "        0.97251908, 0.97328244, 0.97328244, 0.97328244, 0.97328244,\n",
       "        0.97251908, 0.97251908, 0.97251908, 0.97251908, 0.97251908,\n",
       "        0.97251908, 0.97099237, 0.97175573, 0.97099237, 0.97099237,\n",
       "        0.97099237, 0.97099237, 0.97022901, 0.96946565, 0.97099237,\n",
       "        0.97480916, 0.9740458 , 0.9740458 , 0.97480916, 0.9740458 ,\n",
       "        0.97557252, 0.9740458 , 0.97328244, 0.97328244, 0.97328244,\n",
       "        0.97175573, 0.97099237, 0.97328244, 0.97328244, 0.97328244,\n",
       "        0.97099237, 0.97175573, 0.97099237, 0.97099237, 0.97251908,\n",
       "        0.97022901, 0.97022901, 0.97175573, 0.97099237, 0.96946565,\n",
       "        0.97480916, 0.97480916, 0.9740458 , 0.9740458 , 0.97328244,\n",
       "        0.97175573, 0.97328244, 0.97328244, 0.97328244, 0.97328244,\n",
       "        0.97251908, 0.97251908, 0.97251908, 0.97251908, 0.97251908,\n",
       "        0.97175573, 0.97175573, 0.97099237, 0.97099237, 0.97175573,\n",
       "        0.97099237, 0.97022901, 0.97099237, 0.97099237, 0.97099237,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97022901, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97099237, 0.97099237, 0.97099237, 0.97022901, 0.97099237,\n",
       "        0.97099237, 0.97175573, 0.97099237, 0.97099237, 0.97099237,\n",
       "        0.97099237, 0.97022901, 0.97022901, 0.97099237, 0.97022901,\n",
       "        0.97099237, 0.97022901, 0.97022901, 0.97022901, 0.97099237,\n",
       "        0.97022901, 0.97022901, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97099237, 0.97328244, 0.97251908, 0.97251908, 0.97251908,\n",
       "        0.97251908, 0.97175573, 0.97328244, 0.97175573, 0.97251908,\n",
       "        0.97099237, 0.97251908, 0.97175573, 0.97175573, 0.97175573,\n",
       "        0.97099237, 0.97099237, 0.97099237, 0.97099237, 0.97099237,\n",
       "        0.97022901, 0.97022901, 0.97022901, 0.96946565, 0.96946565,\n",
       "        0.97328244, 0.9740458 , 0.9740458 , 0.9740458 , 0.97480916,\n",
       "        0.9740458 , 0.9740458 , 0.97480916, 0.9740458 , 0.97480916,\n",
       "        0.97251908, 0.97251908, 0.97328244, 0.97328244, 0.97251908,\n",
       "        0.97175573, 0.97251908, 0.97251908, 0.97251908, 0.97251908,\n",
       "        0.97251908, 0.97251908, 0.97251908, 0.97175573, 0.97175573,\n",
       "        0.97328244, 0.97480916, 0.97480916, 0.97480916, 0.97480916,\n",
       "        0.97480916, 0.97480916, 0.97480916, 0.97480916, 0.97480916,\n",
       "        0.9740458 , 0.9740458 , 0.97328244, 0.97328244, 0.97328244,\n",
       "        0.97251908, 0.97328244, 0.97328244, 0.97328244, 0.97328244,\n",
       "        0.97175573, 0.97175573, 0.97251908, 0.97251908, 0.97251908,\n",
       "        0.97251908, 0.97251908, 0.97251908, 0.97251908, 0.9740458 ,\n",
       "        0.97480916, 0.97480916, 0.97480916, 0.97480916, 0.97480916,\n",
       "        0.97328244, 0.97480916, 0.97480916, 0.97480916, 0.97480916,\n",
       "        0.97328244, 0.97328244, 0.97328244, 0.97328244, 0.97328244,\n",
       "        0.97251908, 0.97328244, 0.97328244, 0.97328244, 0.97328244,\n",
       "        0.9740458 , 0.9740458 , 0.97251908, 0.97328244, 0.9740458 ,\n",
       "        0.9740458 , 0.97480916, 0.97480916, 0.97557252, 0.97557252,\n",
       "        0.97480916, 0.97480916, 0.97480916, 0.9740458 , 0.97480916,\n",
       "        0.97328244, 0.97328244, 0.9740458 , 0.9740458 , 0.97328244,\n",
       "        0.97251908, 0.97328244, 0.97251908, 0.97328244, 0.97328244,\n",
       "        0.9740458 , 0.97175573, 0.97328244, 0.97328244, 0.9740458 ,\n",
       "        0.97633588, 0.97557252, 0.97480916, 0.97557252, 0.97557252,\n",
       "        0.97480916, 0.97480916, 0.9740458 , 0.97480916, 0.97480916,\n",
       "        0.97328244, 0.97328244, 0.97328244, 0.9740458 , 0.9740458 ,\n",
       "        0.97328244, 0.97251908, 0.97328244, 0.97328244, 0.97328244,\n",
       "        0.9740458 , 0.9740458 , 0.97557252, 0.97480916, 0.97328244,\n",
       "        0.9740458 , 0.97633588, 0.97557252, 0.97633588, 0.97557252,\n",
       "        0.9740458 , 0.97480916, 0.97480916, 0.9740458 , 0.97480916,\n",
       "        0.97328244, 0.97328244, 0.9740458 , 0.9740458 , 0.9740458 ,\n",
       "        0.9740458 , 0.97251908, 0.97251908, 0.97328244, 0.97328244,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97022901, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97099237, 0.97099237, 0.97099237, 0.97099237, 0.97099237,\n",
       "        0.97099237, 0.97099237, 0.97099237, 0.97099237, 0.97099237,\n",
       "        0.97022901, 0.97099237, 0.97022901, 0.97022901, 0.97022901,\n",
       "        0.97022901, 0.97099237, 0.97099237, 0.97099237, 0.97099237,\n",
       "        0.97022901, 0.97099237, 0.96946565, 0.97099237, 0.97099237,\n",
       "        0.97175573, 0.97328244, 0.97251908, 0.97251908, 0.97175573,\n",
       "        0.97251908, 0.97175573, 0.97175573, 0.97175573, 0.97175573,\n",
       "        0.97251908, 0.97099237, 0.97175573, 0.97175573, 0.97175573,\n",
       "        0.97175573, 0.97099237, 0.97099237, 0.97175573, 0.97099237,\n",
       "        0.97175573, 0.97099237, 0.97099237, 0.97099237, 0.97099237,\n",
       "        0.97328244, 0.97328244, 0.9740458 , 0.97328244, 0.97251908,\n",
       "        0.97328244, 0.97328244, 0.97251908, 0.97328244, 0.97328244,\n",
       "        0.97175573, 0.97328244, 0.97328244, 0.97175573, 0.97328244,\n",
       "        0.97251908, 0.97175573, 0.97328244, 0.97328244, 0.97328244,\n",
       "        0.97175573, 0.97099237, 0.97251908, 0.97175573, 0.97099237,\n",
       "        0.97557252, 0.97633588, 0.9740458 , 0.97480916, 0.97557252,\n",
       "        0.97480916, 0.9740458 , 0.9740458 , 0.97328244, 0.97328244,\n",
       "        0.97251908, 0.97328244, 0.97328244, 0.97251908, 0.97328244,\n",
       "        0.97328244, 0.97328244, 0.97328244, 0.97328244, 0.97328244,\n",
       "        0.97251908, 0.97175573, 0.97251908, 0.97175573, 0.97251908,\n",
       "        0.9740458 , 0.9740458 , 0.97328244, 0.9740458 , 0.97251908,\n",
       "        0.9740458 , 0.9740458 , 0.97328244, 0.97328244, 0.97557252,\n",
       "        0.97480916, 0.97480916, 0.97328244, 0.9740458 , 0.97328244,\n",
       "        0.97251908, 0.9740458 , 0.97251908, 0.97328244, 0.97251908,\n",
       "        0.97175573, 0.97099237, 0.97251908, 0.97251908, 0.97251908,\n",
       "        0.97251908, 0.97251908, 0.97328244, 0.97251908, 0.97251908,\n",
       "        0.9740458 , 0.97480916, 0.97480916, 0.9740458 , 0.9740458 ,\n",
       "        0.97328244, 0.97328244, 0.97328244, 0.97328244, 0.9740458 ,\n",
       "        0.97328244, 0.97328244, 0.97328244, 0.97328244, 0.97328244,\n",
       "        0.97175573, 0.97251908, 0.97251908, 0.97251908, 0.97251908]),\n",
       " 'split1_test_score': array([0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97175573, 0.97099237, 0.97251908, 0.97175573, 0.97099237,\n",
       "        0.97099237, 0.97175573, 0.97022901, 0.97022901, 0.97022901,\n",
       "        0.97175573, 0.96946565, 0.96870229, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96870229, 0.96946565, 0.97022901,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97251908, 0.97175573, 0.97251908, 0.97175573, 0.97175573,\n",
       "        0.97175573, 0.97175573, 0.97175573, 0.97175573, 0.97175573,\n",
       "        0.97175573, 0.97175573, 0.97175573, 0.97175573, 0.97175573,\n",
       "        0.96946565, 0.96870229, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97328244, 0.9740458 , 0.97328244, 0.97328244, 0.97251908,\n",
       "        0.97175573, 0.97251908, 0.97251908, 0.97251908, 0.97251908,\n",
       "        0.97175573, 0.97175573, 0.97251908, 0.97251908, 0.97175573,\n",
       "        0.97175573, 0.97175573, 0.97175573, 0.97175573, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.9740458 , 0.97480916, 0.97328244, 0.97480916, 0.97480916,\n",
       "        0.97328244, 0.9740458 , 0.9740458 , 0.97328244, 0.9740458 ,\n",
       "        0.97175573, 0.97251908, 0.97251908, 0.97251908, 0.97175573,\n",
       "        0.97251908, 0.97175573, 0.97328244, 0.97175573, 0.97022901,\n",
       "        0.97022901, 0.96946565, 0.97099237, 0.96946565, 0.96946565,\n",
       "        0.97557252, 0.97557252, 0.97557252, 0.97480916, 0.97480916,\n",
       "        0.9740458 , 0.9740458 , 0.97328244, 0.97557252, 0.9740458 ,\n",
       "        0.97251908, 0.97328244, 0.97328244, 0.97251908, 0.97328244,\n",
       "        0.96946565, 0.97251908, 0.97251908, 0.97251908, 0.97175573,\n",
       "        0.96946565, 0.96946565, 0.97175573, 0.97022901, 0.96946565,\n",
       "        0.97633588, 0.97633588, 0.97709924, 0.9778626 , 0.97862595,\n",
       "        0.97633588, 0.97480916, 0.97557252, 0.97557252, 0.97709924,\n",
       "        0.97328244, 0.97480916, 0.97557252, 0.97633588, 0.97328244,\n",
       "        0.97480916, 0.97251908, 0.9740458 , 0.97328244, 0.97328244,\n",
       "        0.97099237, 0.96946565, 0.97022901, 0.97022901, 0.97022901,\n",
       "        0.98015267, 0.9778626 , 0.97938931, 0.9778626 , 0.97862595,\n",
       "        0.97633588, 0.97633588, 0.97633588, 0.97557252, 0.97709924,\n",
       "        0.97709924, 0.97633588, 0.9740458 , 0.97633588, 0.97633588,\n",
       "        0.97175573, 0.9740458 , 0.97251908, 0.97328244, 0.97328244,\n",
       "        0.97022901, 0.97175573, 0.97022901, 0.97022901, 0.96946565,\n",
       "        0.97709924, 0.98015267, 0.97938931, 0.97862595, 0.9778626 ,\n",
       "        0.97938931, 0.97633588, 0.97709924, 0.97709924, 0.97633588,\n",
       "        0.97557252, 0.97557252, 0.97480916, 0.97709924, 0.9778626 ,\n",
       "        0.9740458 , 0.97328244, 0.9740458 , 0.97328244, 0.97099237,\n",
       "        0.97251908, 0.97099237, 0.97022901, 0.97175573, 0.97099237,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96870229, 0.97175573, 0.97022901, 0.97022901, 0.97099237,\n",
       "        0.96870229, 0.97099237, 0.97022901, 0.97022901, 0.97022901,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.97022901, 0.96946565,\n",
       "        0.97099237, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97022901, 0.97251908, 0.97328244, 0.97328244, 0.97022901,\n",
       "        0.97022901, 0.97175573, 0.97175573, 0.97099237, 0.97251908,\n",
       "        0.97099237, 0.97022901, 0.97099237, 0.97099237, 0.97099237,\n",
       "        0.97022901, 0.97022901, 0.97022901, 0.97022901, 0.97022901,\n",
       "        0.97022901, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97557252, 0.97480916, 0.97480916, 0.97557252, 0.9740458 ,\n",
       "        0.97099237, 0.97328244, 0.96946565, 0.97099237, 0.97328244,\n",
       "        0.97175573, 0.97251908, 0.97099237, 0.97099237, 0.97175573,\n",
       "        0.97175573, 0.97099237, 0.97022901, 0.97022901, 0.97099237,\n",
       "        0.96946565, 0.97022901, 0.96946565, 0.97022901, 0.97022901,\n",
       "        0.97328244, 0.9740458 , 0.97633588, 0.97480916, 0.9740458 ,\n",
       "        0.97328244, 0.97480916, 0.97557252, 0.9740458 , 0.97480916,\n",
       "        0.9740458 , 0.97175573, 0.97175573, 0.97328244, 0.97251908,\n",
       "        0.97022901, 0.97175573, 0.97022901, 0.97175573, 0.97175573,\n",
       "        0.97175573, 0.97099237, 0.97022901, 0.97022901, 0.97022901,\n",
       "        0.97480916, 0.97557252, 0.97709924, 0.97633588, 0.97557252,\n",
       "        0.97328244, 0.97328244, 0.9740458 , 0.9740458 , 0.97251908,\n",
       "        0.97328244, 0.97328244, 0.97328244, 0.9740458 , 0.9740458 ,\n",
       "        0.96946565, 0.9740458 , 0.97022901, 0.97251908, 0.97175573,\n",
       "        0.96946565, 0.97022901, 0.96946565, 0.97022901, 0.97099237,\n",
       "        0.97633588, 0.97938931, 0.97480916, 0.97633588, 0.97557252,\n",
       "        0.97480916, 0.97480916, 0.97557252, 0.97557252, 0.9740458 ,\n",
       "        0.97251908, 0.97480916, 0.97480916, 0.97328244, 0.97328244,\n",
       "        0.97175573, 0.9740458 , 0.97175573, 0.97251908, 0.97099237,\n",
       "        0.97251908, 0.97022901, 0.96946565, 0.97099237, 0.97099237,\n",
       "        0.96946565, 0.96946565, 0.97022901, 0.97022901, 0.97022901,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.97022901,\n",
       "        0.97022901, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.97022901, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97328244, 0.97175573, 0.97251908, 0.97175573, 0.97328244,\n",
       "        0.97099237, 0.97251908, 0.97175573, 0.97251908, 0.97251908,\n",
       "        0.97099237, 0.97099237, 0.97251908, 0.97099237, 0.97175573,\n",
       "        0.97022901, 0.97022901, 0.97251908, 0.96946565, 0.97175573,\n",
       "        0.96946565, 0.97175573, 0.97022901, 0.97022901, 0.96946565,\n",
       "        0.97328244, 0.97251908, 0.97328244, 0.97328244, 0.97328244,\n",
       "        0.97251908, 0.97251908, 0.97251908, 0.97251908, 0.97251908,\n",
       "        0.97099237, 0.97251908, 0.97175573, 0.97175573, 0.97175573,\n",
       "        0.97175573, 0.97175573, 0.97251908, 0.97251908, 0.97251908,\n",
       "        0.97175573, 0.97175573, 0.97175573, 0.97251908, 0.97175573,\n",
       "        0.97328244, 0.97480916, 0.97480916, 0.97480916, 0.9740458 ,\n",
       "        0.9740458 , 0.97328244, 0.97480916, 0.9740458 , 0.97480916,\n",
       "        0.97251908, 0.9740458 , 0.97175573, 0.97328244, 0.97328244,\n",
       "        0.97175573, 0.97328244, 0.97251908, 0.97251908, 0.97251908,\n",
       "        0.9740458 , 0.97175573, 0.9740458 , 0.97251908, 0.97175573,\n",
       "        0.97557252, 0.9740458 , 0.97480916, 0.97480916, 0.97480916,\n",
       "        0.97633588, 0.9740458 , 0.9740458 , 0.97557252, 0.97480916,\n",
       "        0.9740458 , 0.9740458 , 0.9740458 , 0.9740458 , 0.9740458 ,\n",
       "        0.97175573, 0.97328244, 0.9740458 , 0.97328244, 0.9740458 ,\n",
       "        0.9740458 , 0.9740458 , 0.97328244, 0.97328244, 0.97328244,\n",
       "        0.97557252, 0.97709924, 0.97633588, 0.97709924, 0.97557252,\n",
       "        0.97557252, 0.97480916, 0.97709924, 0.97633588, 0.97633588,\n",
       "        0.97709924, 0.97633588, 0.97557252, 0.97480916, 0.97480916,\n",
       "        0.9740458 , 0.9740458 , 0.97328244, 0.9740458 , 0.97328244,\n",
       "        0.9740458 , 0.97480916, 0.97480916, 0.9740458 , 0.97328244,\n",
       "        0.9740458 , 0.97938931, 0.9778626 , 0.9778626 , 0.97709924,\n",
       "        0.97709924, 0.97709924, 0.97633588, 0.9778626 , 0.9778626 ,\n",
       "        0.97709924, 0.97633588, 0.97557252, 0.97633588, 0.9778626 ,\n",
       "        0.97709924, 0.97557252, 0.97709924, 0.97557252, 0.97557252,\n",
       "        0.97251908, 0.97633588, 0.97557252, 0.97633588, 0.9740458 ,\n",
       "        0.97862595, 0.97862595, 0.97709924, 0.97709924, 0.97633588,\n",
       "        0.97709924, 0.9778626 , 0.97862595, 0.97709924, 0.97709924,\n",
       "        0.97862595, 0.97633588, 0.97709924, 0.9778626 , 0.9778626 ,\n",
       "        0.97709924, 0.97633588, 0.9778626 , 0.97557252, 0.97557252,\n",
       "        0.97709924, 0.97557252, 0.97480916, 0.97633588, 0.97557252,\n",
       "        0.98091603, 0.98091603, 0.97862595, 0.98015267, 0.97938931,\n",
       "        0.97862595, 0.97938931, 0.97862595, 0.98015267, 0.97938931,\n",
       "        0.97709924, 0.98015267, 0.97633588, 0.97862595, 0.97938931,\n",
       "        0.97633588, 0.97862595, 0.97862595, 0.9778626 , 0.97862595,\n",
       "        0.97709924, 0.97633588, 0.97709924, 0.9740458 , 0.97633588,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97099237, 0.97099237, 0.97099237, 0.96946565, 0.97175573,\n",
       "        0.97022901, 0.97099237, 0.97022901, 0.97099237, 0.97175573,\n",
       "        0.97251908, 0.97022901, 0.97175573, 0.97099237, 0.97099237,\n",
       "        0.97099237, 0.97175573, 0.97099237, 0.97099237, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.97022901, 0.96946565, 0.96946565,\n",
       "        0.97328244, 0.9740458 , 0.97328244, 0.97480916, 0.97480916,\n",
       "        0.97251908, 0.97251908, 0.97328244, 0.97175573, 0.97175573,\n",
       "        0.97328244, 0.97251908, 0.97251908, 0.97328244, 0.97328244,\n",
       "        0.97251908, 0.97328244, 0.97251908, 0.97251908, 0.97328244,\n",
       "        0.97251908, 0.97251908, 0.97328244, 0.97175573, 0.97175573,\n",
       "        0.97480916, 0.97557252, 0.97480916, 0.97557252, 0.97557252,\n",
       "        0.97328244, 0.97175573, 0.97175573, 0.97328244, 0.97251908,\n",
       "        0.97251908, 0.9740458 , 0.97175573, 0.9740458 , 0.97328244,\n",
       "        0.97328244, 0.97328244, 0.97328244, 0.97328244, 0.97328244,\n",
       "        0.97175573, 0.97175573, 0.97328244, 0.97328244, 0.97251908,\n",
       "        0.97862595, 0.97633588, 0.97633588, 0.97480916, 0.97557252,\n",
       "        0.97480916, 0.97328244, 0.97557252, 0.97480916, 0.97557252,\n",
       "        0.97557252, 0.97480916, 0.97328244, 0.97328244, 0.97480916,\n",
       "        0.9740458 , 0.9740458 , 0.9740458 , 0.9740458 , 0.97328244,\n",
       "        0.97328244, 0.97557252, 0.97251908, 0.9740458 , 0.97251908,\n",
       "        0.9740458 , 0.97480916, 0.97709924, 0.97557252, 0.97557252,\n",
       "        0.97251908, 0.97480916, 0.97557252, 0.97633588, 0.9740458 ,\n",
       "        0.97251908, 0.97557252, 0.97480916, 0.9740458 , 0.97557252,\n",
       "        0.9740458 , 0.9740458 , 0.97480916, 0.97557252, 0.97480916,\n",
       "        0.97480916, 0.97633588, 0.9740458 , 0.97328244, 0.9740458 ,\n",
       "        0.97557252, 0.9740458 , 0.97633588, 0.9740458 , 0.97633588,\n",
       "        0.97557252, 0.97557252, 0.97633588, 0.97709924, 0.97633588,\n",
       "        0.97251908, 0.97480916, 0.9740458 , 0.97633588, 0.97557252,\n",
       "        0.97633588, 0.97480916, 0.97557252, 0.97480916, 0.97480916,\n",
       "        0.97557252, 0.9740458 , 0.97480916, 0.9740458 , 0.9740458 ]),\n",
       " 'split2_test_score': array([0.93435115, 0.9351145 , 0.93664122, 0.93664122, 0.93816794,\n",
       "        0.65725191, 0.93587786, 0.93740458, 0.94045802, 0.93816794,\n",
       "        0.93740458, 0.93740458, 0.93587786, 0.93664122, 0.93664122,\n",
       "        0.94427481, 0.93816794, 0.93816794, 0.93664122, 0.93740458,\n",
       "        0.93816794, 0.93664122, 0.93816794, 0.93664122, 0.93664122,\n",
       "        0.93587786, 0.92748092, 0.93664122, 0.93358779, 0.92977099,\n",
       "        0.92900763, 0.88320611, 0.93664122, 0.90916031, 0.92748092,\n",
       "        0.74274809, 0.93664122, 0.93740458, 0.88244275, 0.92977099,\n",
       "        0.93740458, 0.92290076, 0.92290076, 0.93664122, 0.93664122,\n",
       "        0.61908397, 0.93053435, 0.93587786, 0.93740458, 0.93740458,\n",
       "        0.93587786, 0.93129771, 0.91984733, 0.9351145 , 0.91679389,\n",
       "        0.91374046, 0.73282443, 0.86946565, 0.92900763, 0.90534351,\n",
       "        0.58015267, 0.91374046, 0.72900763, 0.67938931, 0.89923664,\n",
       "        0.87022901, 0.93435115, 0.56030534, 0.92061069, 0.93816794,\n",
       "        0.93664122, 0.93358779, 0.93282443, 0.9351145 , 0.93282443,\n",
       "        0.75267176, 0.91068702, 0.87938931, 0.88320611, 0.87022901,\n",
       "        0.93435115, 0.89694656, 0.93358779, 0.81679389, 0.9221374 ,\n",
       "        0.92977099, 0.63664122, 0.93129771, 0.93358779, 0.9       ,\n",
       "        0.55496183, 0.73206107, 0.59923664, 0.71908397, 0.68091603,\n",
       "        0.63587786, 0.8740458 , 0.7740458 , 0.91832061, 0.75954198,\n",
       "        0.87022901, 0.92671756, 0.93358779, 0.78396947, 0.72137405,\n",
       "        0.66793893, 0.91755725, 0.90458015, 0.90152672, 0.90839695,\n",
       "        0.90305344, 0.57480916, 0.90305344, 0.84503817, 0.92366412,\n",
       "        0.66793893, 0.83587786, 0.9259542 , 0.9389313 , 0.8519084 ,\n",
       "        0.93053435, 0.91832061, 0.92290076, 0.72442748, 0.67709924,\n",
       "        0.92061069, 0.91526718, 0.67022901, 0.85725191, 0.84351145,\n",
       "        0.76641221, 0.75267176, 0.68625954, 0.90458015, 0.58167939,\n",
       "        0.90152672, 0.90534351, 0.89847328, 0.8       , 0.89465649,\n",
       "        0.68167939, 0.70610687, 0.78854962, 0.74427481, 0.89007634,\n",
       "        0.93587786, 0.91984733, 0.72137405, 0.67328244, 0.63740458,\n",
       "        0.9129771 , 0.71374046, 0.70916031, 0.85572519, 0.7519084 ,\n",
       "        0.62671756, 0.93664122, 0.82748092, 0.7       , 0.73740458,\n",
       "        0.93816794, 0.93740458, 0.78549618, 0.92366412, 0.65496183,\n",
       "        0.79923664, 0.68778626, 0.89618321, 0.72824427, 0.88778626,\n",
       "        0.72519084, 0.93206107, 0.92442748, 0.85572519, 0.93435115,\n",
       "        0.75877863, 0.79389313, 0.67328244, 0.90229008, 0.8351145 ,\n",
       "        0.9129771 , 0.76641221, 0.73129771, 0.81450382, 0.65496183,\n",
       "        0.92366412, 0.8648855 , 0.74198473, 0.87251908, 0.7351145 ,\n",
       "        0.92900763, 0.91526718, 0.87557252, 0.88396947, 0.93206107,\n",
       "        0.92366412, 0.87938931, 0.77175573, 0.91984733, 0.89618321,\n",
       "        0.90916031, 0.78244275, 0.86717557, 0.89389313, 0.83053435,\n",
       "        0.7778626 , 0.86412214, 0.60152672, 0.85648855, 0.89618321,\n",
       "        0.58167939, 0.70916031, 0.68091603, 0.75648855, 0.75725191,\n",
       "        0.78778626, 0.81526718, 0.93587786, 0.8351145 , 0.89312977,\n",
       "        0.70229008, 0.89312977, 0.9351145 , 0.90992366, 0.71526718,\n",
       "        0.97022901, 0.96870229, 0.96946565, 0.96946565, 0.96870229,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96870229, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96564885, 0.94427481, 0.96641221, 0.9648855 , 0.94274809,\n",
       "        0.94045802, 0.96717557, 0.95801527, 0.9480916 , 0.94351145,\n",
       "        0.96870229, 0.95954198, 0.95419847, 0.94351145, 0.96641221,\n",
       "        0.95419847, 0.96793893, 0.94656489, 0.95114504, 0.95114504,\n",
       "        0.96717557, 0.96717557, 0.9519084 , 0.96183206, 0.94885496,\n",
       "        0.94885496, 0.9389313 , 0.93816794, 0.93969466, 0.9389313 ,\n",
       "        0.9389313 , 0.9389313 , 0.93664122, 0.9389313 , 0.93740458,\n",
       "        0.93969466, 0.93740458, 0.9389313 , 0.93664122, 0.93816794,\n",
       "        0.93740458, 0.94045802, 0.93816794, 0.9389313 , 0.93664122,\n",
       "        0.93664122, 0.93740458, 0.9389313 , 0.93664122, 0.93816794,\n",
       "        0.93740458, 0.9389313 , 0.93587786, 0.9389313 , 0.93740458,\n",
       "        0.93969466, 0.93969466, 0.93816794, 0.93816794, 0.93816794,\n",
       "        0.94045802, 0.93816794, 0.93740458, 0.93587786, 0.93664122,\n",
       "        0.93664122, 0.93816794, 0.93587786, 0.93816794, 0.93587786,\n",
       "        0.93740458, 0.93740458, 0.9351145 , 0.93664122, 0.93740458,\n",
       "        0.93740458, 0.93664122, 0.93053435, 0.93740458, 0.93587786,\n",
       "        0.93587786, 0.93664122, 0.93587786, 0.93664122, 0.93740458,\n",
       "        0.93740458, 0.93587786, 0.93740458, 0.93740458, 0.93587786,\n",
       "        0.93664122, 0.9351145 , 0.93664122, 0.9351145 , 0.93435115,\n",
       "        0.9351145 , 0.93587786, 0.9351145 , 0.93358779, 0.93740458,\n",
       "        0.92900763, 0.93740458, 0.93282443, 0.93358779, 0.92824427,\n",
       "        0.93435115, 0.93587786, 0.93816794, 0.9351145 , 0.93816794,\n",
       "        0.93435115, 0.9351145 , 0.93740458, 0.9351145 , 0.93740458,\n",
       "        0.93664122, 0.93664122, 0.93358779, 0.9351145 , 0.9351145 ,\n",
       "        0.93664122, 0.93129771, 0.93587786, 0.9351145 , 0.93664122,\n",
       "        0.93129771, 0.92824427, 0.93282443, 0.92977099, 0.93435115,\n",
       "        0.93816794, 0.93587786, 0.93358779, 0.93664122, 0.93587786,\n",
       "        0.93358779, 0.9351145 , 0.93282443, 0.93664122, 0.93664122,\n",
       "        0.93282443, 0.93358779, 0.9351145 , 0.9351145 , 0.93587786,\n",
       "        0.93664122, 0.93282443, 0.93587786, 0.93435115, 0.93664122,\n",
       "        0.92900763, 0.93282443, 0.92977099, 0.93129771, 0.92671756,\n",
       "        0.93435115, 0.93587786, 0.9351145 , 0.93587786, 0.93664122,\n",
       "        0.93358779, 0.93587786, 0.9351145 , 0.93435115, 0.93358779,\n",
       "        0.93358779, 0.93282443, 0.93358779, 0.93664122, 0.93358779,\n",
       "        0.93435115, 0.9351145 , 0.93587786, 0.93587786, 0.93664122,\n",
       "        0.93358779, 0.93282443, 0.93358779, 0.92748092, 0.93053435,\n",
       "        0.94045802, 0.93664122, 0.93587786, 0.93587786, 0.9351145 ,\n",
       "        0.93587786, 0.93664122, 0.9351145 , 0.93587786, 0.93358779,\n",
       "        0.93206107, 0.93664122, 0.93435115, 0.9351145 , 0.93587786,\n",
       "        0.93129771, 0.93435115, 0.93435115, 0.93358779, 0.93358779,\n",
       "        0.93358779, 0.93816794, 0.93435115, 0.93435115, 0.93358779,\n",
       "        0.93740458, 0.93664122, 0.93587786, 0.9389313 , 0.93816794,\n",
       "        0.93587786, 0.95038168, 0.93587786, 0.94045802, 0.94045802,\n",
       "        0.95496183, 0.93587786, 0.93969466, 0.93740458, 0.93664122,\n",
       "        0.94503817, 0.93969466, 0.93969466, 0.93816794, 0.93816794,\n",
       "        0.93587786, 0.93587786, 0.93587786, 0.93587786, 0.93740458,\n",
       "        0.93282443, 0.93435115, 0.93435115, 0.93358779, 0.93358779,\n",
       "        0.91755725, 0.9389313 , 0.93816794, 0.9389313 , 0.93816794,\n",
       "        0.90992366, 0.90916031, 0.93740458, 0.92519084, 0.91984733,\n",
       "        0.93816794, 0.90916031, 0.9351145 , 0.88549618, 0.92442748,\n",
       "        0.93740458, 0.93587786, 0.93664122, 0.9351145 , 0.93435115,\n",
       "        0.93282443, 0.93053435, 0.93358779, 0.93358779, 0.93358779,\n",
       "        0.93816794, 0.93740458, 0.93740458, 0.93816794, 0.93816794,\n",
       "        0.91679389, 0.91374046, 0.93282443, 0.91068702, 0.90534351,\n",
       "        0.93816794, 0.74198473, 0.6221374 , 0.87709924, 0.9351145 ,\n",
       "        0.93129771, 0.93664122, 0.93664122, 0.93664122, 0.93435115,\n",
       "        0.93435115, 0.92137405, 0.9351145 , 0.93587786, 0.93587786,\n",
       "        0.9389313 , 0.93969466, 0.9351145 , 0.93969466, 0.9129771 ,\n",
       "        0.77328244, 0.89847328, 0.73816794, 0.9221374 , 0.88854962,\n",
       "        0.93969466, 0.92366412, 0.93435115, 0.61755725, 0.88931298,\n",
       "        0.93740458, 0.9389313 , 0.93282443, 0.93664122, 0.93587786,\n",
       "        0.86717557, 0.93816794, 0.93816794, 0.93587786, 0.93587786,\n",
       "        0.92519084, 0.93969466, 0.9389313 , 0.90839695, 0.91603053,\n",
       "        0.74274809, 0.90839695, 0.93206107, 0.90458015, 0.89618321,\n",
       "        0.61526718, 0.56793893, 0.75038168, 0.76641221, 0.88854962,\n",
       "        0.89541985, 0.93816794, 0.93206107, 0.91755725, 0.93587786,\n",
       "        0.93740458, 0.92977099, 0.9351145 , 0.93816794, 0.93740458,\n",
       "        0.9259542 , 0.90229008, 0.93969466, 0.88320611, 0.93664122,\n",
       "        0.60839695, 0.89160305, 0.90916031, 0.88091603, 0.74656489,\n",
       "        0.93435115, 0.6       , 0.88854962, 0.8870229 , 0.91145038,\n",
       "        0.92900763, 0.93587786, 0.92061069, 0.9259542 , 0.89770992,\n",
       "        0.93740458, 0.93740458, 0.92366412, 0.91145038, 0.90916031,\n",
       "        0.78015267, 0.93969466, 0.91145038, 0.87633588, 0.78778626,\n",
       "        0.92900763, 0.8648855 , 0.61603053, 0.86641221, 0.94045802,\n",
       "        0.86183206, 0.88473282, 0.76030534, 0.79236641, 0.69923664,\n",
       "        0.91221374, 0.89465649, 0.91832061, 0.91526718, 0.92442748,\n",
       "        0.9351145 , 0.93587786, 0.93740458, 0.93129771, 0.93740458,\n",
       "        0.91068702, 0.88549618, 0.90229008, 0.90610687, 0.93664122,\n",
       "        0.7221374 , 0.89236641, 0.60610687, 0.88931298, 0.83435115,\n",
       "        0.69694656, 0.65877863, 0.7389313 , 0.73587786, 0.85801527,\n",
       "        0.91450382, 0.92061069, 0.91832061, 0.92061069, 0.91984733,\n",
       "        0.93816794, 0.93587786, 0.90992366, 0.93740458, 0.93740458,\n",
       "        0.7129771 , 0.88931298, 0.93358779, 0.94122137, 0.94122137,\n",
       "        0.9389313 , 0.90992366, 0.72290076, 0.91374046, 0.91526718,\n",
       "        0.93587786, 0.92900763, 0.61145038, 0.76335878, 0.88931298,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.95877863, 0.96030534, 0.96641221, 0.96030534, 0.96717557,\n",
       "        0.96641221, 0.94503817, 0.96564885, 0.94885496, 0.96641221,\n",
       "        0.93816794, 0.94198473, 0.95038168, 0.94122137, 0.96183206,\n",
       "        0.9389313 , 0.96259542, 0.96717557, 0.94198473, 0.96412214,\n",
       "        0.96030534, 0.96717557, 0.96412214, 0.94198473, 0.9480916 ,\n",
       "        0.93740458, 0.94045802, 0.93816794, 0.9389313 , 0.93664122,\n",
       "        0.94122137, 0.93969466, 0.9389313 , 0.93740458, 0.9389313 ,\n",
       "        0.93816794, 0.93816794, 0.93816794, 0.93969466, 0.93816794,\n",
       "        0.94045802, 0.93816794, 0.93587786, 0.93816794, 0.93816794,\n",
       "        0.93969466, 0.93740458, 0.93740458, 0.93969466, 0.93740458,\n",
       "        0.93206107, 0.93664122, 0.93740458, 0.93664122, 0.93053435,\n",
       "        0.93664122, 0.93664122, 0.93664122, 0.93740458, 0.93740458,\n",
       "        0.93587786, 0.93816794, 0.93969466, 0.93816794, 0.93740458,\n",
       "        0.93740458, 0.93740458, 0.9389313 , 0.93664122, 0.93816794,\n",
       "        0.93740458, 0.93587786, 0.93587786, 0.93664122, 0.93587786,\n",
       "        0.91374046, 0.91145038, 0.90687023, 0.91068702, 0.91221374,\n",
       "        0.93587786, 0.93587786, 0.93664122, 0.93664122, 0.93587786,\n",
       "        0.93740458, 0.93587786, 0.93587786, 0.93664122, 0.93587786,\n",
       "        0.9351145 , 0.93740458, 0.9351145 , 0.93664122, 0.93664122,\n",
       "        0.9351145 , 0.93740458, 0.93664122, 0.93587786, 0.93664122,\n",
       "        0.89694656, 0.90839695, 0.90687023, 0.90610687, 0.90992366,\n",
       "        0.93587786, 0.93740458, 0.93587786, 0.93740458, 0.93740458,\n",
       "        0.9351145 , 0.93587786, 0.93587786, 0.9351145 , 0.9351145 ,\n",
       "        0.93740458, 0.93740458, 0.93664122, 0.93664122, 0.93664122,\n",
       "        0.93435115, 0.93664122, 0.9351145 , 0.93664122, 0.93664122,\n",
       "        0.87480916, 0.90916031, 0.90687023, 0.90534351, 0.90610687,\n",
       "        0.93587786, 0.93664122, 0.93816794, 0.9351145 , 0.93740458,\n",
       "        0.93664122, 0.9351145 , 0.93740458, 0.93664122, 0.9351145 ,\n",
       "        0.93740458, 0.93816794, 0.93587786, 0.93740458, 0.9351145 ,\n",
       "        0.93664122, 0.93587786, 0.93664122, 0.93740458, 0.93664122,\n",
       "        0.90610687, 0.90305344, 0.89770992, 0.90458015, 0.90458015,\n",
       "        0.9351145 , 0.93587786, 0.93664122, 0.93816794, 0.93664122,\n",
       "        0.93282443, 0.93816794, 0.93664122, 0.93740458, 0.93664122,\n",
       "        0.93358779, 0.93664122, 0.93587786, 0.93664122, 0.93740458,\n",
       "        0.9351145 , 0.93435115, 0.93664122, 0.93664122, 0.93664122,\n",
       "        0.90916031, 0.90458015, 0.9       , 0.90305344, 0.89770992,\n",
       "        0.93969466, 0.93587786, 0.9351145 , 0.93664122, 0.9351145 ,\n",
       "        0.93587786, 0.93816794, 0.93740458, 0.93740458, 0.93740458,\n",
       "        0.9351145 , 0.93587786, 0.93740458, 0.93587786, 0.93664122,\n",
       "        0.93664122, 0.93587786, 0.93740458, 0.93587786, 0.9351145 ]),\n",
       " 'split3_test_score': array([0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97022901, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97022901, 0.97022901, 0.96946565, 0.97022901, 0.96946565,\n",
       "        0.97022901, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97251908, 0.97251908, 0.97251908, 0.97251908, 0.97175573,\n",
       "        0.97251908, 0.97022901, 0.97251908, 0.97175573, 0.97175573,\n",
       "        0.97099237, 0.97099237, 0.97099237, 0.97022901, 0.97099237,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.97022901, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97175573, 0.97328244, 0.9740458 , 0.97328244, 0.97328244,\n",
       "        0.9740458 , 0.97328244, 0.97251908, 0.97328244, 0.97328244,\n",
       "        0.97251908, 0.97251908, 0.97328244, 0.97328244, 0.97251908,\n",
       "        0.97328244, 0.97251908, 0.96946565, 0.97099237, 0.97099237,\n",
       "        0.97022901, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.9740458 , 0.97709924, 0.97557252, 0.97480916, 0.97557252,\n",
       "        0.9740458 , 0.97480916, 0.97480916, 0.9740458 , 0.97480916,\n",
       "        0.97251908, 0.9740458 , 0.9740458 , 0.9740458 , 0.9740458 ,\n",
       "        0.97022901, 0.97328244, 0.97175573, 0.97328244, 0.97022901,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97633588, 0.97633588, 0.9778626 , 0.97709924, 0.9778626 ,\n",
       "        0.97480916, 0.97557252, 0.97557252, 0.97557252, 0.97633588,\n",
       "        0.97480916, 0.9740458 , 0.97480916, 0.97557252, 0.97557252,\n",
       "        0.9740458 , 0.97328244, 0.97557252, 0.97480916, 0.97557252,\n",
       "        0.97099237, 0.97251908, 0.97175573, 0.97175573, 0.97099237,\n",
       "        0.9778626 , 0.9778626 , 0.9778626 , 0.9778626 , 0.9778626 ,\n",
       "        0.97709924, 0.97709924, 0.9778626 , 0.97709924, 0.97633588,\n",
       "        0.97557252, 0.97480916, 0.97557252, 0.97480916, 0.97633588,\n",
       "        0.97251908, 0.97328244, 0.97557252, 0.97328244, 0.9740458 ,\n",
       "        0.97099237, 0.97022901, 0.96946565, 0.97099237, 0.97099237,\n",
       "        0.97862595, 0.97938931, 0.97938931, 0.97862595, 0.97862595,\n",
       "        0.9778626 , 0.9778626 , 0.97709924, 0.97709924, 0.97709924,\n",
       "        0.97557252, 0.97633588, 0.97633588, 0.97557252, 0.97633588,\n",
       "        0.9740458 , 0.9740458 , 0.97328244, 0.97480916, 0.9740458 ,\n",
       "        0.97251908, 0.97099237, 0.97099237, 0.97251908, 0.97022901,\n",
       "        0.97938931, 0.97938931, 0.98015267, 0.97938931, 0.97938931,\n",
       "        0.9778626 , 0.97862595, 0.9778626 , 0.97862595, 0.9778626 ,\n",
       "        0.97633588, 0.9740458 , 0.97557252, 0.97633588, 0.97633588,\n",
       "        0.97557252, 0.97328244, 0.9740458 , 0.9740458 , 0.97328244,\n",
       "        0.97328244, 0.9740458 , 0.97328244, 0.97099237, 0.97175573,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97175573, 0.97099237, 0.97099237, 0.97099237, 0.97099237,\n",
       "        0.97099237, 0.97251908, 0.97099237, 0.96946565, 0.97022901,\n",
       "        0.97175573, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97251908, 0.97251908, 0.97251908, 0.97251908, 0.97251908,\n",
       "        0.97251908, 0.97251908, 0.97251908, 0.97251908, 0.97251908,\n",
       "        0.97251908, 0.97251908, 0.97251908, 0.97251908, 0.97251908,\n",
       "        0.97251908, 0.97099237, 0.97251908, 0.97175573, 0.97175573,\n",
       "        0.97099237, 0.97022901, 0.97099237, 0.97099237, 0.97099237,\n",
       "        0.97480916, 0.97328244, 0.97328244, 0.97251908, 0.9740458 ,\n",
       "        0.9740458 , 0.97251908, 0.97251908, 0.97328244, 0.97328244,\n",
       "        0.97251908, 0.97251908, 0.97251908, 0.97251908, 0.97251908,\n",
       "        0.97251908, 0.97251908, 0.97251908, 0.97099237, 0.97251908,\n",
       "        0.96946565, 0.97099237, 0.97099237, 0.97099237, 0.97099237,\n",
       "        0.97709924, 0.97633588, 0.97862595, 0.97557252, 0.97709924,\n",
       "        0.9740458 , 0.97328244, 0.9740458 , 0.97480916, 0.9740458 ,\n",
       "        0.97251908, 0.97251908, 0.97328244, 0.97251908, 0.9740458 ,\n",
       "        0.97099237, 0.97251908, 0.97175573, 0.97099237, 0.97251908,\n",
       "        0.97099237, 0.97099237, 0.97099237, 0.97099237, 0.97175573,\n",
       "        0.97709924, 0.9778626 , 0.9778626 , 0.9778626 , 0.9778626 ,\n",
       "        0.97480916, 0.97557252, 0.97557252, 0.97709924, 0.97557252,\n",
       "        0.97480916, 0.9740458 , 0.97328244, 0.9740458 , 0.97480916,\n",
       "        0.9740458 , 0.97251908, 0.97251908, 0.97251908, 0.97175573,\n",
       "        0.97175573, 0.97099237, 0.97099237, 0.97022901, 0.97099237,\n",
       "        0.97862595, 0.98091603, 0.98015267, 0.97862595, 0.98015267,\n",
       "        0.97862595, 0.97557252, 0.9778626 , 0.97709924, 0.97709924,\n",
       "        0.9740458 , 0.97557252, 0.97480916, 0.97480916, 0.9740458 ,\n",
       "        0.97328244, 0.97328244, 0.9740458 , 0.9740458 , 0.9740458 ,\n",
       "        0.97328244, 0.97099237, 0.97251908, 0.97099237, 0.97099237,\n",
       "        0.98015267, 0.98091603, 0.98091603, 0.98091603, 0.98091603,\n",
       "        0.97938931, 0.97938931, 0.9778626 , 0.9778626 , 0.97938931,\n",
       "        0.97480916, 0.97557252, 0.97557252, 0.97557252, 0.97557252,\n",
       "        0.97328244, 0.9740458 , 0.97328244, 0.97251908, 0.97251908,\n",
       "        0.97099237, 0.97099237, 0.97251908, 0.97099237, 0.97175573,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97251908, 0.97022901, 0.97099237, 0.97022901, 0.97099237,\n",
       "        0.97099237, 0.97099237, 0.97099237, 0.97099237, 0.97099237,\n",
       "        0.97099237, 0.97022901, 0.96946565, 0.96946565, 0.97022901,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97251908, 0.97251908, 0.97251908, 0.97251908, 0.97251908,\n",
       "        0.97099237, 0.97251908, 0.97251908, 0.97251908, 0.97251908,\n",
       "        0.97251908, 0.97251908, 0.97099237, 0.97175573, 0.97175573,\n",
       "        0.97175573, 0.97099237, 0.97099237, 0.97099237, 0.97099237,\n",
       "        0.97099237, 0.96946565, 0.97022901, 0.96946565, 0.97022901,\n",
       "        0.9740458 , 0.9740458 , 0.97328244, 0.9740458 , 0.97328244,\n",
       "        0.97480916, 0.97328244, 0.97480916, 0.97328244, 0.97328244,\n",
       "        0.97328244, 0.9740458 , 0.9740458 , 0.97328244, 0.97328244,\n",
       "        0.97328244, 0.97328244, 0.97328244, 0.97328244, 0.97328244,\n",
       "        0.97251908, 0.97251908, 0.97251908, 0.97328244, 0.97099237,\n",
       "        0.97480916, 0.97480916, 0.97557252, 0.97480916, 0.97557252,\n",
       "        0.97480916, 0.97557252, 0.97557252, 0.97633588, 0.9740458 ,\n",
       "        0.97557252, 0.97557252, 0.97480916, 0.9740458 , 0.97480916,\n",
       "        0.97328244, 0.97480916, 0.9740458 , 0.97480916, 0.97480916,\n",
       "        0.9740458 , 0.9740458 , 0.97328244, 0.9740458 , 0.9740458 ,\n",
       "        0.97709924, 0.97709924, 0.97709924, 0.97709924, 0.97709924,\n",
       "        0.97633588, 0.97709924, 0.97709924, 0.97633588, 0.97633588,\n",
       "        0.97633588, 0.97557252, 0.97557252, 0.97557252, 0.97557252,\n",
       "        0.9740458 , 0.97557252, 0.97557252, 0.97557252, 0.97480916,\n",
       "        0.97480916, 0.9740458 , 0.97480916, 0.97480916, 0.97480916,\n",
       "        0.97633588, 0.97709924, 0.97709924, 0.97709924, 0.97709924,\n",
       "        0.97709924, 0.97709924, 0.97709924, 0.97709924, 0.97709924,\n",
       "        0.97709924, 0.97557252, 0.97557252, 0.97557252, 0.97633588,\n",
       "        0.97557252, 0.97633588, 0.97557252, 0.97557252, 0.97557252,\n",
       "        0.97480916, 0.9740458 , 0.97557252, 0.97557252, 0.97480916,\n",
       "        0.9778626 , 0.97938931, 0.97938931, 0.97862595, 0.97938931,\n",
       "        0.97862595, 0.97862595, 0.97862595, 0.97862595, 0.97862595,\n",
       "        0.97633588, 0.97709924, 0.97709924, 0.97557252, 0.97633588,\n",
       "        0.97709924, 0.97633588, 0.97709924, 0.97557252, 0.97633588,\n",
       "        0.97557252, 0.97480916, 0.97480916, 0.97480916, 0.97557252,\n",
       "        0.97938931, 0.97938931, 0.98015267, 0.97938931, 0.97938931,\n",
       "        0.97938931, 0.97938931, 0.97938931, 0.97938931, 0.97938931,\n",
       "        0.9778626 , 0.97709924, 0.97862595, 0.97862595, 0.9778626 ,\n",
       "        0.97709924, 0.97557252, 0.97633588, 0.97633588, 0.97633588,\n",
       "        0.9740458 , 0.97633588, 0.97633588, 0.97633588, 0.97633588,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97099237, 0.96946565, 0.97099237, 0.96946565, 0.97099237,\n",
       "        0.96946565, 0.97022901, 0.97022901, 0.97022901, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97328244, 0.97251908, 0.97251908, 0.97251908, 0.97251908,\n",
       "        0.97251908, 0.97022901, 0.97175573, 0.97251908, 0.97251908,\n",
       "        0.97251908, 0.97251908, 0.97251908, 0.97251908, 0.97251908,\n",
       "        0.97099237, 0.97251908, 0.97099237, 0.97022901, 0.97251908,\n",
       "        0.97251908, 0.97251908, 0.97022901, 0.97251908, 0.97099237,\n",
       "        0.9740458 , 0.97251908, 0.97328244, 0.9740458 , 0.97328244,\n",
       "        0.97328244, 0.97480916, 0.9740458 , 0.97557252, 0.97328244,\n",
       "        0.97328244, 0.9740458 , 0.97328244, 0.97251908, 0.97251908,\n",
       "        0.97251908, 0.97251908, 0.97251908, 0.97251908, 0.97251908,\n",
       "        0.97251908, 0.97099237, 0.97175573, 0.97251908, 0.97099237,\n",
       "        0.97862595, 0.9778626 , 0.97557252, 0.9778626 , 0.97862595,\n",
       "        0.97557252, 0.97557252, 0.97557252, 0.97633588, 0.97557252,\n",
       "        0.97480916, 0.97480916, 0.97480916, 0.97480916, 0.97328244,\n",
       "        0.97328244, 0.97328244, 0.97328244, 0.97328244, 0.97328244,\n",
       "        0.97251908, 0.97099237, 0.97251908, 0.97175573, 0.97251908,\n",
       "        0.97862595, 0.97633588, 0.9778626 , 0.97862595, 0.97862595,\n",
       "        0.9778626 , 0.97862595, 0.97633588, 0.9778626 , 0.9778626 ,\n",
       "        0.97557252, 0.97633588, 0.97557252, 0.97480916, 0.97480916,\n",
       "        0.97709924, 0.9740458 , 0.9740458 , 0.9740458 , 0.9740458 ,\n",
       "        0.97328244, 0.97175573, 0.97251908, 0.97251908, 0.97328244,\n",
       "        0.97862595, 0.98244275, 0.97938931, 0.97938931, 0.98015267,\n",
       "        0.98015267, 0.98015267, 0.97862595, 0.97862595, 0.9778626 ,\n",
       "        0.97633588, 0.97633588, 0.97862595, 0.97557252, 0.97633588,\n",
       "        0.97328244, 0.9740458 , 0.97557252, 0.9740458 , 0.9740458 ,\n",
       "        0.9740458 , 0.9740458 , 0.9740458 , 0.9740458 , 0.97251908,\n",
       "        0.98244275, 0.98167939, 0.98091603, 0.97862595, 0.98167939,\n",
       "        0.98091603, 0.98091603, 0.97938931, 0.98015267, 0.98091603,\n",
       "        0.97633588, 0.98015267, 0.97862595, 0.97938931, 0.97862595,\n",
       "        0.97633588, 0.97633588, 0.97557252, 0.97709924, 0.9778626 ,\n",
       "        0.97480916, 0.97557252, 0.97328244, 0.97328244, 0.97328244]),\n",
       " 'split4_test_score': array([0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97099237, 0.97175573, 0.97175573, 0.97099237, 0.97099237,\n",
       "        0.97099237, 0.97022901, 0.97099237, 0.97099237, 0.97022901,\n",
       "        0.97099237, 0.96946565, 0.97022901, 0.96946565, 0.97022901,\n",
       "        0.97022901, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97175573, 0.97175573, 0.97175573, 0.97175573, 0.97175573,\n",
       "        0.97175573, 0.97175573, 0.97175573, 0.97099237, 0.97099237,\n",
       "        0.97022901, 0.97099237, 0.97175573, 0.97022901, 0.97099237,\n",
       "        0.97022901, 0.97022901, 0.97022901, 0.97022901, 0.97022901,\n",
       "        0.96946565, 0.97022901, 0.96946565, 0.96946565, 0.97022901,\n",
       "        0.97328244, 0.97328244, 0.97251908, 0.97251908, 0.97251908,\n",
       "        0.97328244, 0.97251908, 0.97251908, 0.97251908, 0.97328244,\n",
       "        0.97175573, 0.97175573, 0.97175573, 0.97175573, 0.97175573,\n",
       "        0.97022901, 0.97022901, 0.97022901, 0.97022901, 0.97022901,\n",
       "        0.96946565, 0.96946565, 0.97022901, 0.96946565, 0.97022901,\n",
       "        0.97328244, 0.97480916, 0.9740458 , 0.9740458 , 0.9740458 ,\n",
       "        0.9740458 , 0.9740458 , 0.9740458 , 0.9740458 , 0.9740458 ,\n",
       "        0.97251908, 0.97175573, 0.97022901, 0.97328244, 0.97251908,\n",
       "        0.97022901, 0.97175573, 0.97251908, 0.97175573, 0.97022901,\n",
       "        0.97099237, 0.96946565, 0.97022901, 0.97022901, 0.96946565,\n",
       "        0.97480916, 0.97480916, 0.9740458 , 0.97480916, 0.9740458 ,\n",
       "        0.97328244, 0.9740458 , 0.9740458 , 0.9740458 , 0.97328244,\n",
       "        0.9740458 , 0.9740458 , 0.97251908, 0.9740458 , 0.9740458 ,\n",
       "        0.97175573, 0.97022901, 0.97022901, 0.97251908, 0.97022901,\n",
       "        0.97022901, 0.97022901, 0.97022901, 0.97022901, 0.97022901,\n",
       "        0.9740458 , 0.97480916, 0.9740458 , 0.9740458 , 0.97480916,\n",
       "        0.97328244, 0.97328244, 0.9740458 , 0.97328244, 0.9740458 ,\n",
       "        0.97480916, 0.97251908, 0.9740458 , 0.9740458 , 0.9740458 ,\n",
       "        0.97175573, 0.97099237, 0.97175573, 0.97175573, 0.97022901,\n",
       "        0.97099237, 0.97022901, 0.97022901, 0.97022901, 0.97022901,\n",
       "        0.97480916, 0.97480916, 0.97480916, 0.97480916, 0.9740458 ,\n",
       "        0.97328244, 0.97328244, 0.9740458 , 0.9740458 , 0.9740458 ,\n",
       "        0.97251908, 0.97328244, 0.97328244, 0.9740458 , 0.9740458 ,\n",
       "        0.97175573, 0.97099237, 0.97175573, 0.97251908, 0.97251908,\n",
       "        0.97022901, 0.97022901, 0.96946565, 0.97022901, 0.97022901,\n",
       "        0.97480916, 0.97557252, 0.97633588, 0.97633588, 0.97557252,\n",
       "        0.9740458 , 0.9740458 , 0.9740458 , 0.97480916, 0.97328244,\n",
       "        0.9740458 , 0.9740458 , 0.9740458 , 0.9740458 , 0.9740458 ,\n",
       "        0.97175573, 0.97175573, 0.97175573, 0.97099237, 0.97251908,\n",
       "        0.96946565, 0.97022901, 0.97022901, 0.97022901, 0.97022901,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97022901, 0.97022901, 0.97022901, 0.97022901, 0.97022901,\n",
       "        0.97099237, 0.97022901, 0.97022901, 0.97022901, 0.97022901,\n",
       "        0.97022901, 0.97022901, 0.97022901, 0.97022901, 0.97022901,\n",
       "        0.97022901, 0.97022901, 0.97022901, 0.97022901, 0.97022901,\n",
       "        0.97099237, 0.97022901, 0.97022901, 0.97022901, 0.96946565,\n",
       "        0.97099237, 0.97175573, 0.97251908, 0.97099237, 0.97251908,\n",
       "        0.97022901, 0.97251908, 0.97099237, 0.97099237, 0.97251908,\n",
       "        0.97175573, 0.97022901, 0.97022901, 0.97099237, 0.97099237,\n",
       "        0.97022901, 0.97099237, 0.97175573, 0.97022901, 0.97022901,\n",
       "        0.96946565, 0.97022901, 0.97022901, 0.97022901, 0.97022901,\n",
       "        0.97328244, 0.97175573, 0.97251908, 0.97251908, 0.97175573,\n",
       "        0.97099237, 0.97175573, 0.97175573, 0.97099237, 0.97251908,\n",
       "        0.97251908, 0.97251908, 0.97175573, 0.97175573, 0.97251908,\n",
       "        0.97099237, 0.97175573, 0.97099237, 0.97251908, 0.97099237,\n",
       "        0.97099237, 0.97099237, 0.97251908, 0.97022901, 0.97099237,\n",
       "        0.97328244, 0.97328244, 0.9740458 , 0.97633588, 0.9740458 ,\n",
       "        0.97251908, 0.97251908, 0.97328244, 0.97175573, 0.97175573,\n",
       "        0.97251908, 0.97251908, 0.97251908, 0.97251908, 0.97251908,\n",
       "        0.97175573, 0.97251908, 0.97251908, 0.97175573, 0.97251908,\n",
       "        0.97099237, 0.97175573, 0.97022901, 0.97099237, 0.97099237,\n",
       "        0.9740458 , 0.9740458 , 0.97480916, 0.9740458 , 0.97480916,\n",
       "        0.97328244, 0.97251908, 0.97251908, 0.97251908, 0.97328244,\n",
       "        0.97251908, 0.97175573, 0.97251908, 0.97251908, 0.97175573,\n",
       "        0.97251908, 0.97251908, 0.97251908, 0.97175573, 0.97251908,\n",
       "        0.96946565, 0.97099237, 0.97022901, 0.97099237, 0.97099237,\n",
       "        0.9740458 , 0.97480916, 0.9740458 , 0.97480916, 0.97480916,\n",
       "        0.9740458 , 0.9740458 , 0.97251908, 0.97480916, 0.9740458 ,\n",
       "        0.97175573, 0.97175573, 0.97175573, 0.97175573, 0.97251908,\n",
       "        0.97175573, 0.97099237, 0.97175573, 0.97251908, 0.97251908,\n",
       "        0.97099237, 0.97251908, 0.97099237, 0.97251908, 0.97099237,\n",
       "        0.97557252, 0.97557252, 0.97709924, 0.97557252, 0.97709924,\n",
       "        0.97328244, 0.97251908, 0.9740458 , 0.9740458 , 0.97328244,\n",
       "        0.97328244, 0.97175573, 0.97175573, 0.97175573, 0.97175573,\n",
       "        0.97022901, 0.97251908, 0.97251908, 0.97175573, 0.97251908,\n",
       "        0.97175573, 0.97251908, 0.97251908, 0.97099237, 0.97251908,\n",
       "        0.96946565, 0.97099237, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97022901, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97175573, 0.97175573, 0.97175573, 0.97175573, 0.97175573,\n",
       "        0.97022901, 0.97175573, 0.97175573, 0.97175573, 0.97175573,\n",
       "        0.97175573, 0.97099237, 0.97175573, 0.97175573, 0.97099237,\n",
       "        0.97099237, 0.97022901, 0.97099237, 0.97099237, 0.97099237,\n",
       "        0.97175573, 0.97022901, 0.97022901, 0.97099237, 0.97022901,\n",
       "        0.97175573, 0.97175573, 0.97251908, 0.97175573, 0.97175573,\n",
       "        0.97328244, 0.97175573, 0.97175573, 0.97175573, 0.97175573,\n",
       "        0.97251908, 0.97099237, 0.97251908, 0.97175573, 0.97175573,\n",
       "        0.97175573, 0.97175573, 0.97099237, 0.97175573, 0.97175573,\n",
       "        0.97175573, 0.97175573, 0.97175573, 0.97175573, 0.97175573,\n",
       "        0.97251908, 0.97175573, 0.97175573, 0.97175573, 0.97251908,\n",
       "        0.97251908, 0.97251908, 0.97175573, 0.97251908, 0.97251908,\n",
       "        0.97251908, 0.97251908, 0.97328244, 0.97175573, 0.97328244,\n",
       "        0.97251908, 0.97251908, 0.97251908, 0.97251908, 0.97251908,\n",
       "        0.97175573, 0.97175573, 0.97251908, 0.97175573, 0.97251908,\n",
       "        0.9740458 , 0.9740458 , 0.9740458 , 0.9740458 , 0.97328244,\n",
       "        0.97328244, 0.97251908, 0.97328244, 0.97328244, 0.97328244,\n",
       "        0.97251908, 0.97328244, 0.97328244, 0.9740458 , 0.97328244,\n",
       "        0.97251908, 0.97328244, 0.97328244, 0.97251908, 0.97328244,\n",
       "        0.97251908, 0.97251908, 0.97251908, 0.97175573, 0.97251908,\n",
       "        0.9740458 , 0.97480916, 0.97328244, 0.97557252, 0.97480916,\n",
       "        0.9740458 , 0.97480916, 0.9740458 , 0.9740458 , 0.9740458 ,\n",
       "        0.97328244, 0.97328244, 0.97328244, 0.9740458 , 0.9740458 ,\n",
       "        0.9740458 , 0.97328244, 0.97328244, 0.97328244, 0.97328244,\n",
       "        0.97251908, 0.97251908, 0.97175573, 0.97175573, 0.97175573,\n",
       "        0.97633588, 0.97633588, 0.97480916, 0.97480916, 0.97633588,\n",
       "        0.97557252, 0.97557252, 0.97557252, 0.97480916, 0.97480916,\n",
       "        0.97480916, 0.97480916, 0.97480916, 0.9740458 , 0.97328244,\n",
       "        0.97175573, 0.97328244, 0.97251908, 0.97328244, 0.9740458 ,\n",
       "        0.97251908, 0.97175573, 0.97251908, 0.97251908, 0.97175573,\n",
       "        0.97557252, 0.97557252, 0.97709924, 0.97557252, 0.97557252,\n",
       "        0.97480916, 0.97709924, 0.97557252, 0.97557252, 0.97557252,\n",
       "        0.97480916, 0.9740458 , 0.97480916, 0.97480916, 0.97480916,\n",
       "        0.97328244, 0.97328244, 0.97328244, 0.97328244, 0.97328244,\n",
       "        0.97251908, 0.97251908, 0.97251908, 0.97328244, 0.97251908,\n",
       "        0.97633588, 0.97709924, 0.97633588, 0.97633588, 0.97633588,\n",
       "        0.97633588, 0.97633588, 0.97633588, 0.97709924, 0.97633588,\n",
       "        0.97557252, 0.97633588, 0.97633588, 0.97633588, 0.97557252,\n",
       "        0.97251908, 0.97328244, 0.97328244, 0.9740458 , 0.9740458 ,\n",
       "        0.97175573, 0.97251908, 0.97251908, 0.97328244, 0.97251908,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97099237, 0.97022901, 0.97022901, 0.97022901, 0.97022901,\n",
       "        0.97022901, 0.97022901, 0.97022901, 0.97022901, 0.97022901,\n",
       "        0.97022901, 0.97022901, 0.97022901, 0.97022901, 0.97022901,\n",
       "        0.97022901, 0.97022901, 0.97022901, 0.97022901, 0.97022901,\n",
       "        0.97022901, 0.97022901, 0.97022901, 0.97022901, 0.97022901,\n",
       "        0.97175573, 0.97099237, 0.97099237, 0.97099237, 0.97099237,\n",
       "        0.97099237, 0.97099237, 0.97099237, 0.97099237, 0.97175573,\n",
       "        0.97022901, 0.97099237, 0.97099237, 0.97099237, 0.97175573,\n",
       "        0.97175573, 0.97099237, 0.97099237, 0.97099237, 0.97099237,\n",
       "        0.97099237, 0.97022901, 0.97099237, 0.97099237, 0.97099237,\n",
       "        0.97328244, 0.97175573, 0.97251908, 0.97251908, 0.97099237,\n",
       "        0.97099237, 0.97251908, 0.97099237, 0.97175573, 0.97022901,\n",
       "        0.97175573, 0.97175573, 0.97099237, 0.97099237, 0.97099237,\n",
       "        0.97022901, 0.97022901, 0.97251908, 0.97099237, 0.97022901,\n",
       "        0.97022901, 0.97022901, 0.97099237, 0.97099237, 0.97022901,\n",
       "        0.97328244, 0.97480916, 0.9740458 , 0.97480916, 0.97480916,\n",
       "        0.97251908, 0.97251908, 0.97251908, 0.97175573, 0.97251908,\n",
       "        0.9740458 , 0.97251908, 0.97175573, 0.97175573, 0.97175573,\n",
       "        0.97175573, 0.97099237, 0.97022901, 0.97175573, 0.97175573,\n",
       "        0.97251908, 0.97251908, 0.97175573, 0.97099237, 0.97099237,\n",
       "        0.97557252, 0.9740458 , 0.97557252, 0.97480916, 0.97633588,\n",
       "        0.9740458 , 0.97480916, 0.97557252, 0.97480916, 0.97480916,\n",
       "        0.97251908, 0.97328244, 0.9740458 , 0.97328244, 0.97251908,\n",
       "        0.97328244, 0.97099237, 0.97251908, 0.97328244, 0.97175573,\n",
       "        0.97099237, 0.97099237, 0.97099237, 0.97099237, 0.97022901,\n",
       "        0.97557252, 0.97557252, 0.97709924, 0.97633588, 0.97633588,\n",
       "        0.9740458 , 0.97480916, 0.97480916, 0.97480916, 0.97557252,\n",
       "        0.97328244, 0.9740458 , 0.9740458 , 0.9740458 , 0.97328244,\n",
       "        0.97175573, 0.97251908, 0.9740458 , 0.9740458 , 0.97328244,\n",
       "        0.97175573, 0.97251908, 0.97328244, 0.97328244, 0.97251908,\n",
       "        0.97557252, 0.97557252, 0.97633588, 0.97557252, 0.97633588,\n",
       "        0.97480916, 0.97557252, 0.97557252, 0.97557252, 0.97480916,\n",
       "        0.97480916, 0.9740458 , 0.9740458 , 0.9740458 , 0.9740458 ,\n",
       "        0.97251908, 0.97328244, 0.9740458 , 0.9740458 , 0.9740458 ,\n",
       "        0.97251908, 0.97175573, 0.97175573, 0.97251908, 0.97328244]),\n",
       " 'mean_test_score': array([0.96244275, 0.96259542, 0.96290076, 0.96290076, 0.96320611,\n",
       "        0.9070229 , 0.96274809, 0.96305344, 0.96366412, 0.96320611,\n",
       "        0.96305344, 0.96305344, 0.96274809, 0.96290076, 0.96290076,\n",
       "        0.96442748, 0.96320611, 0.96320611, 0.96290076, 0.96305344,\n",
       "        0.96320611, 0.96290076, 0.96320611, 0.96290076, 0.96290076,\n",
       "        0.96381679, 0.96198473, 0.96412214, 0.96335878, 0.96229008,\n",
       "        0.96229008, 0.9529771 , 0.96335878, 0.95816794, 0.96152672,\n",
       "        0.92503817, 0.96290076, 0.96305344, 0.95206107, 0.96183206,\n",
       "        0.96320611, 0.96015267, 0.96      , 0.96290076, 0.96305344,\n",
       "        0.89938931, 0.96167939, 0.96274809, 0.96305344, 0.96305344,\n",
       "        0.9648855 , 0.96381679, 0.96152672, 0.96442748, 0.96061069,\n",
       "        0.96030534, 0.92351145, 0.95145038, 0.96290076, 0.95816794,\n",
       "        0.89267176, 0.95954198, 0.92274809, 0.91236641, 0.95679389,\n",
       "        0.94977099, 0.96244275, 0.88778626, 0.96      , 0.96335878,\n",
       "        0.96290076, 0.96244275, 0.9621374 , 0.96259542, 0.96229008,\n",
       "        0.92870229, 0.96076336, 0.95450382, 0.9551145 , 0.95236641,\n",
       "        0.96519084, 0.95755725, 0.96473282, 0.94167939, 0.96274809,\n",
       "        0.96335878, 0.90503817, 0.96427481, 0.96442748, 0.95740458,\n",
       "        0.8880916 , 0.92320611, 0.89633588, 0.92030534, 0.91221374,\n",
       "        0.90290076, 0.95038168, 0.93053435, 0.95923664, 0.92763359,\n",
       "        0.95312977, 0.96564885, 0.96625954, 0.93633588, 0.92396947,\n",
       "        0.91236641, 0.96274809, 0.96      , 0.95923664, 0.9610687 ,\n",
       "        0.95847328, 0.89312977, 0.95847328, 0.94748092, 0.96290076,\n",
       "        0.91068702, 0.94458015, 0.96259542, 0.96519084, 0.94671756,\n",
       "        0.96244275, 0.95923664, 0.96061069, 0.92061069, 0.91099237,\n",
       "        0.96442748, 0.96335878, 0.91450382, 0.95175573, 0.94900763,\n",
       "        0.93236641, 0.93007634, 0.91664122, 0.96076336, 0.89572519,\n",
       "        0.95938931, 0.95984733, 0.95847328, 0.93908397, 0.95816794,\n",
       "        0.91343511, 0.91847328, 0.93557252, 0.92687023, 0.95572519,\n",
       "        0.96320611, 0.96030534, 0.92091603, 0.91099237, 0.90351145,\n",
       "        0.96305344, 0.92351145, 0.92259542, 0.9519084 , 0.93175573,\n",
       "        0.90549618, 0.96687023, 0.94564885, 0.92015267, 0.92778626,\n",
       "        0.96687023, 0.96656489, 0.93679389, 0.96442748, 0.91038168,\n",
       "        0.93801527, 0.91496183, 0.95770992, 0.92351145, 0.95526718,\n",
       "        0.92152672, 0.96244275, 0.96076336, 0.94732824, 0.96305344,\n",
       "        0.93343511, 0.93984733, 0.91633588, 0.96167939, 0.94839695,\n",
       "        0.96290076, 0.93358779, 0.92671756, 0.94320611, 0.91160305,\n",
       "        0.96442748, 0.95282443, 0.92763359, 0.95435115, 0.92687023,\n",
       "        0.96351145, 0.96122137, 0.9529771 , 0.95496183, 0.96458015,\n",
       "        0.96122137, 0.95236641, 0.93053435, 0.96045802, 0.95526718,\n",
       "        0.96290076, 0.93832061, 0.95526718, 0.96045802, 0.94763359,\n",
       "        0.93679389, 0.95374046, 0.90091603, 0.95251908, 0.95954198,\n",
       "        0.89618321, 0.92122137, 0.91572519, 0.93145038, 0.93175573,\n",
       "        0.93618321, 0.9410687 , 0.96534351, 0.9448855 , 0.95603053,\n",
       "        0.91740458, 0.95557252, 0.96366412, 0.95847328, 0.91954198,\n",
       "        0.96961832, 0.96931298, 0.96946565, 0.96946565, 0.96931298,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96931298, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96870229, 0.96442748, 0.96885496, 0.96854962, 0.96412214,\n",
       "        0.96366412, 0.96900763, 0.96717557, 0.96519084, 0.96427481,\n",
       "        0.96931298, 0.96748092, 0.96641221, 0.96427481, 0.96885496,\n",
       "        0.96641221, 0.96916031, 0.9648855 , 0.96580153, 0.96580153,\n",
       "        0.96900763, 0.96900763, 0.9659542 , 0.96793893, 0.96534351,\n",
       "        0.9659542 , 0.96381679, 0.96381679, 0.96412214, 0.96381679,\n",
       "        0.96396947, 0.96412214, 0.96335878, 0.96351145, 0.96335878,\n",
       "        0.96412214, 0.96320611, 0.96351145, 0.96305344, 0.96335878,\n",
       "        0.96320611, 0.96381679, 0.96335878, 0.96351145, 0.96305344,\n",
       "        0.96320611, 0.96320611, 0.96351145, 0.96305344, 0.96320611,\n",
       "        0.96412214, 0.96519084, 0.96442748, 0.96473282, 0.9648855 ,\n",
       "        0.96442748, 0.96549618, 0.96458015, 0.96458015, 0.9648855 ,\n",
       "        0.9648855 , 0.96427481, 0.96396947, 0.96412214, 0.96396947,\n",
       "        0.96412214, 0.96381679, 0.96412214, 0.96412214, 0.96366412,\n",
       "        0.96335878, 0.96351145, 0.96335878, 0.96335878, 0.96351145,\n",
       "        0.96549618, 0.96534351, 0.96427481, 0.96549618, 0.9648855 ,\n",
       "        0.96473282, 0.96503817, 0.96503817, 0.96458015, 0.96534351,\n",
       "        0.96534351, 0.96473282, 0.96473282, 0.96473282, 0.9648855 ,\n",
       "        0.96427481, 0.96427481, 0.96427481, 0.96396947, 0.96381679,\n",
       "        0.96305344, 0.96335878, 0.96351145, 0.96290076, 0.96396947,\n",
       "        0.96580153, 0.96717557, 0.96671756, 0.96687023, 0.96564885,\n",
       "        0.96503817, 0.96564885, 0.96564885, 0.96503817, 0.96610687,\n",
       "        0.96473282, 0.96503817, 0.96534351, 0.96473282, 0.96564885,\n",
       "        0.96442748, 0.96473282, 0.96381679, 0.96381679, 0.96442748,\n",
       "        0.96381679, 0.96305344, 0.96320611, 0.96366412, 0.96396947,\n",
       "        0.96580153, 0.96564885, 0.96717557, 0.9659542 , 0.9670229 ,\n",
       "        0.96641221, 0.96641221, 0.96610687, 0.96671756, 0.96656489,\n",
       "        0.96549618, 0.96503817, 0.96458015, 0.96580153, 0.96564885,\n",
       "        0.96442748, 0.96427481, 0.96442748, 0.96442748, 0.96458015,\n",
       "        0.96412214, 0.96335878, 0.96351145, 0.96305344, 0.96396947,\n",
       "        0.96625954, 0.96763359, 0.9670229 , 0.96717557, 0.96625954,\n",
       "        0.96717557, 0.96656489, 0.96656489, 0.9670229 , 0.96671756,\n",
       "        0.9648855 , 0.96549618, 0.96564885, 0.96564885, 0.96549618,\n",
       "        0.96381679, 0.96458015, 0.96412214, 0.96534351, 0.9648855 ,\n",
       "        0.96366412, 0.96381679, 0.96412214, 0.96412214, 0.96381679,\n",
       "        0.9680916 , 0.96870229, 0.9680916 , 0.96687023, 0.96748092,\n",
       "        0.96793893, 0.96732824, 0.96732824, 0.96732824, 0.9670229 ,\n",
       "        0.96580153, 0.96625954, 0.9659542 , 0.96580153, 0.96534351,\n",
       "        0.96381679, 0.96580153, 0.96458015, 0.96458015, 0.96473282,\n",
       "        0.96351145, 0.96366412, 0.96396947, 0.96351145, 0.96396947,\n",
       "        0.96229008, 0.96351145, 0.96259542, 0.96259542, 0.96244275,\n",
       "        0.96320611, 0.96290076, 0.96274809, 0.96335878, 0.96335878,\n",
       "        0.96305344, 0.96564885, 0.96274809, 0.96366412, 0.96366412,\n",
       "        0.96656489, 0.96290076, 0.96351145, 0.96305344, 0.96290076,\n",
       "        0.96458015, 0.96351145, 0.96351145, 0.96320611, 0.96320611,\n",
       "        0.9648855 , 0.96412214, 0.96442748, 0.96396947, 0.9648855 ,\n",
       "        0.96320611, 0.96427481, 0.96396947, 0.96396947, 0.96396947,\n",
       "        0.96045802, 0.96427481, 0.96442748, 0.96442748, 0.96427481,\n",
       "        0.95832061, 0.9578626 , 0.96412214, 0.9610687 , 0.96061069,\n",
       "        0.96381679, 0.95816794, 0.96290076, 0.95312977, 0.96061069,\n",
       "        0.96519084, 0.96519084, 0.96549618, 0.96503817, 0.9648855 ,\n",
       "        0.96442748, 0.96381679, 0.96473282, 0.96442748, 0.96458015,\n",
       "        0.96503817, 0.96519084, 0.9648855 , 0.96503817, 0.96503817,\n",
       "        0.96061069, 0.95984733, 0.96366412, 0.95938931, 0.95832061,\n",
       "        0.96458015, 0.92503817, 0.90122137, 0.95206107, 0.96366412,\n",
       "        0.9648855 , 0.96625954, 0.96610687, 0.96625954, 0.96580153,\n",
       "        0.9659542 , 0.96290076, 0.96625954, 0.9659542 , 0.96625954,\n",
       "        0.9659542 , 0.96656489, 0.96549618, 0.96625954, 0.9610687 ,\n",
       "        0.93251908, 0.95801527, 0.92580153, 0.96259542, 0.95587786,\n",
       "        0.96610687, 0.96244275, 0.96519084, 0.90137405, 0.95526718,\n",
       "        0.9670229 , 0.96732824, 0.96641221, 0.9670229 , 0.96687023,\n",
       "        0.95328244, 0.9670229 , 0.96717557, 0.96717557, 0.96656489,\n",
       "        0.96427481, 0.96732824, 0.96687023, 0.96076336, 0.96229008,\n",
       "        0.92656489, 0.96061069, 0.96534351, 0.95969466, 0.95832061,\n",
       "        0.90152672, 0.89206107, 0.92839695, 0.93160305, 0.95618321,\n",
       "        0.9589313 , 0.96793893, 0.96625954, 0.96396947, 0.96748092,\n",
       "        0.96763359, 0.96625954, 0.96763359, 0.96793893, 0.96778626,\n",
       "        0.96519084, 0.96045802, 0.96778626, 0.95648855, 0.96717557,\n",
       "        0.90076336, 0.95755725, 0.96091603, 0.95541985, 0.92824427,\n",
       "        0.96564885, 0.8989313 , 0.95664122, 0.95618321, 0.96091603,\n",
       "        0.9659542 , 0.96854962, 0.96458015, 0.96580153, 0.96045802,\n",
       "        0.96824427, 0.96839695, 0.96549618, 0.96335878, 0.96290076,\n",
       "        0.93679389, 0.96824427, 0.96244275, 0.95526718, 0.93801527,\n",
       "        0.96534351, 0.95267176, 0.90305344, 0.9529771 , 0.96778626,\n",
       "        0.95083969, 0.95603053, 0.93129771, 0.93801527, 0.91862595,\n",
       "        0.96366412, 0.96      , 0.96503817, 0.96396947, 0.9659542 ,\n",
       "        0.96839695, 0.96900763, 0.96900763, 0.96763359, 0.96885496,\n",
       "        0.96305344, 0.95755725, 0.9610687 , 0.96183206, 0.9680916 ,\n",
       "        0.92458015, 0.95832061, 0.90152672, 0.95755725, 0.94671756,\n",
       "        0.91908397, 0.91083969, 0.92687023, 0.92671756, 0.95099237,\n",
       "        0.96503817, 0.96641221, 0.96580153, 0.96625954, 0.96564885,\n",
       "        0.96931298, 0.96946565, 0.96396947, 0.97007634, 0.96961832,\n",
       "        0.92351145, 0.95954198, 0.96793893, 0.96977099, 0.96977099,\n",
       "        0.96763359, 0.9621374 , 0.92503817, 0.96320611, 0.96366412,\n",
       "        0.96656489, 0.96534351, 0.90198473, 0.93206107, 0.95755725,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96732824, 0.96763359, 0.96885496, 0.96763359, 0.96900763,\n",
       "        0.96885496, 0.96458015, 0.96870229, 0.96534351, 0.96885496,\n",
       "        0.96320611, 0.96396947, 0.96564885, 0.96381679, 0.96793893,\n",
       "        0.96335878, 0.9680916 , 0.96900763, 0.96396947, 0.96839695,\n",
       "        0.96763359, 0.96900763, 0.96839695, 0.96396947, 0.96519084,\n",
       "        0.96366412, 0.96381679, 0.96366412, 0.96351145, 0.96335878,\n",
       "        0.96412214, 0.96381679, 0.96366412, 0.96335878, 0.96351145,\n",
       "        0.96335878, 0.96335878, 0.96335878, 0.96366412, 0.96335878,\n",
       "        0.96381679, 0.96335878, 0.96290076, 0.96335878, 0.96335878,\n",
       "        0.96366412, 0.96320611, 0.96320611, 0.96366412, 0.96320611,\n",
       "        0.96381679, 0.96442748, 0.96458015, 0.96412214, 0.96335878,\n",
       "        0.96427481, 0.96396947, 0.96412214, 0.96458015, 0.9648855 ,\n",
       "        0.96427481, 0.96458015, 0.96503817, 0.96458015, 0.96458015,\n",
       "        0.96427481, 0.96473282, 0.96458015, 0.96396947, 0.96442748,\n",
       "        0.96412214, 0.96381679, 0.96335878, 0.96412214, 0.96366412,\n",
       "        0.96122137, 0.96061069, 0.95969466, 0.96091603, 0.96061069,\n",
       "        0.96503817, 0.96549618, 0.96534351, 0.96549618, 0.96458015,\n",
       "        0.96564885, 0.96503817, 0.9648855 , 0.96503817, 0.9648855 ,\n",
       "        0.96442748, 0.9648855 , 0.96473282, 0.9648855 , 0.96473282,\n",
       "        0.96442748, 0.96442748, 0.96473282, 0.96442748, 0.96412214,\n",
       "        0.95938931, 0.96198473, 0.9610687 , 0.96152672, 0.96229008,\n",
       "        0.96610687, 0.96610687, 0.96564885, 0.96641221, 0.96625954,\n",
       "        0.96564885, 0.96610687, 0.96549618, 0.96549618, 0.96534351,\n",
       "        0.96564885, 0.96534351, 0.96534351, 0.96564885, 0.96564885,\n",
       "        0.96458015, 0.96458015, 0.96503817, 0.9648855 , 0.96473282,\n",
       "        0.95664122, 0.96244275, 0.9621374 , 0.96167939, 0.96244275,\n",
       "        0.96748092, 0.96748092, 0.96793893, 0.96717557, 0.96778626,\n",
       "        0.96656489, 0.96656489, 0.96671756, 0.96610687, 0.96610687,\n",
       "        0.9670229 , 0.96610687, 0.9659542 , 0.96641221, 0.96549618,\n",
       "        0.96534351, 0.96519084, 0.96503817, 0.96534351, 0.96503817,\n",
       "        0.96167939, 0.96198473, 0.96091603, 0.96198473, 0.96183206,\n",
       "        0.96717557, 0.96793893, 0.96778626, 0.96824427, 0.96793893,\n",
       "        0.9659542 , 0.96778626, 0.96748092, 0.9670229 , 0.9670229 ,\n",
       "        0.96503817, 0.96625954, 0.96656489, 0.96671756, 0.96641221,\n",
       "        0.96549618, 0.96564885, 0.96610687, 0.9659542 , 0.96564885,\n",
       "        0.96305344, 0.96167939, 0.96137405, 0.96076336, 0.96091603,\n",
       "        0.96900763, 0.96854962, 0.96824427, 0.96870229, 0.96824427,\n",
       "        0.96656489, 0.9680916 , 0.96748092, 0.9680916 , 0.96793893,\n",
       "        0.96671756, 0.96671756, 0.96717557, 0.9670229 , 0.96732824,\n",
       "        0.96625954, 0.9659542 , 0.9659542 , 0.96564885, 0.96564885]),\n",
       " 'std_test_score': array([1.40458015e-02, 1.37404580e-02, 1.31297710e-02, 1.31297710e-02,\n",
       "        1.25190840e-02, 1.24885496e-01, 1.34351145e-02, 1.28244275e-02,\n",
       "        1.16030534e-02, 1.25190840e-02, 1.28244275e-02, 1.28244275e-02,\n",
       "        1.34351145e-02, 1.31297710e-02, 1.31297710e-02, 1.00763359e-02,\n",
       "        1.25190840e-02, 1.25190840e-02, 1.31297710e-02, 1.28244275e-02,\n",
       "        1.25190840e-02, 1.31297710e-02, 1.25190840e-02, 1.31297710e-02,\n",
       "        1.31297710e-02, 1.39809322e-02, 1.72687886e-02, 1.37828016e-02,\n",
       "        1.49040792e-02, 1.62693946e-02, 1.66447227e-02, 3.48934295e-02,\n",
       "        1.33707689e-02, 2.45056003e-02, 1.70254679e-02, 9.11482348e-02,\n",
       "        1.31297710e-02, 1.28335119e-02, 3.48091603e-02, 1.60341690e-02,\n",
       "        1.29041506e-02, 1.86259542e-02, 1.85519742e-02, 1.31297710e-02,\n",
       "        1.32094158e-02, 1.40152672e-01, 1.55725191e-02, 1.34351145e-02,\n",
       "        1.28244275e-02, 1.28244275e-02, 1.45078339e-02, 1.62622296e-02,\n",
       "        2.08473827e-02, 1.46644380e-02, 2.19103917e-02, 2.32843198e-02,\n",
       "        9.53451922e-02, 4.09934325e-02, 1.69500031e-02, 2.64144199e-02,\n",
       "        1.56260568e-01, 2.29058519e-02, 9.68718832e-02, 1.16490050e-01,\n",
       "        2.87801445e-02, 3.97720912e-02, 1.40540965e-02, 1.63740725e-01,\n",
       "        1.96976150e-02, 1.25988892e-02, 1.31297710e-02, 1.44305098e-02,\n",
       "        1.46564885e-02, 1.37404580e-02, 1.47357905e-02, 8.80170878e-02,\n",
       "        2.50428221e-02, 3.75603549e-02, 3.59554140e-02, 4.10701211e-02,\n",
       "        1.54387308e-02, 3.03067856e-02, 1.55725191e-02, 6.24436813e-02,\n",
       "        2.03082131e-02, 1.68008313e-02, 1.34198908e-01, 1.64956162e-02,\n",
       "        1.54387308e-02, 2.87063502e-02, 1.66568734e-01, 9.55786160e-02,\n",
       "        1.48551580e-01, 1.00613583e-01, 1.15650241e-01, 1.33511778e-01,\n",
       "        3.81679389e-02, 7.82448334e-02, 2.04580153e-02, 8.40463215e-02,\n",
       "        4.14514360e-02, 1.94858449e-02, 1.63537036e-02, 7.61839710e-02,\n",
       "        1.01299292e-01, 1.22215052e-01, 2.26005771e-02, 2.77199107e-02,\n",
       "        2.88569812e-02, 2.63375373e-02, 2.77115008e-02, 1.59162044e-01,\n",
       "        2.77367229e-02, 5.12245025e-02, 1.96324243e-02, 1.21378367e-01,\n",
       "        5.43597214e-02, 1.83650860e-02, 1.31652282e-02, 4.74055021e-02,\n",
       "        1.59642395e-02, 2.04580153e-02, 1.88634589e-02, 9.80920486e-02,\n",
       "        1.16946565e-01, 2.19157101e-02, 2.40524648e-02, 1.22144084e-01,\n",
       "        4.72602319e-02, 5.27643836e-02, 8.29790304e-02, 8.87042609e-02,\n",
       "        1.15193243e-01, 2.80998992e-02, 1.57026890e-01, 2.89408633e-02,\n",
       "        2.72577880e-02, 3.00092249e-02, 6.95493163e-02, 3.17667333e-02,\n",
       "        1.15888422e-01, 1.06190203e-01, 7.35342366e-02, 9.13091979e-02,\n",
       "        3.28758695e-02, 1.36758447e-02, 2.02599504e-02, 9.97749347e-02,\n",
       "        1.18857291e-01, 1.33054639e-01, 2.50800246e-02, 1.04891607e-01,\n",
       "        1.06726839e-01, 4.81218855e-02, 8.99346797e-02, 1.39396420e-01,\n",
       "        1.51952504e-02, 5.91046771e-02, 1.10083218e-01, 9.51986444e-02,\n",
       "        1.43916919e-02, 1.46071051e-02, 7.56540543e-02, 2.04066805e-02,\n",
       "        1.27714829e-01, 6.93983400e-02, 1.13592916e-01, 3.08064215e-02,\n",
       "        9.76376164e-02, 3.37698052e-02, 9.81697197e-02, 1.51937164e-02,\n",
       "        1.81711460e-02, 4.58040712e-02, 1.43592636e-02, 8.73535969e-02,\n",
       "        7.30090319e-02, 1.21543978e-01, 2.97353476e-02, 5.66689918e-02,\n",
       "        2.50148840e-02, 8.36036445e-02, 9.77158872e-02, 6.43590679e-02,\n",
       "        1.28326400e-01, 2.04466187e-02, 4.39906649e-02, 9.28332157e-02,\n",
       "        4.09302698e-02, 9.58888018e-02, 1.72822809e-02, 2.30094115e-02,\n",
       "        3.87064304e-02, 3.55269505e-02, 1.62908704e-02, 1.88065330e-02,\n",
       "        3.64965337e-02, 7.93907810e-02, 2.03311550e-02, 2.95434641e-02,\n",
       "        2.69352094e-02, 7.79723818e-02, 4.41128916e-02, 3.33349261e-02,\n",
       "        5.85722559e-02, 7.94896606e-02, 4.48335369e-02, 1.49702734e-01,\n",
       "        4.80331645e-02, 3.17212085e-02, 1.57255614e-01, 1.06033145e-01,\n",
       "        1.17407062e-01, 8.74922391e-02, 8.72671008e-02, 7.42126082e-02,\n",
       "        6.29044689e-02, 1.47831676e-02, 5.48990311e-02, 3.14689044e-02,\n",
       "        1.07568493e-01, 3.12600779e-02, 1.43348942e-02, 2.42868087e-02,\n",
       "        1.02140257e-01, 3.05343511e-04, 3.05343511e-04, 1.11022302e-16,\n",
       "        1.11022302e-16, 3.05343511e-04, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        3.05343511e-04, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.52671756e-03, 1.00763359e-02,\n",
       "        1.22137405e-03, 1.83206107e-03, 1.06870229e-02, 1.16030534e-02,\n",
       "        9.16030534e-04, 4.58015267e-03, 8.54961832e-03, 1.03816794e-02,\n",
       "        3.05343511e-04, 3.96946565e-03, 6.10687023e-03, 1.03816794e-02,\n",
       "        1.22137405e-03, 6.10687023e-03, 6.10687023e-04, 9.16030534e-03,\n",
       "        7.32824427e-03, 7.32824427e-03, 9.16030534e-04, 9.16030534e-04,\n",
       "        7.02290076e-03, 3.05343511e-03, 8.24427481e-03, 8.59041520e-03,\n",
       "        1.24556202e-02, 1.28335119e-02, 1.22232787e-02, 1.24556202e-02,\n",
       "        1.25376887e-02, 1.26450560e-02, 1.33707689e-02, 1.22936318e-02,\n",
       "        1.29815888e-02, 1.22423329e-02, 1.29041506e-02, 1.22936318e-02,\n",
       "        1.32094158e-02, 1.25988892e-02, 1.29041506e-02, 1.16831307e-02,\n",
       "        1.25988892e-02, 1.22936318e-02, 1.32094158e-02, 1.32955976e-02,\n",
       "        1.29041506e-02, 1.22936318e-02, 1.32094158e-02, 1.25190840e-02,\n",
       "        1.34142795e-02, 1.31386443e-02, 1.43023370e-02, 1.29222009e-02,\n",
       "        1.37574111e-02, 1.24275184e-02, 1.29131789e-02, 1.32270495e-02,\n",
       "        1.32270495e-02, 1.33881901e-02, 1.22613576e-02, 1.30924376e-02,\n",
       "        1.33218683e-02, 1.41417236e-02, 1.37013863e-02, 1.37658798e-02,\n",
       "        1.28425898e-02, 1.41581962e-02, 1.29995316e-02, 1.39140854e-02,\n",
       "        1.29905633e-02, 1.30567828e-02, 1.41334801e-02, 1.33707689e-02,\n",
       "        1.30657056e-02, 1.41285317e-02, 1.43592636e-02, 1.68797251e-02,\n",
       "        1.40540965e-02, 1.45559529e-02, 1.44869327e-02, 1.42025768e-02,\n",
       "        1.45911393e-02, 1.39975940e-02, 1.39892656e-02, 1.39892656e-02,\n",
       "        1.44547180e-02, 1.36758447e-02, 1.36758447e-02, 1.45158648e-02,\n",
       "        1.38368123e-02, 1.45991244e-02, 1.38368123e-02, 1.44466531e-02,\n",
       "        1.47515998e-02, 1.39809322e-02, 1.37574111e-02, 1.42435466e-02,\n",
       "        1.46644380e-02, 1.32955976e-02, 1.84436075e-02, 1.49197101e-02,\n",
       "        1.70459913e-02, 1.66727064e-02, 1.87357545e-02, 1.53767063e-02,\n",
       "        1.48884319e-02, 1.38334428e-02, 1.50162587e-02, 1.39892656e-02,\n",
       "        1.51937164e-02, 1.49618321e-02, 1.39892656e-02, 1.48209601e-02,\n",
       "        1.41417236e-02, 1.38973234e-02, 1.40623865e-02, 1.51337683e-02,\n",
       "        1.43592636e-02, 1.46723832e-02, 1.36006458e-02, 1.58852009e-02,\n",
       "        1.36758447e-02, 1.42778704e-02, 1.36758447e-02, 1.73092339e-02,\n",
       "        1.87606194e-02, 1.72255422e-02, 1.81583142e-02, 1.63964064e-02,\n",
       "        1.41417236e-02, 1.53052959e-02, 1.63051720e-02, 1.51183587e-02,\n",
       "        1.53691253e-02, 1.59788334e-02, 1.49851820e-02, 1.58852009e-02,\n",
       "        1.45911393e-02, 1.45399309e-02, 1.58484754e-02, 1.53539519e-02,\n",
       "        1.46803241e-02, 1.46644380e-02, 1.43592636e-02, 1.37658798e-02,\n",
       "        1.52671756e-02, 1.38199566e-02, 1.43592636e-02, 1.36673202e-02,\n",
       "        1.86946549e-02, 1.75711860e-02, 1.87631041e-02, 1.79932586e-02,\n",
       "        1.98848735e-02, 1.65139753e-02, 1.53615404e-02, 1.58322893e-02,\n",
       "        1.56248186e-02, 1.51183587e-02, 1.56739698e-02, 1.48915627e-02,\n",
       "        1.52976795e-02, 1.56814035e-02, 1.59642395e-02, 1.51645405e-02,\n",
       "        1.59145202e-02, 1.53205175e-02, 1.43835917e-02, 1.56665326e-02,\n",
       "        1.47120448e-02, 1.43754869e-02, 1.41581962e-02, 1.41417236e-02,\n",
       "        1.36006458e-02, 1.73495850e-02, 1.80837101e-02, 1.74166290e-02,\n",
       "        1.98273534e-02, 1.86397146e-02, 1.39759298e-02, 1.55275507e-02,\n",
       "        1.58028174e-02, 1.58028174e-02, 1.61168161e-02, 1.49851820e-02,\n",
       "        1.48759022e-02, 1.54839571e-02, 1.50162587e-02, 1.59291596e-02,\n",
       "        1.59071955e-02, 1.46071051e-02, 1.51337683e-02, 1.47436973e-02,\n",
       "        1.44385837e-02, 1.61168161e-02, 1.46803241e-02, 1.48523805e-02,\n",
       "        1.49618321e-02, 1.52013850e-02, 1.43511450e-02, 1.26855439e-02,\n",
       "        1.41252318e-02, 1.41252318e-02, 1.44305098e-02, 1.29041506e-02,\n",
       "        1.31297710e-02, 1.34351145e-02, 1.22137405e-02, 1.25988892e-02,\n",
       "        1.35920741e-02, 7.63358779e-03, 1.34351145e-02, 1.16030534e-02,\n",
       "        1.16030534e-02, 5.80152672e-03, 1.35146846e-02, 1.19083969e-02,\n",
       "        1.28244275e-02, 1.31297710e-02, 9.77099237e-03, 1.19083969e-02,\n",
       "        1.19083969e-02, 1.25190840e-02, 1.25190840e-02, 1.45238913e-02,\n",
       "        1.41334801e-02, 1.42860306e-02, 1.40623865e-02, 1.37658798e-02,\n",
       "        1.51937164e-02, 1.49696194e-02, 1.48130946e-02, 1.52013850e-02,\n",
       "        1.52013850e-02, 2.14524190e-02, 1.26763534e-02, 1.31740776e-02,\n",
       "        1.27697854e-02, 1.30657056e-02, 2.42050946e-02, 2.43529397e-02,\n",
       "        1.33968922e-02, 1.79478620e-02, 2.03952552e-02, 1.28516614e-02,\n",
       "        2.45151100e-02, 1.38973234e-02, 3.38215322e-02, 1.80940186e-02,\n",
       "        1.39140854e-02, 1.46644380e-02, 1.44305098e-02, 1.49696194e-02,\n",
       "        1.52748073e-02, 1.58190337e-02, 1.66447227e-02, 1.55800012e-02,\n",
       "        1.54236259e-02, 1.54990032e-02, 1.34524524e-02, 1.39057069e-02,\n",
       "        1.37489372e-02, 1.34351145e-02, 1.34351145e-02, 2.19103917e-02,\n",
       "        2.30559627e-02, 1.54311802e-02, 2.43577248e-02, 2.64945986e-02,\n",
       "        1.32182356e-02, 9.15310149e-02, 1.39543655e-01, 3.75007332e-02,\n",
       "        1.43023370e-02, 1.68008313e-02, 1.48445316e-02, 1.47673921e-02,\n",
       "        1.48445316e-02, 1.57437081e-02, 1.58190337e-02, 2.07689710e-02,\n",
       "        1.56173580e-02, 1.50488202e-02, 1.52167105e-02, 1.35146846e-02,\n",
       "        1.34524524e-02, 1.52090497e-02, 1.32955976e-02, 2.40476190e-02,\n",
       "        7.96203333e-02, 2.97729496e-02, 9.38172597e-02, 2.02311680e-02,\n",
       "        3.36654203e-02, 1.32270495e-02, 1.93923181e-02, 1.54311802e-02,\n",
       "        1.41909526e-01, 3.29806331e-02, 1.48288214e-02, 1.42025768e-02,\n",
       "        1.68008313e-02, 1.51937164e-02, 1.55140348e-02, 4.30642615e-02,\n",
       "        1.44627784e-02, 1.45238913e-02, 1.56814035e-02, 1.53539519e-02,\n",
       "        1.95658252e-02, 1.38368123e-02, 1.39809322e-02, 2.61848752e-02,\n",
       "        2.31366981e-02, 9.19096650e-02, 2.61135655e-02, 1.66447227e-02,\n",
       "        2.75672943e-02, 3.10738597e-02, 1.43132519e-01, 1.62063496e-01,\n",
       "        8.90082883e-02, 8.25989473e-02, 3.38215322e-02, 3.17924039e-02,\n",
       "        1.49820707e-02, 1.71876124e-02, 2.32662940e-02, 1.58337614e-02,\n",
       "        1.51337683e-02, 1.82658214e-02, 1.63051720e-02, 1.49118967e-02,\n",
       "        1.52167105e-02, 1.96798572e-02, 2.91014954e-02, 1.40706716e-02,\n",
       "        3.66444019e-02, 1.52748073e-02, 1.46183505e-01, 3.29876997e-02,\n",
       "        2.58930578e-02, 3.72612928e-02, 9.08416191e-02, 1.56739698e-02,\n",
       "        1.49467598e-01, 3.40646236e-02, 3.45948943e-02, 2.47516656e-02,\n",
       "        1.85016500e-02, 1.64248132e-02, 2.20641061e-02, 1.99900914e-02,\n",
       "        3.13940056e-02, 1.54613605e-02, 1.55215451e-02, 2.09299558e-02,\n",
       "        2.59766405e-02, 2.68919066e-02, 7.83273065e-02, 1.42860306e-02,\n",
       "        2.54984686e-02, 3.94756141e-02, 7.51300176e-02, 1.82607163e-02,\n",
       "        4.39100532e-02, 1.43519571e-01, 4.32915294e-02, 1.36928778e-02,\n",
       "        4.45126541e-02, 3.56794906e-02, 8.55070876e-02, 7.28380290e-02,\n",
       "        1.09699305e-01, 2.57766717e-02, 3.27821492e-02, 2.34409571e-02,\n",
       "        2.44150732e-02, 2.08361991e-02, 1.66866807e-02, 1.65956375e-02,\n",
       "        1.58778626e-02, 1.82031860e-02, 1.57659000e-02, 2.62204573e-02,\n",
       "        3.60467036e-02, 2.94145822e-02, 2.78850688e-02, 1.57659000e-02,\n",
       "        1.01235765e-01, 3.30053597e-02, 1.47722054e-01, 3.41336627e-02,\n",
       "        5.61935769e-02, 1.11080637e-01, 1.26036429e-01, 9.39736513e-02,\n",
       "        9.54265646e-02, 4.65045285e-02, 2.53793548e-02, 2.30175141e-02,\n",
       "        2.37962331e-02, 2.29078869e-02, 2.30124503e-02, 1.56843760e-02,\n",
       "        1.68493187e-02, 2.70595344e-02, 1.63964064e-02, 1.61817657e-02,\n",
       "        1.05275340e-01, 3.51576237e-02, 1.72187752e-02, 1.43754869e-02,\n",
       "        1.43673775e-02, 1.44563305e-02, 2.61804240e-02, 1.01085997e-01,\n",
       "        2.47751970e-02, 2.42579998e-02, 1.54372210e-02, 1.82479475e-02,\n",
       "        1.45279510e-01, 8.43585711e-02, 3.41575546e-02, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        4.27480916e-03, 3.66412214e-03, 1.22137405e-03, 3.66412214e-03,\n",
       "        9.16030534e-04, 1.22137405e-03, 9.77099237e-03, 1.52671756e-03,\n",
       "        8.24427481e-03, 1.22137405e-03, 1.25190840e-02, 1.09923664e-02,\n",
       "        7.63358779e-03, 1.12977099e-02, 3.05343511e-03, 1.22137405e-02,\n",
       "        2.74809160e-03, 9.16030534e-04, 1.09923664e-02, 2.13740458e-03,\n",
       "        3.66412214e-03, 9.16030534e-04, 2.13740458e-03, 1.09923664e-02,\n",
       "        8.54961832e-03, 1.31475115e-02, 1.16831307e-02, 1.27606557e-02,\n",
       "        1.22936318e-02, 1.33707689e-02, 1.14554696e-02, 1.20658991e-02,\n",
       "        1.23711234e-02, 1.29815888e-02, 1.22936318e-02, 1.25988892e-02,\n",
       "        1.25988892e-02, 1.25988892e-02, 1.19883789e-02, 1.25988892e-02,\n",
       "        1.16831307e-02, 1.25988892e-02, 1.35146846e-02, 1.25988892e-02,\n",
       "        1.25988892e-02, 1.19883789e-02, 1.29041506e-02, 1.29041506e-02,\n",
       "        1.19883789e-02, 1.29041506e-02, 1.58998673e-02, 1.39057069e-02,\n",
       "        1.36006458e-02, 1.37743433e-02, 1.64219747e-02, 1.38368123e-02,\n",
       "        1.36673202e-02, 1.37489372e-02, 1.36006458e-02, 1.37489372e-02,\n",
       "        1.42353621e-02, 1.32270495e-02, 1.26947276e-02, 1.32270495e-02,\n",
       "        1.36092120e-02, 1.34437862e-02, 1.36758447e-02, 1.28244275e-02,\n",
       "        1.36673202e-02, 1.31652282e-02, 1.33968922e-02, 1.40059175e-02,\n",
       "        1.37489372e-02, 1.37743433e-02, 1.39057069e-02, 2.37521142e-02,\n",
       "        2.45920032e-02, 2.64144199e-02, 2.51301606e-02, 2.42339663e-02,\n",
       "        1.45991244e-02, 1.48445316e-02, 1.43916919e-02, 1.45030132e-02,\n",
       "        1.43835917e-02, 1.41334801e-02, 1.46150815e-02, 1.45238913e-02,\n",
       "        1.42189789e-02, 1.45238913e-02, 1.46803241e-02, 1.37828016e-02,\n",
       "        1.48209601e-02, 1.41334801e-02, 1.40872273e-02, 1.46803241e-02,\n",
       "        1.35319205e-02, 1.40706716e-02, 1.42860306e-02, 1.37489372e-02,\n",
       "        3.12824390e-02, 2.68346399e-02, 2.71051493e-02, 2.77493253e-02,\n",
       "        2.62559912e-02, 1.51491622e-02, 1.44078788e-02, 1.49431259e-02,\n",
       "        1.45799528e-02, 1.44708343e-02, 1.53052959e-02, 1.51337683e-02,\n",
       "        1.48523805e-02, 1.52396699e-02, 1.51260654e-02, 1.41334801e-02,\n",
       "        1.39975940e-02, 1.43997876e-02, 1.45158648e-02, 1.45158648e-02,\n",
       "        1.51183587e-02, 1.39809322e-02, 1.49696194e-02, 1.41417236e-02,\n",
       "        1.40623865e-02, 4.09388110e-02, 2.66559814e-02, 2.76609876e-02,\n",
       "        2.82067008e-02, 2.81901689e-02, 1.58558273e-02, 1.55290517e-02,\n",
       "        1.49040792e-02, 1.60994520e-02, 1.52625947e-02, 1.50240178e-02,\n",
       "        1.57659000e-02, 1.46803241e-02, 1.47515998e-02, 1.55215451e-02,\n",
       "        1.48759022e-02, 1.40142360e-02, 1.50488202e-02, 1.45078339e-02,\n",
       "        1.52090497e-02, 1.43754869e-02, 1.47436973e-02, 1.42107802e-02,\n",
       "        1.40059175e-02, 1.42353621e-02, 2.78365454e-02, 2.96175336e-02,\n",
       "        3.16638424e-02, 2.87550271e-02, 2.87290763e-02, 1.62435860e-02,\n",
       "        1.61788846e-02, 1.56695079e-02, 1.51414672e-02, 1.56962604e-02,\n",
       "        1.66166918e-02, 1.48288214e-02, 1.55290517e-02, 1.48209601e-02,\n",
       "        1.52396699e-02, 1.57437081e-02, 1.48209601e-02, 1.53767063e-02,\n",
       "        1.50565625e-02, 1.45238913e-02, 1.52396699e-02, 1.57481490e-02,\n",
       "        1.47436973e-02, 1.46644380e-02, 1.45158648e-02, 2.71421014e-02,\n",
       "        2.87185272e-02, 3.07837146e-02, 2.89255568e-02, 3.17373699e-02,\n",
       "        1.48539497e-02, 1.64814800e-02, 1.66377194e-02, 1.61572599e-02,\n",
       "        1.67354988e-02, 1.53994272e-02, 1.51553154e-02, 1.51568533e-02,\n",
       "        1.54899773e-02, 1.53585055e-02, 1.58778626e-02, 1.54613605e-02,\n",
       "        1.49118967e-02, 1.56248186e-02, 1.54221146e-02, 1.48759022e-02,\n",
       "        1.50952148e-02, 1.43104832e-02, 1.48962576e-02, 1.52748073e-02]),\n",
       " 'rank_test_score': array([642, 633, 603, 603, 564, 878, 627, 584, 494, 564, 584, 584, 627,\n",
       "        603, 603, 396, 564, 564, 603, 584, 564, 603, 564, 603, 603, 481,\n",
       "        658, 428, 531, 649, 649, 772, 541, 734, 670, 840, 603, 584, 781,\n",
       "        664, 564, 707, 708, 603, 584, 891, 665, 627, 584, 584, 328, 471,\n",
       "        670, 396, 694, 705, 846, 784, 603, 734, 897, 716, 850, 869, 747,\n",
       "        788, 642, 900, 708, 541, 603, 642, 655, 633, 649, 827, 687, 766,\n",
       "        764, 778, 298, 741, 363, 800, 626, 531, 880, 412, 387, 746, 899,\n",
       "        849, 893, 856, 871, 883, 787, 824, 723, 831, 770, 242, 190, 811,\n",
       "        844, 870, 627, 708, 722, 678, 726, 896, 727, 792, 603, 876, 798,\n",
       "        633, 298, 794, 642, 723, 694, 855, 873, 387, 531, 867, 783, 789,\n",
       "        817, 826, 863, 690, 895, 720, 712, 727, 803, 737, 868, 861, 813,\n",
       "        833, 756, 564, 705, 854, 873, 881, 584, 846, 851, 782, 819, 879,\n",
       "        156, 796, 857, 830, 156, 170, 808, 396, 877, 805, 866, 740, 845,\n",
       "        759, 852, 642, 687, 793, 584, 815, 802, 864, 665, 790, 603, 814,\n",
       "        837, 799, 872, 396, 775, 831, 767, 833, 514, 674, 772, 765, 368,\n",
       "        675, 778, 824, 703, 760, 603, 804, 760, 700, 791, 808, 768, 889,\n",
       "        777, 718, 894, 853, 865, 822, 819, 812, 801, 279, 797, 754, 862,\n",
       "        757, 494, 727, 858,   4,  53,   6,   6,  53,   6,   6,   6,   6,\n",
       "          6,   6,  53,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,\n",
       "          6,   6,   6,  74, 396,  68,  78, 428, 494,  59, 141, 306, 412,\n",
       "         53, 120, 185, 412,  68, 185,  58, 328, 237, 237,  59,  59, 217,\n",
       "         96, 289, 217, 481, 481, 428, 481, 457, 428, 531, 514, 541, 428,\n",
       "        564, 514, 584, 541, 564, 481, 541, 514, 584, 560, 564, 514, 584,\n",
       "        564, 428, 298, 387, 348, 328, 396, 264, 368, 368, 328, 328, 412,\n",
       "        450, 428, 457, 428, 481, 428, 428, 494, 541, 514, 531, 531, 514,\n",
       "        264, 279, 412, 264, 328, 348, 312, 312, 364, 289, 279, 348, 348,\n",
       "        348, 328, 412, 412, 412, 457, 471, 584, 541, 514, 603, 457, 237,\n",
       "        134, 164, 156, 242, 308, 242, 242, 308, 205, 348, 312, 289, 348,\n",
       "        241, 396, 348, 471, 481, 387, 471, 584, 564, 494, 450, 237, 242,\n",
       "        134, 217, 146, 181, 185, 211, 164, 170, 278, 312, 368, 230, 242,\n",
       "        387, 412, 387, 396, 368, 428, 531, 514, 584, 457, 190, 112, 146,\n",
       "        134, 190, 134, 170, 170, 146, 164, 328, 264, 242, 242, 264, 471,\n",
       "        364, 428, 279, 328, 494, 471, 428, 428, 471,  90,  74,  90, 156,\n",
       "        120,  96, 128, 128, 128, 146, 230, 190, 217, 230, 289, 471, 230,\n",
       "        368, 364, 348, 514, 494, 457, 514, 457, 649, 514, 633, 633, 642,\n",
       "        560, 603, 627, 541, 541, 584, 242, 627, 494, 494, 170, 603, 514,\n",
       "        584, 603, 368, 514, 514, 564, 564, 328, 428, 396, 457, 328, 560,\n",
       "        412, 450, 450, 450, 703, 412, 396, 396, 412, 730, 739, 428, 678,\n",
       "        694, 481, 734, 603, 771, 694, 297, 298, 264, 312, 328, 396, 471,\n",
       "        348, 387, 368, 312, 298, 328, 312, 312, 694, 712, 494, 719, 730,\n",
       "        368, 840, 888, 780, 494, 328, 190, 205, 190, 230, 217, 603, 190,\n",
       "        217, 190, 217, 170, 264, 190, 677, 816, 738, 839, 633, 755, 205,\n",
       "        639, 298, 887, 760, 146, 128, 185, 146, 156, 769, 146, 134, 134,\n",
       "        170, 412, 127, 156, 687, 649, 838, 694, 289, 714, 730, 885, 898,\n",
       "        828, 821, 751, 725,  96, 190, 457, 120, 112, 190, 112,  96, 106,\n",
       "        298, 700, 106, 750, 141, 890, 741, 682, 758, 829, 242, 892, 748,\n",
       "        751, 682, 216,  78, 368, 230, 700,  85,  82, 264, 541, 603, 808,\n",
       "         85, 639, 763, 805, 289, 776, 882, 772, 109, 786, 753, 823, 807,\n",
       "        860, 494, 708, 312, 457, 217,  81,  59,  59, 112,  68, 583, 741,\n",
       "        678, 662,  90, 843, 730, 886, 741, 794, 859, 875, 833, 836, 785,\n",
       "        308, 181, 230, 190, 242,  53,   6, 457,   1,   4, 846, 716,  96,\n",
       "          2,   2, 112, 655, 840, 560, 494, 169, 289, 884, 818, 745,   6,\n",
       "          6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,\n",
       "          6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6, 128, 112,\n",
       "         68, 112,  59,  68, 368,  74, 289,  68, 564, 457, 242, 481,  96,\n",
       "        541,  90,  59, 457,  82, 112,  59,  82, 457, 306, 494, 481, 494,\n",
       "        514, 531, 428, 481, 494, 541, 514, 541, 541, 541, 494, 541, 481,\n",
       "        541, 603, 541, 541, 494, 564, 564, 494, 564, 471, 387, 368, 428,\n",
       "        531, 412, 450, 428, 368, 328, 412, 368, 312, 368, 364, 412, 348,\n",
       "        368, 450, 396, 428, 481, 531, 428, 494, 675, 692, 714, 682, 692,\n",
       "        312, 264, 279, 264, 368, 242, 312, 328, 308, 328, 396, 328, 348,\n",
       "        328, 348, 396, 396, 348, 387, 428, 720, 659, 678, 672, 649, 211,\n",
       "        211, 242, 181, 190, 242, 211, 264, 264, 279, 242, 279, 279, 242,\n",
       "        242, 368, 368, 312, 328, 348, 748, 642, 655, 665, 639, 120, 120,\n",
       "         96, 141, 109, 179, 170, 164, 205, 211, 146, 205, 217, 181, 264,\n",
       "        279, 298, 312, 279, 312, 665, 659, 682, 659, 662, 134,  96, 106,\n",
       "         85,  96, 217, 109, 126, 146, 145, 312, 190, 179, 162, 185, 264,\n",
       "        242, 205, 217, 242, 584, 665, 673, 690, 682,  59,  78,  85,  74,\n",
       "         85, 170,  95, 120,  90,  96, 164, 162, 141, 146, 128, 190, 217,\n",
       "        217, 242, 242]),\n",
       " 'split0_train_score': array([0.97003817, 0.97041985, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97194656, 0.97290076, 0.97270992, 0.9730916 , 0.9730916 ,\n",
       "        0.97099237, 0.97175573, 0.9721374 , 0.97232824, 0.97232824,\n",
       "        0.97194656, 0.97118321, 0.97137405, 0.97099237, 0.97232824,\n",
       "        0.97156489, 0.97156489, 0.97080153, 0.97137405, 0.97137405,\n",
       "        0.96946565, 0.97003817, 0.96965649, 0.96965649, 0.96946565,\n",
       "        0.9740458 , 0.97423664, 0.97461832, 0.97461832, 0.97480916,\n",
       "        0.97385496, 0.97366412, 0.97347328, 0.97347328, 0.97328244,\n",
       "        0.97270992, 0.97270992, 0.97251908, 0.97270992, 0.97290076,\n",
       "        0.97232824, 0.97232824, 0.97232824, 0.97232824, 0.9721374 ,\n",
       "        0.97194656, 0.97175573, 0.97137405, 0.97175573, 0.97118321,\n",
       "        0.97671756, 0.97729008, 0.97729008, 0.97633588, 0.97748092,\n",
       "        0.97557252, 0.97614504, 0.9759542 , 0.97633588, 0.97576336,\n",
       "        0.97423664, 0.9740458 , 0.97442748, 0.97442748, 0.9740458 ,\n",
       "        0.97328244, 0.9730916 , 0.97328244, 0.97328244, 0.97328244,\n",
       "        0.9721374 , 0.97232824, 0.97232824, 0.97194656, 0.97194656,\n",
       "        0.98263359, 0.98263359, 0.98225191, 0.98282443, 0.98225191,\n",
       "        0.97996183, 0.97900763, 0.97958015, 0.97958015, 0.97958015,\n",
       "        0.97729008, 0.9769084 , 0.97671756, 0.9769084 , 0.97671756,\n",
       "        0.97480916, 0.97423664, 0.97423664, 0.97480916, 0.97442748,\n",
       "        0.97290076, 0.97270992, 0.97270992, 0.97270992, 0.9730916 ,\n",
       "        0.98778626, 0.98816794, 0.98931298, 0.98835878, 0.98835878,\n",
       "        0.98244275, 0.98320611, 0.98225191, 0.98263359, 0.98225191,\n",
       "        0.97824427, 0.97881679, 0.97996183, 0.97958015, 0.98015267,\n",
       "        0.97748092, 0.97557252, 0.97729008, 0.97576336, 0.97652672,\n",
       "        0.97480916, 0.97461832, 0.97442748, 0.97347328, 0.97423664,\n",
       "        0.99312977, 0.99274809, 0.99312977, 0.99351145, 0.99332061,\n",
       "        0.9860687 , 0.98587786, 0.98568702, 0.98549618, 0.9860687 ,\n",
       "        0.98110687, 0.98110687, 0.98148855, 0.98110687, 0.98129771,\n",
       "        0.97843511, 0.97881679, 0.97843511, 0.97805344, 0.97805344,\n",
       "        0.97423664, 0.97519084, 0.97576336, 0.97480916, 0.975     ,\n",
       "        0.99484733, 0.99561069, 0.99561069, 0.99637405, 0.99580153,\n",
       "        0.98664122, 0.98740458, 0.98759542, 0.98740458, 0.98740458,\n",
       "        0.98148855, 0.98167939, 0.98148855, 0.98167939, 0.98187023,\n",
       "        0.97862595, 0.97938931, 0.97881679, 0.97900763, 0.97919847,\n",
       "        0.9759542 , 0.975     , 0.9759542 , 0.97614504, 0.9759542 ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.9879771 , 0.98778626, 0.98816794, 0.98835878, 0.98816794,\n",
       "        0.98187023, 0.98244275, 0.98263359, 0.98320611, 0.98244275,\n",
       "        0.98072519, 0.98034351, 0.97977099, 0.97900763, 0.97958015,\n",
       "        0.97767176, 0.97557252, 0.97614504, 0.97767176, 0.97709924,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96984733, 0.96946565, 0.96965649, 0.96984733, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97118321, 0.97137405, 0.97137405, 0.97156489, 0.97156489,\n",
       "        0.97175573, 0.97080153, 0.97080153, 0.97061069, 0.97099237,\n",
       "        0.97061069, 0.97061069, 0.97041985, 0.97041985, 0.97061069,\n",
       "        0.97003817, 0.96984733, 0.97003817, 0.97022901, 0.97003817,\n",
       "        0.97061069, 0.96984733, 0.97022901, 0.97003817, 0.97003817,\n",
       "        0.97824427, 0.97824427, 0.97805344, 0.9778626 , 0.97805344,\n",
       "        0.975     , 0.9759542 , 0.97480916, 0.97576336, 0.97557252,\n",
       "        0.9740458 , 0.97290076, 0.97270992, 0.97328244, 0.97251908,\n",
       "        0.97156489, 0.97118321, 0.97251908, 0.97232824, 0.97175573,\n",
       "        0.97080153, 0.97061069, 0.97099237, 0.97061069, 0.97061069,\n",
       "        0.98530534, 0.98549618, 0.98416031, 0.98435115, 0.98530534,\n",
       "        0.97977099, 0.97938931, 0.97900763, 0.97881679, 0.98015267,\n",
       "        0.97652672, 0.97709924, 0.97748092, 0.97709924, 0.97671756,\n",
       "        0.97328244, 0.97385496, 0.9730916 , 0.97366412, 0.9730916 ,\n",
       "        0.97156489, 0.97137405, 0.97080153, 0.97156489, 0.97156489,\n",
       "        0.9898855 , 0.99026718, 0.99103053, 0.99026718, 0.99045802,\n",
       "        0.98339695, 0.98320611, 0.98358779, 0.98358779, 0.98377863,\n",
       "        0.98053435, 0.98167939, 0.97977099, 0.97996183, 0.98053435,\n",
       "        0.9778626 , 0.97576336, 0.97576336, 0.97614504, 0.97614504,\n",
       "        0.97480916, 0.97232824, 0.97347328, 0.97385496, 0.97347328,\n",
       "        0.99351145, 0.99465649, 0.99446565, 0.99484733, 0.99484733,\n",
       "        0.9870229 , 0.98683206, 0.98721374, 0.9860687 , 0.98645038,\n",
       "        0.98206107, 0.98206107, 0.98282443, 0.98244275, 0.98148855,\n",
       "        0.97824427, 0.9769084 , 0.97843511, 0.97824427, 0.97862595,\n",
       "        0.97538168, 0.97519084, 0.9740458 , 0.97461832, 0.97461832,\n",
       "        0.99694656, 0.9971374 , 0.9971374 , 0.99732824, 0.9971374 ,\n",
       "        0.98816794, 0.98874046, 0.9879771 , 0.98854962, 0.98816794,\n",
       "        0.98339695, 0.98358779, 0.98225191, 0.98301527, 0.98339695,\n",
       "        0.97881679, 0.97748092, 0.97919847, 0.97881679, 0.97996183,\n",
       "        0.97538168, 0.975     , 0.97519084, 0.975     , 0.97423664,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.98931298, 0.98969466, 0.98874046, 0.98874046, 0.98931298,\n",
       "        0.98454198, 0.98416031, 0.98396947, 0.98301527, 0.98377863,\n",
       "        0.97919847, 0.98072519, 0.97900763, 0.97958015, 0.97977099,\n",
       "        0.97614504, 0.975     , 0.97614504, 0.975     , 0.97576336,\n",
       "        0.96984733, 0.96946565, 0.97022901, 0.97003817, 0.96984733,\n",
       "        0.97251908, 0.96946565, 0.97003817, 0.96965649, 0.96946565,\n",
       "        0.96946565, 0.96965649, 0.96984733, 0.96946565, 0.96946565,\n",
       "        0.97003817, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97022901, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97366412, 0.97366412, 0.9740458 , 0.97385496, 0.97385496,\n",
       "        0.9730916 , 0.97328244, 0.97328244, 0.97347328, 0.97328244,\n",
       "        0.97099237, 0.97270992, 0.97270992, 0.97270992, 0.97270992,\n",
       "        0.9721374 , 0.97194656, 0.97270992, 0.97270992, 0.97251908,\n",
       "        0.97251908, 0.97270992, 0.9721374 , 0.97099237, 0.97156489,\n",
       "        0.975     , 0.97671756, 0.97576336, 0.97614504, 0.97633588,\n",
       "        0.97461832, 0.9740458 , 0.975     , 0.9740458 , 0.97442748,\n",
       "        0.97366412, 0.97442748, 0.97385496, 0.97366412, 0.9740458 ,\n",
       "        0.97385496, 0.97347328, 0.9730916 , 0.97328244, 0.97328244,\n",
       "        0.97290076, 0.97270992, 0.97270992, 0.97251908, 0.97290076,\n",
       "        0.97843511, 0.97977099, 0.97977099, 0.97919847, 0.97919847,\n",
       "        0.97748092, 0.9778626 , 0.97748092, 0.97748092, 0.97729008,\n",
       "        0.97652672, 0.97614504, 0.9769084 , 0.97709924, 0.97671756,\n",
       "        0.97519084, 0.97480916, 0.975     , 0.97519084, 0.97557252,\n",
       "        0.9740458 , 0.97480916, 0.97423664, 0.97461832, 0.97461832,\n",
       "        0.98759542, 0.98721374, 0.98721374, 0.98645038, 0.98721374,\n",
       "        0.98396947, 0.98492366, 0.98396947, 0.98301527, 0.98416031,\n",
       "        0.98015267, 0.98034351, 0.98129771, 0.98187023, 0.98148855,\n",
       "        0.97996183, 0.97919847, 0.97881679, 0.97919847, 0.97958015,\n",
       "        0.97729008, 0.97633588, 0.9778626 , 0.97748092, 0.97729008,\n",
       "        0.99045802, 0.99122137, 0.99083969, 0.99122137, 0.99122137,\n",
       "        0.98721374, 0.9879771 , 0.98759542, 0.98759542, 0.98759542,\n",
       "        0.98377863, 0.98454198, 0.98377863, 0.98568702, 0.98530534,\n",
       "        0.98244275, 0.98187023, 0.98187023, 0.98129771, 0.98167939,\n",
       "        0.97996183, 0.97958015, 0.97843511, 0.97919847, 0.97938931,\n",
       "        0.99408397, 0.99389313, 0.99446565, 0.99408397, 0.99408397,\n",
       "        0.99045802, 0.99064885, 0.99026718, 0.99064885, 0.99064885,\n",
       "        0.98931298, 0.98835878, 0.98854962, 0.98835878, 0.98721374,\n",
       "        0.98454198, 0.98320611, 0.98320611, 0.98435115, 0.98416031,\n",
       "        0.98091603, 0.98110687, 0.98167939, 0.98110687, 0.98167939,\n",
       "        0.9971374 , 0.99732824, 0.99694656, 0.99694656, 0.99675573,\n",
       "        0.99236641, 0.99293893, 0.99179389, 0.99217557, 0.99236641,\n",
       "        0.98912214, 0.98912214, 0.98950382, 0.98912214, 0.98931298,\n",
       "        0.98645038, 0.9860687 , 0.9851145 , 0.98568702, 0.98549618,\n",
       "        0.98244275, 0.98282443, 0.98301527, 0.98244275, 0.98320611,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.99427481, 0.99370229, 0.99465649, 0.99465649, 0.99465649,\n",
       "        0.98950382, 0.99026718, 0.99045802, 0.99064885, 0.99007634,\n",
       "        0.9860687 , 0.9860687 , 0.9860687 , 0.98645038, 0.98625954,\n",
       "        0.98206107, 0.98377863, 0.98320611, 0.98396947, 0.98358779,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96984733, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96965649, 0.97003817,\n",
       "        0.96946565, 0.97003817, 0.96946565, 0.96984733, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97251908, 0.97270992, 0.9721374 , 0.97270992, 0.9730916 ,\n",
       "        0.97137405, 0.97194656, 0.97194656, 0.97118321, 0.97099237,\n",
       "        0.97156489, 0.9721374 , 0.97041985, 0.97061069, 0.97080153,\n",
       "        0.97175573, 0.97041985, 0.97041985, 0.97022901, 0.97022901,\n",
       "        0.97080153, 0.97022901, 0.97022901, 0.97022901, 0.97041985,\n",
       "        0.97938931, 0.98034351, 0.97862595, 0.97938931, 0.97958015,\n",
       "        0.97748092, 0.9769084 , 0.9769084 , 0.97767176, 0.97767176,\n",
       "        0.97519084, 0.9759542 , 0.97557252, 0.97614504, 0.97557252,\n",
       "        0.97461832, 0.97461832, 0.97519084, 0.97480916, 0.97442748,\n",
       "        0.9721374 , 0.97366412, 0.97366412, 0.9730916 , 0.97328244,\n",
       "        0.98759542, 0.98664122, 0.98683206, 0.9870229 , 0.98683206,\n",
       "        0.98454198, 0.9851145 , 0.98473282, 0.98473282, 0.98473282,\n",
       "        0.98053435, 0.98053435, 0.98129771, 0.98187023, 0.98015267,\n",
       "        0.97862595, 0.97748092, 0.97862595, 0.97843511, 0.97938931,\n",
       "        0.97709924, 0.97729008, 0.97652672, 0.97671756, 0.97633588,\n",
       "        0.99179389, 0.99198473, 0.99217557, 0.99198473, 0.99179389,\n",
       "        0.98874046, 0.98874046, 0.9889313 , 0.98874046, 0.9889313 ,\n",
       "        0.98664122, 0.98549618, 0.98549618, 0.98549618, 0.98530534,\n",
       "        0.98225191, 0.98282443, 0.98244275, 0.98301527, 0.98244275,\n",
       "        0.98015267, 0.97958015, 0.98015267, 0.98129771, 0.98072519,\n",
       "        0.99580153, 0.99541985, 0.99618321, 0.99561069, 0.99580153,\n",
       "        0.99141221, 0.99160305, 0.99179389, 0.99198473, 0.99198473,\n",
       "        0.98854962, 0.98816794, 0.98931298, 0.98854962, 0.98874046,\n",
       "        0.98625954, 0.9860687 , 0.98587786, 0.98454198, 0.9851145 ,\n",
       "        0.98282443, 0.98377863, 0.98339695, 0.98358779, 0.98263359,\n",
       "        0.99790076, 0.99866412, 0.99828244, 0.99847328, 0.99828244,\n",
       "        0.99274809, 0.99255725, 0.99255725, 0.99293893, 0.99255725,\n",
       "        0.98931298, 0.98931298, 0.99045802, 0.99007634, 0.98969466,\n",
       "        0.98549618, 0.98664122, 0.98683206, 0.98645038, 0.98664122,\n",
       "        0.98320611, 0.98454198, 0.98435115, 0.98416031, 0.98396947,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.99484733, 0.99484733, 0.99465649, 0.99465649, 0.99465649,\n",
       "        0.99083969, 0.99045802, 0.99103053, 0.99026718, 0.99083969,\n",
       "        0.98759542, 0.98740458, 0.98816794, 0.98778626, 0.98759542,\n",
       "        0.98530534, 0.98454198, 0.98492366, 0.98473282, 0.98454198]),\n",
       " 'split1_train_score': array([0.96946565, 0.96946565, 0.97156489, 0.96946565, 0.96965649,\n",
       "        0.97003817, 0.96984733, 0.96946565, 0.96946565, 0.96965649,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97232824, 0.97194656, 0.97270992, 0.97290076, 0.97270992,\n",
       "        0.9721374 , 0.97232824, 0.97194656, 0.97194656, 0.97232824,\n",
       "        0.97156489, 0.97022901, 0.97175573, 0.97137405, 0.97118321,\n",
       "        0.96965649, 0.96984733, 0.97061069, 0.96984733, 0.97080153,\n",
       "        0.96984733, 0.96946565, 0.96965649, 0.96965649, 0.96946565,\n",
       "        0.97423664, 0.9740458 , 0.97423664, 0.97442748, 0.9740458 ,\n",
       "        0.97385496, 0.97366412, 0.9730916 , 0.97385496, 0.97328244,\n",
       "        0.97290076, 0.97328244, 0.97270992, 0.9730916 , 0.9730916 ,\n",
       "        0.97137405, 0.97194656, 0.97232824, 0.97137405, 0.97175573,\n",
       "        0.97022901, 0.97003817, 0.97099237, 0.97022901, 0.97099237,\n",
       "        0.97919847, 0.97881679, 0.97767176, 0.97824427, 0.97862595,\n",
       "        0.9759542 , 0.97652672, 0.97614504, 0.9759542 , 0.9759542 ,\n",
       "        0.9740458 , 0.97461832, 0.97538168, 0.97480916, 0.97480916,\n",
       "        0.97366412, 0.9740458 , 0.97385496, 0.97385496, 0.97385496,\n",
       "        0.97175573, 0.97270992, 0.97251908, 0.97194656, 0.97290076,\n",
       "        0.98358779, 0.98301527, 0.98416031, 0.98358779, 0.98301527,\n",
       "        0.97977099, 0.98072519, 0.98301527, 0.97996183, 0.98110687,\n",
       "        0.97767176, 0.97633588, 0.97843511, 0.9778626 , 0.97824427,\n",
       "        0.9759542 , 0.9759542 , 0.9759542 , 0.97614504, 0.97671756,\n",
       "        0.97442748, 0.9740458 , 0.9730916 , 0.97347328, 0.9740458 ,\n",
       "        0.98950382, 0.99007634, 0.98969466, 0.9898855 , 0.99083969,\n",
       "        0.9851145 , 0.98549618, 0.98530534, 0.98530534, 0.98530534,\n",
       "        0.98206107, 0.98263359, 0.98167939, 0.98244275, 0.98244275,\n",
       "        0.97709924, 0.97996183, 0.97996183, 0.98015267, 0.97919847,\n",
       "        0.97671756, 0.97671756, 0.97729008, 0.97709924, 0.97709924,\n",
       "        0.99370229, 0.99389313, 0.99427481, 0.99389313, 0.99446565,\n",
       "        0.98778626, 0.98683206, 0.98645038, 0.98740458, 0.98664122,\n",
       "        0.98282443, 0.98282443, 0.98320611, 0.98282443, 0.98320611,\n",
       "        0.98072519, 0.97996183, 0.98091603, 0.98110687, 0.98034351,\n",
       "        0.97652672, 0.9769084 , 0.97824427, 0.97614504, 0.97729008,\n",
       "        0.99599237, 0.99503817, 0.99580153, 0.99561069, 0.99561069,\n",
       "        0.9870229 , 0.9879771 , 0.98759542, 0.98816794, 0.98721374,\n",
       "        0.98339695, 0.98320611, 0.98358779, 0.98396947, 0.98377863,\n",
       "        0.98148855, 0.98110687, 0.98072519, 0.98129771, 0.98148855,\n",
       "        0.97633588, 0.97843511, 0.97709924, 0.97824427, 0.97767176,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.9889313 , 0.9889313 , 0.98912214, 0.98854962, 0.98854962,\n",
       "        0.98339695, 0.98358779, 0.98396947, 0.98396947, 0.98416031,\n",
       "        0.98129771, 0.98167939, 0.98148855, 0.98263359, 0.98167939,\n",
       "        0.97748092, 0.97843511, 0.97843511, 0.9778626 , 0.97843511,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.97003817, 0.96946565, 0.96984733, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96965649, 0.96984733, 0.96965649,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97003817, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.9730916 , 0.9721374 , 0.9730916 , 0.9721374 , 0.97194656,\n",
       "        0.97194656, 0.97194656, 0.97175573, 0.9721374 , 0.97175573,\n",
       "        0.97099237, 0.97156489, 0.97137405, 0.97137405, 0.97099237,\n",
       "        0.97099237, 0.97099237, 0.97080153, 0.97099237, 0.97080153,\n",
       "        0.97156489, 0.97080153, 0.97061069, 0.97061069, 0.97080153,\n",
       "        0.97919847, 0.97900763, 0.97938931, 0.97900763, 0.97919847,\n",
       "        0.97614504, 0.97633588, 0.97652672, 0.97633588, 0.97633588,\n",
       "        0.9740458 , 0.97461832, 0.97442748, 0.97480916, 0.97480916,\n",
       "        0.97480916, 0.97442748, 0.9730916 , 0.97328244, 0.97270992,\n",
       "        0.9721374 , 0.97118321, 0.97194656, 0.97270992, 0.9721374 ,\n",
       "        0.98568702, 0.9860687 , 0.98721374, 0.98664122, 0.9879771 ,\n",
       "        0.98263359, 0.98282443, 0.98282443, 0.98225191, 0.98244275,\n",
       "        0.97977099, 0.97805344, 0.97900763, 0.97938931, 0.97977099,\n",
       "        0.9769084 , 0.97461832, 0.97576336, 0.97633588, 0.9778626 ,\n",
       "        0.97671756, 0.9730916 , 0.97423664, 0.97366412, 0.97328244,\n",
       "        0.99217557, 0.99351145, 0.99293893, 0.99332061, 0.99370229,\n",
       "        0.98778626, 0.98816794, 0.98721374, 0.98664122, 0.9870229 ,\n",
       "        0.98206107, 0.98301527, 0.98263359, 0.98244275, 0.98320611,\n",
       "        0.98129771, 0.98053435, 0.97958015, 0.98015267, 0.98015267,\n",
       "        0.97729008, 0.97843511, 0.97748092, 0.97614504, 0.9778626 ,\n",
       "        0.99599237, 0.99561069, 0.99580153, 0.99580153, 0.99561069,\n",
       "        0.98854962, 0.98874046, 0.98912214, 0.98854962, 0.9889313 ,\n",
       "        0.98339695, 0.98377863, 0.98377863, 0.98377863, 0.9851145 ,\n",
       "        0.98167939, 0.98148855, 0.98091603, 0.98129771, 0.98091603,\n",
       "        0.97938931, 0.97862595, 0.9778626 , 0.97805344, 0.97862595,\n",
       "        0.99751908, 0.9971374 , 0.99770992, 0.99770992, 0.9980916 ,\n",
       "        0.98931298, 0.98950382, 0.98950382, 0.98912214, 0.98912214,\n",
       "        0.98530534, 0.98473282, 0.9851145 , 0.98473282, 0.98435115,\n",
       "        0.98167939, 0.98167939, 0.98110687, 0.98148855, 0.98148855,\n",
       "        0.97881679, 0.97805344, 0.97843511, 0.97900763, 0.97824427,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.98950382, 0.98950382, 0.9898855 , 0.98931298, 0.98969466,\n",
       "        0.98473282, 0.98435115, 0.98416031, 0.98416031, 0.98435115,\n",
       "        0.98167939, 0.98148855, 0.98091603, 0.98282443, 0.98148855,\n",
       "        0.97862595, 0.97843511, 0.97900763, 0.9778626 , 0.97881679,\n",
       "        0.97156489, 0.96984733, 0.97156489, 0.9721374 , 0.97175573,\n",
       "        0.96984733, 0.97022901, 0.97061069, 0.97041985, 0.97175573,\n",
       "        0.97232824, 0.96946565, 0.96946565, 0.97175573, 0.97080153,\n",
       "        0.96946565, 0.96984733, 0.96965649, 0.96946565, 0.97003817,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96984733, 0.96984733,\n",
       "        0.97328244, 0.97328244, 0.97328244, 0.97328244, 0.97328244,\n",
       "        0.9721374 , 0.97290076, 0.97251908, 0.9730916 , 0.9730916 ,\n",
       "        0.97270992, 0.9721374 , 0.97290076, 0.97270992, 0.9730916 ,\n",
       "        0.97270992, 0.97232824, 0.97290076, 0.97270992, 0.97232824,\n",
       "        0.97232824, 0.97251908, 0.97251908, 0.97232824, 0.9721374 ,\n",
       "        0.97480916, 0.97576336, 0.97557252, 0.97519084, 0.97557252,\n",
       "        0.97538168, 0.975     , 0.975     , 0.97519084, 0.97557252,\n",
       "        0.97480916, 0.975     , 0.97480916, 0.97442748, 0.97442748,\n",
       "        0.97290076, 0.97423664, 0.97461832, 0.9730916 , 0.97442748,\n",
       "        0.97461832, 0.97328244, 0.9730916 , 0.97328244, 0.97270992,\n",
       "        0.98015267, 0.97996183, 0.97881679, 0.97958015, 0.97958015,\n",
       "        0.98034351, 0.97805344, 0.97824427, 0.97805344, 0.97748092,\n",
       "        0.97709924, 0.97729008, 0.97671756, 0.97671756, 0.9769084 ,\n",
       "        0.97652672, 0.9759542 , 0.97633588, 0.97614504, 0.97614504,\n",
       "        0.97557252, 0.97576336, 0.97576336, 0.97576336, 0.97538168,\n",
       "        0.98912214, 0.98931298, 0.98721374, 0.98759542, 0.98721374,\n",
       "        0.98492366, 0.9870229 , 0.98530534, 0.98416031, 0.98435115,\n",
       "        0.98358779, 0.98435115, 0.98244275, 0.98320611, 0.98301527,\n",
       "        0.97938931, 0.98244275, 0.97919847, 0.98263359, 0.97977099,\n",
       "        0.97767176, 0.98167939, 0.97938931, 0.98015267, 0.97843511,\n",
       "        0.99427481, 0.99332061, 0.99312977, 0.99370229, 0.99351145,\n",
       "        0.98950382, 0.98969466, 0.99026718, 0.99026718, 0.98969466,\n",
       "        0.98683206, 0.98645038, 0.98664122, 0.98721374, 0.98721374,\n",
       "        0.98435115, 0.98492366, 0.98435115, 0.98416031, 0.98435115,\n",
       "        0.98320611, 0.98416031, 0.98416031, 0.98358779, 0.98339695,\n",
       "        0.99541985, 0.99541985, 0.99541985, 0.99561069, 0.99503817,\n",
       "        0.99198473, 0.99179389, 0.99236641, 0.99198473, 0.99217557,\n",
       "        0.98912214, 0.9889313 , 0.98874046, 0.98778626, 0.9889313 ,\n",
       "        0.98664122, 0.9860687 , 0.98568702, 0.98568702, 0.9860687 ,\n",
       "        0.98377863, 0.98435115, 0.98454198, 0.98473282, 0.98492366,\n",
       "        0.99694656, 0.99675573, 0.99675573, 0.99694656, 0.99675573,\n",
       "        0.99274809, 0.99255725, 0.99274809, 0.99255725, 0.99255725,\n",
       "        0.9889313 , 0.98912214, 0.98950382, 0.98931298, 0.98931298,\n",
       "        0.98587786, 0.98664122, 0.98625954, 0.9860687 , 0.9860687 ,\n",
       "        0.98454198, 0.98492366, 0.98492366, 0.9851145 , 0.98492366,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.99389313, 0.99332061, 0.99389313, 0.99389313, 0.99370229,\n",
       "        0.98969466, 0.99064885, 0.98931298, 0.99007634, 0.98969466,\n",
       "        0.9860687 , 0.98683206, 0.98740458, 0.9860687 , 0.98683206,\n",
       "        0.98549618, 0.9851145 , 0.98492366, 0.98492366, 0.9851145 ,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.97022901,\n",
       "        0.97022901, 0.96946565, 0.97003817, 0.96946565, 0.96965649,\n",
       "        0.97003817, 0.96984733, 0.97003817, 0.96946565, 0.96946565,\n",
       "        0.97003817, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.9730916 , 0.9721374 , 0.97328244, 0.97366412, 0.97385496,\n",
       "        0.97270992, 0.97385496, 0.9721374 , 0.97232824, 0.97270992,\n",
       "        0.97328244, 0.97175573, 0.9721374 , 0.97156489, 0.97118321,\n",
       "        0.97118321, 0.97175573, 0.97099237, 0.97137405, 0.97156489,\n",
       "        0.97099237, 0.9721374 , 0.97118321, 0.97118321, 0.97137405,\n",
       "        0.98187023, 0.98167939, 0.98129771, 0.98110687, 0.98129771,\n",
       "        0.97919847, 0.97938931, 0.97977099, 0.97958015, 0.97938931,\n",
       "        0.97805344, 0.97633588, 0.97767176, 0.9778626 , 0.9778626 ,\n",
       "        0.9759542 , 0.97576336, 0.97557252, 0.97652672, 0.97614504,\n",
       "        0.97366412, 0.975     , 0.97442748, 0.97442748, 0.97461832,\n",
       "        0.99064885, 0.98874046, 0.98950382, 0.98759542, 0.9879771 ,\n",
       "        0.98683206, 0.9851145 , 0.98683206, 0.98721374, 0.98683206,\n",
       "        0.98301527, 0.98244275, 0.98263359, 0.98396947, 0.98473282,\n",
       "        0.98282443, 0.98148855, 0.98034351, 0.98206107, 0.98053435,\n",
       "        0.97900763, 0.97881679, 0.97919847, 0.97824427, 0.97671756,\n",
       "        0.99465649, 0.99561069, 0.99541985, 0.99541985, 0.99541985,\n",
       "        0.99141221, 0.99217557, 0.99122137, 0.99217557, 0.99255725,\n",
       "        0.98759542, 0.98931298, 0.98854962, 0.98950382, 0.98931298,\n",
       "        0.98664122, 0.98454198, 0.98664122, 0.98625954, 0.98625954,\n",
       "        0.98396947, 0.98301527, 0.98301527, 0.98396947, 0.98377863,\n",
       "        0.99770992, 0.99790076, 0.99770992, 0.99732824, 0.99770992,\n",
       "        0.99332061, 0.99332061, 0.99312977, 0.99293893, 0.99332061,\n",
       "        0.99007634, 0.9898855 , 0.99026718, 0.99007634, 0.9898855 ,\n",
       "        0.98874046, 0.98874046, 0.98759542, 0.98759542, 0.9870229 ,\n",
       "        0.98454198, 0.98568702, 0.98454198, 0.98454198, 0.98454198,\n",
       "        0.99866412, 0.99828244, 0.99828244, 0.99828244, 0.9980916 ,\n",
       "        0.99351145, 0.99389313, 0.99389313, 0.99389313, 0.99351145,\n",
       "        0.99007634, 0.99045802, 0.99026718, 0.99045802, 0.99026718,\n",
       "        0.9879771 , 0.98778626, 0.98816794, 0.9879771 , 0.98778626,\n",
       "        0.98473282, 0.98549618, 0.9851145 , 0.98530534, 0.9851145 ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.99522901, 0.99522901, 0.99522901, 0.99599237, 0.99561069,\n",
       "        0.99026718, 0.99064885, 0.99045802, 0.99045802, 0.99026718,\n",
       "        0.98740458, 0.98740458, 0.98874046, 0.9879771 , 0.98835878,\n",
       "        0.98645038, 0.9851145 , 0.9851145 , 0.98549618, 0.98549618]),\n",
       " 'split2_train_score': array([0.97423664, 0.97423664, 0.97423664, 0.97423664, 0.97423664,\n",
       "        0.97423664, 0.97423664, 0.97423664, 0.9740458 , 0.97423664,\n",
       "        0.9740458 , 0.97423664, 0.97423664, 0.97423664, 0.97423664,\n",
       "        0.97347328, 0.97423664, 0.9740458 , 0.97423664, 0.97423664,\n",
       "        0.9740458 , 0.97423664, 0.97423664, 0.97423664, 0.97423664,\n",
       "        0.97767176, 0.97748092, 0.97671756, 0.97709924, 0.97748092,\n",
       "        0.97614504, 0.97576336, 0.97633588, 0.97557252, 0.97538168,\n",
       "        0.97480916, 0.97461832, 0.97557252, 0.97633588, 0.9759542 ,\n",
       "        0.97442748, 0.97423664, 0.97442748, 0.97423664, 0.97480916,\n",
       "        0.97442748, 0.97461832, 0.97461832, 0.97423664, 0.97423664,\n",
       "        0.97977099, 0.97938931, 0.97958015, 0.97919847, 0.97881679,\n",
       "        0.9778626 , 0.9778626 , 0.97824427, 0.97843511, 0.97843511,\n",
       "        0.97671756, 0.97709924, 0.97767176, 0.97805344, 0.97824427,\n",
       "        0.97671756, 0.97614504, 0.97671756, 0.97729008, 0.97729008,\n",
       "        0.97519084, 0.97480916, 0.97538168, 0.97519084, 0.97614504,\n",
       "        0.98187023, 0.98244275, 0.98263359, 0.98167939, 0.98206107,\n",
       "        0.98034351, 0.98129771, 0.98110687, 0.98129771, 0.98110687,\n",
       "        0.97958015, 0.97938931, 0.97996183, 0.98015267, 0.98015267,\n",
       "        0.9778626 , 0.97843511, 0.97958015, 0.97862595, 0.97977099,\n",
       "        0.97824427, 0.97748092, 0.97748092, 0.97709924, 0.97767176,\n",
       "        0.98568702, 0.98645038, 0.98625954, 0.98549618, 0.98568702,\n",
       "        0.98396947, 0.98358779, 0.98473282, 0.98473282, 0.98416031,\n",
       "        0.98225191, 0.98187023, 0.98263359, 0.98206107, 0.98244275,\n",
       "        0.97919847, 0.98091603, 0.98091603, 0.98110687, 0.98053435,\n",
       "        0.97996183, 0.97996183, 0.97919847, 0.97843511, 0.97977099,\n",
       "        0.99064885, 0.98912214, 0.99026718, 0.98969466, 0.99026718,\n",
       "        0.98587786, 0.98721374, 0.98683206, 0.98645038, 0.98664122,\n",
       "        0.98492366, 0.98435115, 0.98377863, 0.98416031, 0.98454198,\n",
       "        0.98263359, 0.98206107, 0.98225191, 0.98206107, 0.98187023,\n",
       "        0.98053435, 0.98072519, 0.98034351, 0.98072519, 0.98034351,\n",
       "        0.99351145, 0.99255725, 0.99370229, 0.99351145, 0.99389313,\n",
       "        0.98759542, 0.98816794, 0.98816794, 0.98816794, 0.98759542,\n",
       "        0.98587786, 0.98568702, 0.98492366, 0.9851145 , 0.9851145 ,\n",
       "        0.98339695, 0.98206107, 0.98263359, 0.98358779, 0.98320611,\n",
       "        0.98072519, 0.98129771, 0.98091603, 0.98110687, 0.98148855,\n",
       "        0.99465649, 0.99561069, 0.99580153, 0.99541985, 0.99541985,\n",
       "        0.98816794, 0.9889313 , 0.98912214, 0.9889313 , 0.98854962,\n",
       "        0.98396947, 0.9860687 , 0.9860687 , 0.98568702, 0.98530534,\n",
       "        0.98282443, 0.98320611, 0.98263359, 0.98320611, 0.98339695,\n",
       "        0.98263359, 0.98148855, 0.98148855, 0.98091603, 0.98110687,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.9898855 , 0.98950382, 0.98969466, 0.98950382, 0.9898855 ,\n",
       "        0.98568702, 0.98587786, 0.9860687 , 0.98587786, 0.98625954,\n",
       "        0.98339695, 0.98320611, 0.98358779, 0.98358779, 0.98320611,\n",
       "        0.98091603, 0.98072519, 0.98167939, 0.98091603, 0.98148855,\n",
       "        0.96965649, 0.97022901, 0.96946565, 0.96946565, 0.96984733,\n",
       "        0.96946565, 0.96984733, 0.96965649, 0.96946565, 0.96965649,\n",
       "        0.96946565, 0.96984733, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96965649, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.9721374 , 0.97442748, 0.97232824, 0.97232824, 0.97423664,\n",
       "        0.97423664, 0.97099237, 0.97251908, 0.97366412, 0.97385496,\n",
       "        0.97061069, 0.97137405, 0.97270992, 0.97385496, 0.97137405,\n",
       "        0.97347328, 0.97080153, 0.97347328, 0.9730916 , 0.97290076,\n",
       "        0.97061069, 0.97022901, 0.97251908, 0.97156489, 0.97270992,\n",
       "        0.9769084 , 0.97729008, 0.97652672, 0.97729008, 0.9769084 ,\n",
       "        0.97709924, 0.97633588, 0.97633588, 0.97652672, 0.97709924,\n",
       "        0.97881679, 0.97652672, 0.97652672, 0.9759542 , 0.9759542 ,\n",
       "        0.97538168, 0.97538168, 0.97671756, 0.97633588, 0.97538168,\n",
       "        0.9759542 , 0.97538168, 0.97519084, 0.97557252, 0.97557252,\n",
       "        0.98549618, 0.9851145 , 0.98492366, 0.98530534, 0.9860687 ,\n",
       "        0.98263359, 0.98263359, 0.98339695, 0.98206107, 0.98225191,\n",
       "        0.98034351, 0.98034351, 0.98244275, 0.98072519, 0.98072519,\n",
       "        0.98110687, 0.97938931, 0.98015267, 0.97938931, 0.97996183,\n",
       "        0.97900763, 0.97919847, 0.97862595, 0.97862595, 0.97881679,\n",
       "        0.99083969, 0.99045802, 0.99103053, 0.99122137, 0.99103053,\n",
       "        0.98568702, 0.98721374, 0.98664122, 0.9870229 , 0.98740458,\n",
       "        0.98530534, 0.98416031, 0.98454198, 0.98454198, 0.98435115,\n",
       "        0.98244275, 0.98167939, 0.98187023, 0.98244275, 0.98167939,\n",
       "        0.98187023, 0.98167939, 0.98034351, 0.98072519, 0.98034351,\n",
       "        0.99370229, 0.99427481, 0.99389313, 0.99370229, 0.99370229,\n",
       "        0.9889313 , 0.98835878, 0.98874046, 0.98874046, 0.9889313 ,\n",
       "        0.98683206, 0.98645038, 0.98568702, 0.98549618, 0.98568702,\n",
       "        0.98282443, 0.98225191, 0.98339695, 0.98225191, 0.98282443,\n",
       "        0.98129771, 0.98167939, 0.98148855, 0.98187023, 0.98187023,\n",
       "        0.99599237, 0.99561069, 0.99561069, 0.99599237, 0.99561069,\n",
       "        0.99026718, 0.98912214, 0.98950382, 0.98931298, 0.98912214,\n",
       "        0.98645038, 0.98568702, 0.98664122, 0.98587786, 0.98625954,\n",
       "        0.98416031, 0.98339695, 0.98282443, 0.98358779, 0.98339695,\n",
       "        0.98206107, 0.98110687, 0.98167939, 0.98167939, 0.98206107,\n",
       "        0.99751908, 0.99770992, 0.99770992, 0.99770992, 0.99790076,\n",
       "        0.98969466, 0.98931298, 0.98969466, 0.98950382, 0.98969466,\n",
       "        0.9860687 , 0.98645038, 0.98645038, 0.98587786, 0.98664122,\n",
       "        0.98416031, 0.98358779, 0.98358779, 0.98396947, 0.98396947,\n",
       "        0.98148855, 0.98244275, 0.98206107, 0.98167939, 0.98148855,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.99045802, 0.9898855 , 0.9898855 , 0.99083969, 0.99026718,\n",
       "        0.9860687 , 0.98664122, 0.98683206, 0.9870229 , 0.98683206,\n",
       "        0.98435115, 0.98320611, 0.98416031, 0.98454198, 0.98339695,\n",
       "        0.98148855, 0.98206107, 0.98187023, 0.98187023, 0.98244275,\n",
       "        0.97576336, 0.975     , 0.97480916, 0.97480916, 0.975     ,\n",
       "        0.97480916, 0.97461832, 0.975     , 0.97461832, 0.97480916,\n",
       "        0.97442748, 0.97290076, 0.97461832, 0.97442748, 0.97442748,\n",
       "        0.97232824, 0.97461832, 0.97442748, 0.97461832, 0.97461832,\n",
       "        0.97366412, 0.97442748, 0.97442748, 0.97461832, 0.97442748,\n",
       "        0.97843511, 0.97843511, 0.97843511, 0.97862595, 0.97843511,\n",
       "        0.97748092, 0.97843511, 0.97729008, 0.97843511, 0.97767176,\n",
       "        0.97729008, 0.97824427, 0.97748092, 0.97748092, 0.97729008,\n",
       "        0.97767176, 0.97633588, 0.9759542 , 0.97652672, 0.97748092,\n",
       "        0.97519084, 0.97633588, 0.9759542 , 0.9759542 , 0.97519084,\n",
       "        0.97977099, 0.97977099, 0.98015267, 0.98034351, 0.97958015,\n",
       "        0.97996183, 0.97900763, 0.97977099, 0.97919847, 0.97881679,\n",
       "        0.98034351, 0.97843511, 0.97938931, 0.97919847, 0.97900763,\n",
       "        0.97938931, 0.97938931, 0.97900763, 0.97824427, 0.97843511,\n",
       "        0.97958015, 0.97729008, 0.97843511, 0.97862595, 0.9778626 ,\n",
       "        0.98358779, 0.98263359, 0.98339695, 0.98339695, 0.98263359,\n",
       "        0.98206107, 0.98206107, 0.98206107, 0.98244275, 0.98301527,\n",
       "        0.98282443, 0.98187023, 0.98167939, 0.98167939, 0.98225191,\n",
       "        0.98167939, 0.98148855, 0.98110687, 0.98148855, 0.98187023,\n",
       "        0.98015267, 0.98053435, 0.98053435, 0.98053435, 0.98034351,\n",
       "        0.98931298, 0.98931298, 0.98874046, 0.98912214, 0.98912214,\n",
       "        0.98625954, 0.98778626, 0.98778626, 0.98759542, 0.98625954,\n",
       "        0.98587786, 0.98721374, 0.98645038, 0.98625954, 0.98645038,\n",
       "        0.98549618, 0.98339695, 0.98549618, 0.98435115, 0.98454198,\n",
       "        0.98416031, 0.98244275, 0.98148855, 0.98187023, 0.98301527,\n",
       "        0.99370229, 0.99351145, 0.99351145, 0.99332061, 0.99370229,\n",
       "        0.98950382, 0.98950382, 0.98912214, 0.98969466, 0.98969466,\n",
       "        0.98854962, 0.98816794, 0.98854962, 0.98854962, 0.98816794,\n",
       "        0.98759542, 0.98664122, 0.9870229 , 0.98645038, 0.98645038,\n",
       "        0.9860687 , 0.98492366, 0.98587786, 0.9860687 , 0.98587786,\n",
       "        0.99580153, 0.99561069, 0.99561069, 0.99580153, 0.99541985,\n",
       "        0.99103053, 0.99160305, 0.99122137, 0.99103053, 0.99103053,\n",
       "        0.9889313 , 0.98931298, 0.98931298, 0.98931298, 0.98931298,\n",
       "        0.98778626, 0.98816794, 0.98740458, 0.98759542, 0.98759542,\n",
       "        0.98530534, 0.98587786, 0.98568702, 0.98625954, 0.98530534,\n",
       "        0.9971374 , 0.99732824, 0.99732824, 0.9971374 , 0.99732824,\n",
       "        0.99255725, 0.99198473, 0.99198473, 0.99217557, 0.99217557,\n",
       "        0.98931298, 0.98950382, 0.9898855 , 0.98950382, 0.99007634,\n",
       "        0.98854962, 0.9879771 , 0.9879771 , 0.98835878, 0.9879771 ,\n",
       "        0.98645038, 0.98587786, 0.9860687 , 0.98625954, 0.9860687 ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.99370229, 0.99389313, 0.99408397, 0.99408397, 0.99408397,\n",
       "        0.9898855 , 0.9898855 , 0.99026718, 0.99045802, 0.99026718,\n",
       "        0.98835878, 0.98816794, 0.98816794, 0.98816794, 0.98816794,\n",
       "        0.98683206, 0.98683206, 0.98625954, 0.98645038, 0.98625954,\n",
       "        0.96946565, 0.96965649, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97328244, 0.97232824, 0.97137405, 0.97290076, 0.97175573,\n",
       "        0.97118321, 0.97347328, 0.97156489, 0.97251908, 0.97118321,\n",
       "        0.97423664, 0.97251908, 0.97385496, 0.97270992, 0.97194656,\n",
       "        0.9740458 , 0.97175573, 0.97080153, 0.97385496, 0.97156489,\n",
       "        0.97194656, 0.97041985, 0.97137405, 0.9740458 , 0.9730916 ,\n",
       "        0.97748092, 0.97862595, 0.97843511, 0.97729008, 0.9778626 ,\n",
       "        0.9778626 , 0.97729008, 0.97767176, 0.9778626 , 0.97748092,\n",
       "        0.97767176, 0.97652672, 0.97709924, 0.97729008, 0.97633588,\n",
       "        0.9769084 , 0.97767176, 0.97729008, 0.97748092, 0.97729008,\n",
       "        0.9759542 , 0.97729008, 0.97614504, 0.9769084 , 0.97652672,\n",
       "        0.98740458, 0.98721374, 0.98645038, 0.9879771 , 0.9860687 ,\n",
       "        0.9860687 , 0.98435115, 0.98396947, 0.98454198, 0.98416031,\n",
       "        0.98072519, 0.98301527, 0.98072519, 0.98263359, 0.98454198,\n",
       "        0.98129771, 0.98110687, 0.98187023, 0.98225191, 0.98225191,\n",
       "        0.98129771, 0.98110687, 0.98148855, 0.98187023, 0.98091603,\n",
       "        0.99351145, 0.99370229, 0.99351145, 0.99351145, 0.99351145,\n",
       "        0.98931298, 0.99007634, 0.99045802, 0.99064885, 0.99026718,\n",
       "        0.98874046, 0.98854962, 0.98721374, 0.98816794, 0.98816794,\n",
       "        0.98549618, 0.98587786, 0.9860687 , 0.98664122, 0.98645038,\n",
       "        0.98587786, 0.98568702, 0.98396947, 0.98396947, 0.98416031,\n",
       "        0.99580153, 0.99580153, 0.99599237, 0.99599237, 0.99580153,\n",
       "        0.99236641, 0.99274809, 0.99255725, 0.99236641, 0.99236641,\n",
       "        0.9889313 , 0.98950382, 0.98874046, 0.9898855 , 0.99007634,\n",
       "        0.98721374, 0.98759542, 0.98759542, 0.98740458, 0.98740458,\n",
       "        0.98625954, 0.9860687 , 0.98568702, 0.98625954, 0.9860687 ,\n",
       "        0.99732824, 0.9971374 , 0.9971374 , 0.99732824, 0.99732824,\n",
       "        0.99293893, 0.99293893, 0.99312977, 0.99293893, 0.99293893,\n",
       "        0.99103053, 0.99064885, 0.99064885, 0.99122137, 0.99064885,\n",
       "        0.9879771 , 0.98778626, 0.98816794, 0.98854962, 0.9879771 ,\n",
       "        0.98683206, 0.98683206, 0.9860687 , 0.98664122, 0.98645038,\n",
       "        0.99847328, 0.99866412, 0.99847328, 0.99866412, 0.99847328,\n",
       "        0.99389313, 0.99332061, 0.99370229, 0.99370229, 0.99408397,\n",
       "        0.99103053, 0.99045802, 0.99141221, 0.99141221, 0.99122137,\n",
       "        0.98931298, 0.98835878, 0.98854962, 0.98854962, 0.98835878,\n",
       "        0.98664122, 0.98645038, 0.98645038, 0.98664122, 0.98664122,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.99465649, 0.99465649, 0.99465649, 0.99522901, 0.99503817,\n",
       "        0.99103053, 0.99160305, 0.99122137, 0.99122137, 0.99103053,\n",
       "        0.98931298, 0.98854962, 0.98912214, 0.98874046, 0.98835878,\n",
       "        0.9870229 , 0.9870229 , 0.98645038, 0.98664122, 0.98664122]),\n",
       " 'split3_train_score': array([0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96965649,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.9721374 , 0.97232824, 0.97118321, 0.9721374 , 0.97194656,\n",
       "        0.97041985, 0.97099237, 0.97061069, 0.97118321, 0.97118321,\n",
       "        0.97061069, 0.97041985, 0.97022901, 0.97022901, 0.97080153,\n",
       "        0.96946565, 0.96946565, 0.97022901, 0.96965649, 0.96984733,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97423664, 0.97442748, 0.97423664, 0.97461832, 0.97385496,\n",
       "        0.97385496, 0.9730916 , 0.97366412, 0.97328244, 0.97328244,\n",
       "        0.9730916 , 0.97251908, 0.97251908, 0.97232824, 0.97290076,\n",
       "        0.96965649, 0.9721374 , 0.97003817, 0.97194656, 0.97118321,\n",
       "        0.96984733, 0.96965649, 0.97003817, 0.96946565, 0.96946565,\n",
       "        0.97843511, 0.97748092, 0.97843511, 0.97767176, 0.9778626 ,\n",
       "        0.97729008, 0.97614504, 0.97519084, 0.97614504, 0.97614504,\n",
       "        0.97442748, 0.97519084, 0.97519084, 0.97461832, 0.97519084,\n",
       "        0.97347328, 0.97366412, 0.97251908, 0.9730916 , 0.97251908,\n",
       "        0.97061069, 0.97137405, 0.97022901, 0.97137405, 0.97061069,\n",
       "        0.98148855, 0.98377863, 0.98339695, 0.98339695, 0.98320611,\n",
       "        0.97881679, 0.97958015, 0.98015267, 0.98034351, 0.98034351,\n",
       "        0.9769084 , 0.97729008, 0.9778626 , 0.97671756, 0.97729008,\n",
       "        0.97480916, 0.97576336, 0.97614504, 0.97538168, 0.97557252,\n",
       "        0.97175573, 0.97232824, 0.97290076, 0.97290076, 0.97290076,\n",
       "        0.98759542, 0.9870229 , 0.98740458, 0.98778626, 0.98816794,\n",
       "        0.98206107, 0.98225191, 0.98225191, 0.98225191, 0.98244275,\n",
       "        0.97862595, 0.97881679, 0.97919847, 0.97881679, 0.97977099,\n",
       "        0.97709924, 0.97729008, 0.97729008, 0.97671756, 0.97729008,\n",
       "        0.97442748, 0.975     , 0.97461832, 0.97385496, 0.97423664,\n",
       "        0.99160305, 0.99255725, 0.99312977, 0.99236641, 0.99332061,\n",
       "        0.98568702, 0.98492366, 0.98549618, 0.9851145 , 0.98492366,\n",
       "        0.98053435, 0.97958015, 0.98015267, 0.98072519, 0.98015267,\n",
       "        0.97652672, 0.97729008, 0.97805344, 0.97805344, 0.9778626 ,\n",
       "        0.97442748, 0.97480916, 0.97423664, 0.97480916, 0.97423664,\n",
       "        0.99618321, 0.99599237, 0.99561069, 0.99580153, 0.99561069,\n",
       "        0.98530534, 0.98664122, 0.98721374, 0.98568702, 0.98664122,\n",
       "        0.98091603, 0.98148855, 0.98167939, 0.98015267, 0.98206107,\n",
       "        0.97805344, 0.97767176, 0.97843511, 0.9778626 , 0.97843511,\n",
       "        0.97461832, 0.97423664, 0.975     , 0.97519084, 0.97480916,\n",
       "        1.        , 0.99980916, 1.        , 1.        , 1.        ,\n",
       "        0.98759542, 0.98816794, 0.98759542, 0.9879771 , 0.98816794,\n",
       "        0.98301527, 0.98320611, 0.98148855, 0.98263359, 0.98225191,\n",
       "        0.97824427, 0.9769084 , 0.97862595, 0.97767176, 0.97824427,\n",
       "        0.97576336, 0.97480916, 0.97461832, 0.97519084, 0.97461832,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97099237, 0.97194656, 0.97061069, 0.97022901, 0.97118321,\n",
       "        0.97022901, 0.97270992, 0.97137405, 0.97099237, 0.97061069,\n",
       "        0.97061069, 0.97003817, 0.97041985, 0.97022901, 0.97022901,\n",
       "        0.97003817, 0.96984733, 0.97022901, 0.96965649, 0.97022901,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96984733, 0.97003817,\n",
       "        0.97824427, 0.97938931, 0.97824427, 0.97938931, 0.97824427,\n",
       "        0.9769084 , 0.97576336, 0.97576336, 0.975     , 0.97519084,\n",
       "        0.9740458 , 0.97290076, 0.97328244, 0.97290076, 0.9730916 ,\n",
       "        0.97232824, 0.97194656, 0.97251908, 0.97194656, 0.97175573,\n",
       "        0.97118321, 0.97022901, 0.9721374 , 0.97194656, 0.9721374 ,\n",
       "        0.98530534, 0.98339695, 0.98416031, 0.98396947, 0.98358779,\n",
       "        0.97900763, 0.98034351, 0.97996183, 0.98015267, 0.98034351,\n",
       "        0.97519084, 0.97576336, 0.97576336, 0.97538168, 0.9759542 ,\n",
       "        0.97366412, 0.97385496, 0.97385496, 0.97385496, 0.97385496,\n",
       "        0.97099237, 0.97175573, 0.97251908, 0.97194656, 0.9721374 ,\n",
       "        0.99007634, 0.99026718, 0.98950382, 0.98950382, 0.98950382,\n",
       "        0.98358779, 0.98358779, 0.98320611, 0.98416031, 0.98320611,\n",
       "        0.97824427, 0.97881679, 0.97862595, 0.97824427, 0.97862595,\n",
       "        0.97480916, 0.97519084, 0.97538168, 0.97538168, 0.97538168,\n",
       "        0.97251908, 0.97270992, 0.97290076, 0.97328244, 0.97366412,\n",
       "        0.99351145, 0.99408397, 0.99446565, 0.99389313, 0.99408397,\n",
       "        0.98473282, 0.98587786, 0.98587786, 0.9860687 , 0.98549618,\n",
       "        0.97977099, 0.97977099, 0.98053435, 0.98034351, 0.98091603,\n",
       "        0.9759542 , 0.97576336, 0.97576336, 0.97633588, 0.9759542 ,\n",
       "        0.97423664, 0.97347328, 0.97385496, 0.97366412, 0.97385496,\n",
       "        0.99732824, 0.99770992, 0.9971374 , 0.99751908, 0.99732824,\n",
       "        0.98874046, 0.98721374, 0.98721374, 0.9870229 , 0.9879771 ,\n",
       "        0.98072519, 0.98110687, 0.98034351, 0.98129771, 0.98167939,\n",
       "        0.9778626 , 0.9759542 , 0.97729008, 0.97633588, 0.97671756,\n",
       "        0.97461832, 0.97442748, 0.97442748, 0.9740458 , 0.9740458 ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.9889313 , 0.98931298, 0.9898855 , 0.98912214, 0.99007634,\n",
       "        0.98244275, 0.98301527, 0.98358779, 0.98206107, 0.98244275,\n",
       "        0.97729008, 0.97729008, 0.97671756, 0.97652672, 0.97614504,\n",
       "        0.97519084, 0.97461832, 0.97423664, 0.97442748, 0.9740458 ,\n",
       "        0.96965649, 0.96984733, 0.96946565, 0.97022901, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.97003817,\n",
       "        0.97061069, 0.96965649, 0.97080153, 0.96984733, 0.96946565,\n",
       "        0.97022901, 0.96984733, 0.96946565, 0.96984733, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97270992, 0.97328244, 0.97232824, 0.9730916 , 0.97270992,\n",
       "        0.97270992, 0.97194656, 0.97232824, 0.97251908, 0.9721374 ,\n",
       "        0.97137405, 0.97270992, 0.97194656, 0.9721374 , 0.97232824,\n",
       "        0.9721374 , 0.97137405, 0.97061069, 0.97118321, 0.97156489,\n",
       "        0.97022901, 0.96984733, 0.97118321, 0.97080153, 0.97022901,\n",
       "        0.97519084, 0.97576336, 0.97614504, 0.97576336, 0.97633588,\n",
       "        0.97480916, 0.97519084, 0.97557252, 0.97538168, 0.9759542 ,\n",
       "        0.97480916, 0.97442748, 0.97576336, 0.97538168, 0.97519084,\n",
       "        0.97576336, 0.97442748, 0.975     , 0.97442748, 0.97423664,\n",
       "        0.97385496, 0.97251908, 0.97385496, 0.97423664, 0.97366412,\n",
       "        0.98091603, 0.98129771, 0.98015267, 0.98034351, 0.98072519,\n",
       "        0.97881679, 0.97862595, 0.97824427, 0.97824427, 0.97900763,\n",
       "        0.97709924, 0.9769084 , 0.97671756, 0.9769084 , 0.9769084 ,\n",
       "        0.97671756, 0.9759542 , 0.97671756, 0.97671756, 0.97614504,\n",
       "        0.97519084, 0.97557252, 0.97557252, 0.9759542 , 0.97557252,\n",
       "        0.98587786, 0.98587786, 0.9860687 , 0.98568702, 0.9860687 ,\n",
       "        0.98320611, 0.98396947, 0.98435115, 0.9851145 , 0.98339695,\n",
       "        0.98282443, 0.98244275, 0.98263359, 0.98148855, 0.98206107,\n",
       "        0.97938931, 0.98110687, 0.98053435, 0.98072519, 0.98053435,\n",
       "        0.97977099, 0.98015267, 0.97938931, 0.97919847, 0.97938931,\n",
       "        0.99179389, 0.99179389, 0.99141221, 0.99141221, 0.99160305,\n",
       "        0.98625954, 0.98759542, 0.98740458, 0.98740458, 0.98740458,\n",
       "        0.98320611, 0.98377863, 0.98435115, 0.98454198, 0.98454198,\n",
       "        0.98167939, 0.98263359, 0.98282443, 0.98225191, 0.98263359,\n",
       "        0.98129771, 0.98053435, 0.98091603, 0.98167939, 0.98129771,\n",
       "        0.99370229, 0.99427481, 0.99465649, 0.99484733, 0.99484733,\n",
       "        0.98969466, 0.9898855 , 0.98969466, 0.99064885, 0.99045802,\n",
       "        0.98625954, 0.98549618, 0.98549618, 0.98625954, 0.98645038,\n",
       "        0.98435115, 0.98377863, 0.98377863, 0.98377863, 0.98320611,\n",
       "        0.98187023, 0.98244275, 0.98148855, 0.98244275, 0.98206107,\n",
       "        0.9971374 , 0.99675573, 0.99732824, 0.99732824, 0.9971374 ,\n",
       "        0.99312977, 0.99332061, 0.99332061, 0.99351145, 0.99312977,\n",
       "        0.9879771 , 0.98740458, 0.98778626, 0.98778626, 0.98778626,\n",
       "        0.9851145 , 0.9851145 , 0.98454198, 0.98358779, 0.98530534,\n",
       "        0.98282443, 0.98358779, 0.98263359, 0.98339695, 0.98320611,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.99427481, 0.99427481, 0.99427481, 0.99446565, 0.99427481,\n",
       "        0.9898855 , 0.98912214, 0.98931298, 0.98912214, 0.98912214,\n",
       "        0.98473282, 0.9851145 , 0.9851145 , 0.9851145 , 0.9851145 ,\n",
       "        0.98377863, 0.98435115, 0.98435115, 0.98396947, 0.98396947,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97194656, 0.97041985, 0.97080153, 0.97118321, 0.97022901,\n",
       "        0.96984733, 0.97022901, 0.97041985, 0.97175573, 0.96984733,\n",
       "        0.97003817, 0.96984733, 0.96984733, 0.96984733, 0.96984733,\n",
       "        0.96946565, 0.96965649, 0.96946565, 0.97041985, 0.96965649,\n",
       "        0.96965649, 0.97003817, 0.96984733, 0.97022901, 0.96984733,\n",
       "        0.97958015, 0.98072519, 0.98091603, 0.98129771, 0.98072519,\n",
       "        0.97881679, 0.97862595, 0.97900763, 0.97958015, 0.97919847,\n",
       "        0.97614504, 0.97652672, 0.9769084 , 0.97614504, 0.97671756,\n",
       "        0.975     , 0.97423664, 0.97461832, 0.9740458 , 0.97366412,\n",
       "        0.97270992, 0.97290076, 0.97290076, 0.97347328, 0.9730916 ,\n",
       "        0.98645038, 0.98568702, 0.98625954, 0.98530534, 0.9860687 ,\n",
       "        0.98301527, 0.98416031, 0.98358779, 0.98377863, 0.98301527,\n",
       "        0.98034351, 0.98148855, 0.97996183, 0.98053435, 0.98053435,\n",
       "        0.97748092, 0.97824427, 0.97729008, 0.9769084 , 0.97748092,\n",
       "        0.975     , 0.9759542 , 0.97519084, 0.97442748, 0.97480916,\n",
       "        0.99122137, 0.99179389, 0.99141221, 0.99255725, 0.99274809,\n",
       "        0.98854962, 0.98835878, 0.98854962, 0.98835878, 0.98854962,\n",
       "        0.98587786, 0.98473282, 0.9860687 , 0.98530534, 0.98473282,\n",
       "        0.98187023, 0.98053435, 0.98034351, 0.98091603, 0.98091603,\n",
       "        0.97824427, 0.97767176, 0.97824427, 0.97843511, 0.97843511,\n",
       "        0.99637405, 0.99561069, 0.99599237, 0.99580153, 0.99561069,\n",
       "        0.99122137, 0.99064885, 0.99026718, 0.99103053, 0.99064885,\n",
       "        0.98721374, 0.98759542, 0.98721374, 0.98721374, 0.98740458,\n",
       "        0.98358779, 0.98435115, 0.98320611, 0.98377863, 0.98339695,\n",
       "        0.97977099, 0.98053435, 0.97977099, 0.97938931, 0.98034351,\n",
       "        0.99770992, 0.9980916 , 0.9980916 , 0.99828244, 0.99847328,\n",
       "        0.99332061, 0.99351145, 0.99332061, 0.99332061, 0.99312977,\n",
       "        0.9898855 , 0.98816794, 0.9889313 , 0.98912214, 0.98874046,\n",
       "        0.98396947, 0.9851145 , 0.98454198, 0.9851145 , 0.9851145 ,\n",
       "        0.98167939, 0.98148855, 0.98110687, 0.98167939, 0.98148855,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.99503817, 0.99503817, 0.99484733, 0.99465649, 0.99503817,\n",
       "        0.99026718, 0.99122137, 0.99045802, 0.99083969, 0.99103053,\n",
       "        0.98587786, 0.98759542, 0.98625954, 0.9870229 , 0.98645038,\n",
       "        0.98358779, 0.98225191, 0.98225191, 0.98206107, 0.98320611]),\n",
       " 'split4_train_score': array([0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97251908, 0.97232824, 0.97232824, 0.97232824, 0.97232824,\n",
       "        0.9721374 , 0.97118321, 0.97194656, 0.97194656, 0.97175573,\n",
       "        0.97156489, 0.96984733, 0.97137405, 0.97080153, 0.97118321,\n",
       "        0.97156489, 0.96946565, 0.96984733, 0.96984733, 0.97041985,\n",
       "        0.96965649, 0.96984733, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97385496, 0.97423664, 0.97423664, 0.97442748, 0.97423664,\n",
       "        0.97385496, 0.9730916 , 0.97290076, 0.97347328, 0.97328244,\n",
       "        0.9721374 , 0.97251908, 0.97251908, 0.97328244, 0.97251908,\n",
       "        0.97175573, 0.97194656, 0.97137405, 0.9721374 , 0.97175573,\n",
       "        0.97156489, 0.97175573, 0.96984733, 0.97061069, 0.97175573,\n",
       "        0.9778626 , 0.97671756, 0.97729008, 0.9769084 , 0.97709924,\n",
       "        0.97557252, 0.97519084, 0.97480916, 0.97519084, 0.97557252,\n",
       "        0.97366412, 0.9740458 , 0.97347328, 0.97366412, 0.9740458 ,\n",
       "        0.97366412, 0.97328244, 0.97347328, 0.97232824, 0.97290076,\n",
       "        0.97118321, 0.97061069, 0.97156489, 0.97099237, 0.97232824,\n",
       "        0.98568702, 0.98339695, 0.98358779, 0.98358779, 0.98358779,\n",
       "        0.97996183, 0.97996183, 0.98110687, 0.98072519, 0.97977099,\n",
       "        0.97652672, 0.9778626 , 0.97709924, 0.9778626 , 0.9769084 ,\n",
       "        0.975     , 0.975     , 0.97519084, 0.97614504, 0.97557252,\n",
       "        0.97385496, 0.97423664, 0.97461832, 0.97442748, 0.9730916 ,\n",
       "        0.98912214, 0.9889313 , 0.99007634, 0.9898855 , 0.98835878,\n",
       "        0.98377863, 0.98263359, 0.98358779, 0.98377863, 0.98358779,\n",
       "        0.97996183, 0.98091603, 0.97938931, 0.97996183, 0.97919847,\n",
       "        0.9778626 , 0.97729008, 0.9769084 , 0.97767176, 0.9769084 ,\n",
       "        0.97557252, 0.97480916, 0.975     , 0.97557252, 0.97519084,\n",
       "        0.99274809, 0.99332061, 0.99389313, 0.99446565, 0.99389313,\n",
       "        0.9860687 , 0.98492366, 0.98530534, 0.98625954, 0.98568702,\n",
       "        0.98187023, 0.98206107, 0.98187023, 0.98206107, 0.98110687,\n",
       "        0.98015267, 0.97900763, 0.97977099, 0.97919847, 0.97862595,\n",
       "        0.9778626 , 0.97652672, 0.97576336, 0.97614504, 0.9759542 ,\n",
       "        0.99522901, 0.99561069, 0.99580153, 0.99599237, 0.99580153,\n",
       "        0.98740458, 0.98759542, 0.98740458, 0.9889313 , 0.9870229 ,\n",
       "        0.98301527, 0.98301527, 0.98320611, 0.98244275, 0.98301527,\n",
       "        0.97977099, 0.97900763, 0.97958015, 0.97938931, 0.97958015,\n",
       "        0.97652672, 0.97652672, 0.97709924, 0.97729008, 0.97671756,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.98874046, 0.98854962, 0.98931298, 0.98874046, 0.98950382,\n",
       "        0.98396947, 0.98377863, 0.98320611, 0.98339695, 0.98320611,\n",
       "        0.97977099, 0.98072519, 0.97919847, 0.98015267, 0.98015267,\n",
       "        0.97423664, 0.97652672, 0.97709924, 0.97709924, 0.9769084 ,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96965649, 0.96946565, 0.96965649, 0.96984733,\n",
       "        0.96946565, 0.96984733, 0.96946565, 0.96946565, 0.96965649,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96984733, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97156489, 0.97156489, 0.97194656, 0.97137405, 0.97137405,\n",
       "        0.97137405, 0.97118321, 0.97137405, 0.97137405, 0.97137405,\n",
       "        0.97061069, 0.97041985, 0.97099237, 0.97099237, 0.97003817,\n",
       "        0.97022901, 0.97041985, 0.97041985, 0.97041985, 0.97022901,\n",
       "        0.97175573, 0.97118321, 0.97022901, 0.97041985, 0.97003817,\n",
       "        0.97862595, 0.97881679, 0.97938931, 0.97824427, 0.97900763,\n",
       "        0.97385496, 0.97614504, 0.9759542 , 0.975     , 0.9769084 ,\n",
       "        0.9730916 , 0.97442748, 0.97347328, 0.97347328, 0.97270992,\n",
       "        0.97251908, 0.97251908, 0.97232824, 0.97232824, 0.9721374 ,\n",
       "        0.97099237, 0.97118321, 0.97118321, 0.97156489, 0.97099237,\n",
       "        0.98549618, 0.98530534, 0.98492366, 0.9851145 , 0.98568702,\n",
       "        0.98110687, 0.97958015, 0.98225191, 0.98129771, 0.98110687,\n",
       "        0.97652672, 0.9778626 , 0.97748092, 0.97824427, 0.97709924,\n",
       "        0.975     , 0.97461832, 0.9759542 , 0.97442748, 0.97461832,\n",
       "        0.9721374 , 0.97232824, 0.97442748, 0.97194656, 0.9721374 ,\n",
       "        0.99103053, 0.99064885, 0.99007634, 0.99083969, 0.99045802,\n",
       "        0.98473282, 0.98454198, 0.98568702, 0.98473282, 0.98530534,\n",
       "        0.98091603, 0.98053435, 0.98091603, 0.98206107, 0.98187023,\n",
       "        0.97767176, 0.97824427, 0.97709924, 0.97671756, 0.97652672,\n",
       "        0.97232824, 0.97366412, 0.97385496, 0.97423664, 0.9740458 ,\n",
       "        0.99484733, 0.99446565, 0.99465649, 0.99465649, 0.99522901,\n",
       "        0.98625954, 0.98759542, 0.98683206, 0.98740458, 0.9870229 ,\n",
       "        0.98263359, 0.98339695, 0.98301527, 0.98263359, 0.98358779,\n",
       "        0.97977099, 0.97958015, 0.97919847, 0.97900763, 0.98053435,\n",
       "        0.97442748, 0.97480916, 0.97461832, 0.97519084, 0.97614504,\n",
       "        0.99732824, 0.99790076, 0.99770992, 0.99770992, 0.99751908,\n",
       "        0.98874046, 0.99007634, 0.98931298, 0.9889313 , 0.98931298,\n",
       "        0.98492366, 0.98358779, 0.98377863, 0.98377863, 0.9851145 ,\n",
       "        0.98091603, 0.97900763, 0.97977099, 0.97958015, 0.98015267,\n",
       "        0.97557252, 0.97652672, 0.97557252, 0.97652672, 0.97576336,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.99007634, 0.98969466, 0.98950382, 0.99045802, 0.98950382,\n",
       "        0.98492366, 0.98530534, 0.98587786, 0.98473282, 0.98530534,\n",
       "        0.98072519, 0.97900763, 0.98053435, 0.98034351, 0.98053435,\n",
       "        0.97709924, 0.97633588, 0.97729008, 0.97614504, 0.97633588,\n",
       "        0.96965649, 0.96965649, 0.96984733, 0.96946565, 0.96946565,\n",
       "        0.96984733, 0.96965649, 0.96965649, 0.96965649, 0.96984733,\n",
       "        0.97099237, 0.96946565, 0.96946565, 0.96965649, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96984733,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96965649,\n",
       "        0.97347328, 0.97347328, 0.97328244, 0.97347328, 0.97366412,\n",
       "        0.97232824, 0.9730916 , 0.97290076, 0.97270992, 0.97251908,\n",
       "        0.97270992, 0.97232824, 0.97251908, 0.97232824, 0.97251908,\n",
       "        0.97194656, 0.97175573, 0.97156489, 0.97251908, 0.9721374 ,\n",
       "        0.97175573, 0.97175573, 0.97175573, 0.9721374 , 0.9721374 ,\n",
       "        0.975     , 0.97538168, 0.97576336, 0.97519084, 0.975     ,\n",
       "        0.97442748, 0.97423664, 0.97423664, 0.97461832, 0.975     ,\n",
       "        0.9740458 , 0.97385496, 0.97347328, 0.97385496, 0.97385496,\n",
       "        0.97423664, 0.97366412, 0.97347328, 0.97328244, 0.97366412,\n",
       "        0.97270992, 0.97290076, 0.97270992, 0.97270992, 0.97290076,\n",
       "        0.98015267, 0.97919847, 0.97919847, 0.97938931, 0.97996183,\n",
       "        0.97748092, 0.97767176, 0.97824427, 0.97767176, 0.97748092,\n",
       "        0.9759542 , 0.97576336, 0.9769084 , 0.97671756, 0.97576336,\n",
       "        0.97480916, 0.97519084, 0.975     , 0.97480916, 0.975     ,\n",
       "        0.97423664, 0.97519084, 0.975     , 0.9740458 , 0.97480916,\n",
       "        0.98816794, 0.98721374, 0.98645038, 0.98664122, 0.98625954,\n",
       "        0.98454198, 0.98454198, 0.98377863, 0.98454198, 0.98473282,\n",
       "        0.98244275, 0.98339695, 0.98282443, 0.98091603, 0.98301527,\n",
       "        0.98072519, 0.98053435, 0.97996183, 0.97996183, 0.97996183,\n",
       "        0.97862595, 0.97881679, 0.97805344, 0.97843511, 0.97862595,\n",
       "        0.99198473, 0.99293893, 0.99160305, 0.99255725, 0.99255725,\n",
       "        0.98950382, 0.98969466, 0.98931298, 0.98969466, 0.9889313 ,\n",
       "        0.98568702, 0.98587786, 0.98683206, 0.98625954, 0.9870229 ,\n",
       "        0.98416031, 0.98282443, 0.98416031, 0.98454198, 0.98435115,\n",
       "        0.98301527, 0.98263359, 0.98206107, 0.98148855, 0.98148855,\n",
       "        0.99580153, 0.99580153, 0.99503817, 0.99541985, 0.99561069,\n",
       "        0.99198473, 0.99236641, 0.99198473, 0.99217557, 0.99198473,\n",
       "        0.98854962, 0.98816794, 0.98854962, 0.98874046, 0.98816794,\n",
       "        0.98587786, 0.9860687 , 0.98625954, 0.98625954, 0.9860687 ,\n",
       "        0.98435115, 0.98301527, 0.98454198, 0.98416031, 0.98435115,\n",
       "        0.99675573, 0.99694656, 0.99675573, 0.99694656, 0.99675573,\n",
       "        0.99293893, 0.99274809, 0.99332061, 0.99312977, 0.99312977,\n",
       "        0.98950382, 0.99026718, 0.98912214, 0.98950382, 0.99007634,\n",
       "        0.98683206, 0.98683206, 0.98664122, 0.98683206, 0.98721374,\n",
       "        0.9851145 , 0.98416031, 0.98454198, 0.98416031, 0.98396947,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.99389313, 0.99370229, 0.99389313, 0.99389313, 0.99389313,\n",
       "        0.99064885, 0.99026718, 0.99064885, 0.99064885, 0.99026718,\n",
       "        0.98740458, 0.98778626, 0.98816794, 0.9879771 , 0.98816794,\n",
       "        0.98416031, 0.98530534, 0.98530534, 0.98530534, 0.9851145 ,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96984733, 0.96984733, 0.96984733, 0.96946565, 0.96984733,\n",
       "        0.96984733, 0.96984733, 0.96984733, 0.96984733, 0.96965649,\n",
       "        0.96946565, 0.96984733, 0.96984733, 0.96984733, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96984733, 0.96984733, 0.96984733,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97385496, 0.97118321, 0.97328244, 0.97194656, 0.9721374 ,\n",
       "        0.97270992, 0.9721374 , 0.9721374 , 0.97232824, 0.97175573,\n",
       "        0.97175573, 0.97118321, 0.97175573, 0.97061069, 0.9721374 ,\n",
       "        0.97251908, 0.97003817, 0.97099237, 0.97080153, 0.97061069,\n",
       "        0.97175573, 0.97118321, 0.97022901, 0.97061069, 0.97080153,\n",
       "        0.98148855, 0.98053435, 0.98091603, 0.98015267, 0.98053435,\n",
       "        0.97824427, 0.97748092, 0.97862595, 0.97881679, 0.97824427,\n",
       "        0.97671756, 0.97729008, 0.97748092, 0.9778626 , 0.9778626 ,\n",
       "        0.97614504, 0.97519084, 0.975     , 0.975     , 0.97576336,\n",
       "        0.9740458 , 0.9730916 , 0.975     , 0.97290076, 0.97328244,\n",
       "        0.9860687 , 0.9860687 , 0.9870229 , 0.9870229 , 0.98664122,\n",
       "        0.98416031, 0.98358779, 0.9851145 , 0.98377863, 0.98377863,\n",
       "        0.98110687, 0.98206107, 0.97996183, 0.98110687, 0.98187023,\n",
       "        0.98053435, 0.97824427, 0.97919847, 0.97938931, 0.97900763,\n",
       "        0.97805344, 0.97709924, 0.97748092, 0.9769084 , 0.97729008,\n",
       "        0.99236641, 0.99236641, 0.99370229, 0.99370229, 0.99332061,\n",
       "        0.98931298, 0.98969466, 0.99064885, 0.99026718, 0.98969466,\n",
       "        0.98435115, 0.98549618, 0.9860687 , 0.98664122, 0.98645038,\n",
       "        0.98339695, 0.98416031, 0.98320611, 0.98358779, 0.98396947,\n",
       "        0.97919847, 0.98072519, 0.98282443, 0.98225191, 0.98072519,\n",
       "        0.99694656, 0.99637405, 0.9971374 , 0.99675573, 0.99656489,\n",
       "        0.99312977, 0.99255725, 0.99255725, 0.99274809, 0.99274809,\n",
       "        0.98931298, 0.98950382, 0.98950382, 0.98912214, 0.98931298,\n",
       "        0.98664122, 0.98645038, 0.98587786, 0.98683206, 0.98664122,\n",
       "        0.98377863, 0.98492366, 0.98473282, 0.98454198, 0.98473282,\n",
       "        0.9980916 , 0.99828244, 0.9980916 , 0.9980916 , 0.99828244,\n",
       "        0.99293893, 0.99312977, 0.99332061, 0.99332061, 0.99332061,\n",
       "        0.9898855 , 0.99007634, 0.98969466, 0.98950382, 0.9898855 ,\n",
       "        0.98740458, 0.98721374, 0.98759542, 0.98759542, 0.98721374,\n",
       "        0.98358779, 0.98492366, 0.98492366, 0.98530534, 0.98492366,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.99522901, 0.99484733, 0.99503817, 0.99503817, 0.99541985,\n",
       "        0.99064885, 0.99083969, 0.99064885, 0.99064885, 0.99045802,\n",
       "        0.98778626, 0.9879771 , 0.98816794, 0.9879771 , 0.98816794,\n",
       "        0.98492366, 0.98492366, 0.9860687 , 0.98549618, 0.98587786]),\n",
       " 'mean_train_score': array([0.97053435, 0.97061069, 0.97083969, 0.97041985, 0.97045802,\n",
       "        0.97053435, 0.97049618, 0.97041985, 0.97038168, 0.97049618,\n",
       "        0.97038168, 0.97041985, 0.97041985, 0.97041985, 0.97041985,\n",
       "        0.97026718, 0.97041985, 0.97038168, 0.97041985, 0.97041985,\n",
       "        0.97038168, 0.97041985, 0.97041985, 0.97041985, 0.97041985,\n",
       "        0.97332061, 0.97339695, 0.97312977, 0.97351145, 0.97351145,\n",
       "        0.97236641, 0.97240458, 0.97259542, 0.97259542, 0.97259542,\n",
       "        0.97209924, 0.97125954, 0.97206107, 0.97194656, 0.97229008,\n",
       "        0.97133588, 0.97091603, 0.97118321, 0.97099237, 0.97145038,\n",
       "        0.97057252, 0.97068702, 0.97057252, 0.97049618, 0.97041985,\n",
       "        0.97522901, 0.97526718, 0.97538168, 0.97545802, 0.97515267,\n",
       "        0.97465649, 0.97427481, 0.97427481, 0.97450382, 0.97431298,\n",
       "        0.97351145, 0.97362595, 0.97358779, 0.97389313, 0.9739313 ,\n",
       "        0.97236641, 0.97290076, 0.97255725, 0.97301527, 0.97282443,\n",
       "        0.97175573, 0.97160305, 0.97152672, 0.97145038, 0.9719084 ,\n",
       "        0.97881679, 0.97854962, 0.97866412, 0.97816794, 0.97862595,\n",
       "        0.97694656, 0.97706107, 0.97664122, 0.97698473, 0.9769084 ,\n",
       "        0.97519084, 0.97545802, 0.97568702, 0.97553435, 0.97564885,\n",
       "        0.97438931, 0.97450382, 0.97454198, 0.97423664, 0.97446565,\n",
       "        0.97278626, 0.97290076, 0.97282443, 0.97267176, 0.9730916 ,\n",
       "        0.98381679, 0.98385496, 0.9839313 , 0.98377863, 0.98354962,\n",
       "        0.98049618, 0.98057252, 0.98171756, 0.9810687 , 0.98099237,\n",
       "        0.97812977, 0.97805344, 0.97854962, 0.97828244, 0.97832061,\n",
       "        0.9759542 , 0.97637405, 0.97648855, 0.97671756, 0.97656489,\n",
       "        0.97458015, 0.97465649, 0.97450382, 0.97438931, 0.97458015,\n",
       "        0.9889313 , 0.98866412, 0.98935115, 0.98912214, 0.98919847,\n",
       "        0.98385496, 0.98416031, 0.9840458 , 0.98408397, 0.9840458 ,\n",
       "        0.98076336, 0.98110687, 0.98080153, 0.98099237, 0.98122137,\n",
       "        0.97843511, 0.97843511, 0.97874046, 0.97847328, 0.97835878,\n",
       "        0.97641221, 0.97637405, 0.97633588, 0.97614504, 0.97622137,\n",
       "        0.99293893, 0.99301527, 0.99362595, 0.99354962, 0.99377863,\n",
       "        0.98664122, 0.98614504, 0.98622137, 0.98648855, 0.98618321,\n",
       "        0.98244275, 0.98225191, 0.98232824, 0.98236641, 0.98217557,\n",
       "        0.97984733, 0.97942748, 0.97996183, 0.98      , 0.97961832,\n",
       "        0.97675573, 0.97694656, 0.97698473, 0.97660305, 0.97679389,\n",
       "        0.99538168, 0.99557252, 0.99572519, 0.99583969, 0.99564885,\n",
       "        0.9869084 , 0.98770992, 0.98778626, 0.98782443, 0.98736641,\n",
       "        0.98255725, 0.9830916 , 0.98320611, 0.98278626, 0.98320611,\n",
       "        0.98015267, 0.98007634, 0.98003817, 0.98015267, 0.98041985,\n",
       "        0.97721374, 0.9771374 , 0.97732824, 0.97755725, 0.97725191,\n",
       "        1.        , 0.99996183, 1.        , 1.        , 1.        ,\n",
       "        0.98862595, 0.98858779, 0.98877863, 0.98862595, 0.98885496,\n",
       "        0.98358779, 0.98377863, 0.98347328, 0.98381679, 0.98366412,\n",
       "        0.98068702, 0.98057252, 0.98053435, 0.98061069, 0.98057252,\n",
       "        0.97721374, 0.97721374, 0.97759542, 0.97774809, 0.97770992,\n",
       "        0.96950382, 0.96961832, 0.96946565, 0.96946565, 0.96954198,\n",
       "        0.96946565, 0.96954198, 0.96950382, 0.96946565, 0.96950382,\n",
       "        0.96946565, 0.96954198, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96950382, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97007634, 0.97061069, 0.97007634, 0.97022901, 0.97049618,\n",
       "        0.97041985, 0.96984733, 0.9701145 , 0.97038168, 0.97041985,\n",
       "        0.96969466, 0.96984733, 0.9701145 , 0.97034351, 0.96984733,\n",
       "        0.97038168, 0.96973282, 0.97034351, 0.97019084, 0.97015267,\n",
       "        0.96969466, 0.96961832, 0.97007634, 0.9698855 , 0.9701145 ,\n",
       "        0.97274809, 0.9728626 , 0.97270992, 0.97251908, 0.97259542,\n",
       "        0.97248092, 0.97259542, 0.97232824, 0.97232824, 0.97236641,\n",
       "        0.97232824, 0.97183206, 0.97194656, 0.97179389, 0.97156489,\n",
       "        0.97133588, 0.97129771, 0.97164122, 0.97152672, 0.97133588,\n",
       "        0.97187023, 0.97133588, 0.97114504, 0.97129771, 0.97129771,\n",
       "        0.97996183, 0.9801145 , 0.98      , 0.97996183, 0.9801145 ,\n",
       "        0.9769084 , 0.97736641, 0.97729008, 0.97683206, 0.97725191,\n",
       "        0.9751145 , 0.97503817, 0.97526718, 0.97503817, 0.97477099,\n",
       "        0.97446565, 0.97389313, 0.97412214, 0.97385496, 0.97366412,\n",
       "        0.97282443, 0.97248092, 0.9729771 , 0.9730916 , 0.97293893,\n",
       "        0.98652672, 0.98614504, 0.98629771, 0.98625954, 0.98671756,\n",
       "        0.98164122, 0.98187023, 0.9821374 , 0.9819084 , 0.98229008,\n",
       "        0.97866412, 0.97858779, 0.97885496, 0.9789313 , 0.97877863,\n",
       "        0.97625954, 0.97572519, 0.97610687, 0.97614504, 0.97622137,\n",
       "        0.97465649, 0.9740458 , 0.97446565, 0.97396947, 0.97389313,\n",
       "        0.99137405, 0.99179389, 0.99148855, 0.99152672, 0.99156489,\n",
       "        0.98568702, 0.98557252, 0.98568702, 0.98557252, 0.98564885,\n",
       "        0.98171756, 0.98209924, 0.98152672, 0.98164122, 0.98198473,\n",
       "        0.97889313, 0.97839695, 0.97824427, 0.97812977, 0.97820611,\n",
       "        0.97564885, 0.97576336, 0.97583969, 0.97587786, 0.97618321,\n",
       "        0.99477099, 0.9948855 , 0.995     , 0.99503817, 0.99507634,\n",
       "        0.98736641, 0.98763359, 0.98770992, 0.98748092, 0.98740458,\n",
       "        0.9828626 , 0.98293893, 0.98335878, 0.98301527, 0.98347328,\n",
       "        0.97996183, 0.97942748, 0.97942748, 0.97969466, 0.9798855 ,\n",
       "        0.97709924, 0.97664122, 0.97641221, 0.97664122, 0.97706107,\n",
       "        0.99732824, 0.99751908, 0.99748092, 0.99759542, 0.99759542,\n",
       "        0.9889313 , 0.98896947, 0.98874046, 0.98862595, 0.98885496,\n",
       "        0.98408397, 0.98389313, 0.98358779, 0.98374046, 0.98423664,\n",
       "        0.98068702, 0.97954198, 0.98019084, 0.98003817, 0.98045802,\n",
       "        0.97717557, 0.97729008, 0.9771374 , 0.97725191, 0.97675573,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.98965649, 0.98961832, 0.98958015, 0.98969466, 0.98977099,\n",
       "        0.98454198, 0.98469466, 0.9848855 , 0.98419847, 0.98454198,\n",
       "        0.98064885, 0.98034351, 0.98026718, 0.98076336, 0.98026718,\n",
       "        0.97770992, 0.97729008, 0.97770992, 0.97706107, 0.97748092,\n",
       "        0.97129771, 0.97076336, 0.97118321, 0.97133588, 0.97110687,\n",
       "        0.97129771, 0.97068702, 0.9709542 , 0.97076336, 0.97118321,\n",
       "        0.97156489, 0.97022901, 0.97083969, 0.97103053, 0.97072519,\n",
       "        0.97030534, 0.97064885, 0.97049618, 0.97057252, 0.97068702,\n",
       "        0.97045802, 0.97045802, 0.97045802, 0.97057252, 0.97057252,\n",
       "        0.97431298, 0.97442748, 0.97427481, 0.97446565, 0.97438931,\n",
       "        0.97354962, 0.9739313 , 0.97366412, 0.9740458 , 0.97374046,\n",
       "        0.97301527, 0.97362595, 0.97351145, 0.97347328, 0.97358779,\n",
       "        0.97332061, 0.97274809, 0.97274809, 0.97312977, 0.97320611,\n",
       "        0.97240458, 0.97263359, 0.97270992, 0.97244275, 0.97225191,\n",
       "        0.9759542 , 0.97667939, 0.97667939, 0.97652672, 0.97656489,\n",
       "        0.97583969, 0.97549618, 0.97591603, 0.97568702, 0.9759542 ,\n",
       "        0.97553435, 0.97522901, 0.97545802, 0.97530534, 0.97530534,\n",
       "        0.97522901, 0.97503817, 0.97503817, 0.97446565, 0.97480916,\n",
       "        0.97473282, 0.97374046, 0.97416031, 0.97427481, 0.97400763,\n",
       "        0.98064885, 0.98057252, 0.98026718, 0.98038168, 0.98041985,\n",
       "        0.97923664, 0.97885496, 0.97885496, 0.97877863, 0.97885496,\n",
       "        0.97790076, 0.97759542, 0.97778626, 0.97782443, 0.97770992,\n",
       "        0.97698473, 0.97667939, 0.97683206, 0.97687023, 0.97694656,\n",
       "        0.97583969, 0.97637405, 0.97622137, 0.97618321, 0.97614504,\n",
       "        0.98801527, 0.98778626, 0.9871374 , 0.98709924, 0.98717557,\n",
       "        0.98458015, 0.98564885, 0.98503817, 0.9848855 , 0.98458015,\n",
       "        0.9829771 , 0.98354962, 0.98312977, 0.98274809, 0.98320611,\n",
       "        0.98099237, 0.98133588, 0.98080153, 0.98137405, 0.98087786,\n",
       "        0.97950382, 0.9798855 , 0.97923664, 0.97942748, 0.97935115,\n",
       "        0.99244275, 0.99255725, 0.99209924, 0.99244275, 0.99251908,\n",
       "        0.98839695, 0.98889313, 0.98874046, 0.9889313 , 0.98866412,\n",
       "        0.98561069, 0.98576336, 0.98603053, 0.98645038, 0.98645038,\n",
       "        0.9840458 , 0.98377863, 0.9840458 , 0.98374046, 0.98389313,\n",
       "        0.98270992, 0.98236641, 0.98229008, 0.98240458, 0.98229008,\n",
       "        0.99496183, 0.995     , 0.99503817, 0.99515267, 0.995     ,\n",
       "        0.99103053, 0.99125954, 0.99110687, 0.99129771, 0.99125954,\n",
       "        0.98843511, 0.98805344, 0.98812977, 0.9880916 , 0.98801527,\n",
       "        0.98583969, 0.98545802, 0.98526718, 0.98553435, 0.98541985,\n",
       "        0.98324427, 0.98335878, 0.98358779, 0.98374046, 0.98366412,\n",
       "        0.9970229 , 0.9970229 , 0.9970229 , 0.99706107, 0.99694656,\n",
       "        0.99274809, 0.99270992, 0.99263359, 0.99270992, 0.99267176,\n",
       "        0.98896947, 0.98908397, 0.98916031, 0.9890458 , 0.98931298,\n",
       "        0.98656489, 0.98652672, 0.98610687, 0.98610687, 0.98641221,\n",
       "        0.98427481, 0.98427481, 0.98423664, 0.98427481, 0.98427481,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.99400763, 0.99377863, 0.99416031, 0.99419847, 0.99412214,\n",
       "        0.98992366, 0.99003817, 0.99      , 0.99019084, 0.9898855 ,\n",
       "        0.98652672, 0.98679389, 0.98698473, 0.98675573, 0.9869084 ,\n",
       "        0.98446565, 0.98507634, 0.98480916, 0.98492366, 0.98480916,\n",
       "        0.96946565, 0.96950382, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.96946565, 0.96946565, 0.96946565, 0.96946565, 0.96946565,\n",
       "        0.97038168, 0.9701145 , 0.96992366, 0.97015267, 0.97015267,\n",
       "        0.97003817, 0.97034351, 0.97007634, 0.97019084, 0.97      ,\n",
       "        0.97053435, 0.97034351, 0.97053435, 0.97026718, 0.96996183,\n",
       "        0.97049618, 0.96992366, 0.96980916, 0.97041985, 0.96996183,\n",
       "        0.96996183, 0.96965649, 0.96984733, 0.97038168, 0.97019084,\n",
       "        0.97377863, 0.97301527, 0.97358779, 0.97335878, 0.97343511,\n",
       "        0.97290076, 0.9730916 , 0.9728626 , 0.9730916 , 0.97255725,\n",
       "        0.9728626 , 0.97229008, 0.97225191, 0.97198473, 0.97206107,\n",
       "        0.97236641, 0.9719084 , 0.97183206, 0.97206107, 0.97187023,\n",
       "        0.97183206, 0.97217557, 0.97152672, 0.97183206, 0.97179389,\n",
       "        0.98194656, 0.98209924, 0.98164122, 0.98198473, 0.98164122,\n",
       "        0.97996183, 0.97935115, 0.97965649, 0.98003817, 0.97973282,\n",
       "        0.97736641, 0.97782443, 0.97767176, 0.97812977, 0.97851145,\n",
       "        0.97660305, 0.97618321, 0.97645038, 0.97652672, 0.97645038,\n",
       "        0.97477099, 0.97515267, 0.97549618, 0.97515267, 0.97503817,\n",
       "        0.98885496, 0.98816794, 0.98862595, 0.9880916 , 0.98820611,\n",
       "        0.98557252, 0.98561069, 0.98614504, 0.98603053, 0.98572519,\n",
       "        0.98274809, 0.98301527, 0.98221374, 0.98312977, 0.9830916 ,\n",
       "        0.98099237, 0.98026718, 0.98030534, 0.98068702, 0.98057252,\n",
       "        0.97900763, 0.97896947, 0.97847328, 0.97805344, 0.9778626 ,\n",
       "        0.99316794, 0.99351145, 0.99374046, 0.9939313 , 0.99381679,\n",
       "        0.99007634, 0.99034351, 0.99038168, 0.99038168, 0.99041985,\n",
       "        0.98667939, 0.9869084 , 0.98698473, 0.98736641, 0.98717557,\n",
       "        0.98427481, 0.9839313 , 0.9840458 , 0.98423664, 0.98419847,\n",
       "        0.98156489, 0.98141221, 0.98198473, 0.98244275, 0.98194656,\n",
       "        0.99683206, 0.99648855, 0.99683206, 0.99656489, 0.99660305,\n",
       "        0.99240458, 0.99221374, 0.99217557, 0.99232824, 0.99232824,\n",
       "        0.98923664, 0.98916031, 0.98938931, 0.98923664, 0.98919847,\n",
       "        0.98664122, 0.98667939, 0.98614504, 0.98625954, 0.98603053,\n",
       "        0.98354962, 0.98435115, 0.98370229, 0.98374046, 0.98374046,\n",
       "        0.99816794, 0.99839695, 0.99824427, 0.99835878, 0.99832061,\n",
       "        0.99328244, 0.99328244, 0.99335878, 0.99343511, 0.99332061,\n",
       "        0.99003817, 0.98969466, 0.99015267, 0.9901145 , 0.98996183,\n",
       "        0.98683206, 0.9870229 , 0.9871374 , 0.9871374 , 0.9870229 ,\n",
       "        0.98396947, 0.98458015, 0.98438931, 0.98461832, 0.98442748,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.995     , 0.99492366, 0.9948855 , 0.9951145 , 0.99515267,\n",
       "        0.99061069, 0.9909542 , 0.99076336, 0.99068702, 0.99072519,\n",
       "        0.98759542, 0.98778626, 0.9880916 , 0.98790076, 0.98778626,\n",
       "        0.98545802, 0.98477099, 0.98496183, 0.9848855 , 0.98515267]),\n",
       " 'std_train_score': array([1.86437782e-03, 1.85025949e-03, 1.88303762e-03, 1.90839695e-03,\n",
       "        1.89075818e-03, 1.86437782e-03, 1.87606194e-03, 1.90839695e-03,\n",
       "        1.83206107e-03, 1.87217534e-03, 1.83206107e-03, 1.90839695e-03,\n",
       "        1.90839695e-03, 1.90839695e-03, 1.90839695e-03, 1.60305344e-03,\n",
       "        1.90839695e-03, 1.83206107e-03, 1.90839695e-03, 1.90839695e-03,\n",
       "        1.83206107e-03, 1.90839695e-03, 1.90839695e-03, 1.90839695e-03,\n",
       "        1.90839695e-03, 2.18392664e-03, 2.06459975e-03, 1.87916544e-03,\n",
       "        1.82808092e-03, 2.02109959e-03, 2.00299874e-03, 1.74323469e-03,\n",
       "        1.94843496e-03, 1.53433216e-03, 1.45639573e-03, 1.42504998e-03,\n",
       "        1.73485774e-03, 1.82887764e-03, 2.22555416e-03, 1.90228027e-03,\n",
       "        1.78779213e-03, 1.83285606e-03, 1.65492240e-03, 1.73653636e-03,\n",
       "        1.75157159e-03, 1.93267006e-03, 1.97811580e-03, 2.02470034e-03,\n",
       "        1.87217534e-03, 1.90839695e-03, 2.27539825e-03, 2.06459975e-03,\n",
       "        2.10443492e-03, 1.87217534e-03, 1.85968362e-03, 1.60305344e-03,\n",
       "        1.81207290e-03, 2.00299874e-03, 1.97443010e-03, 2.06106870e-03,\n",
       "        1.63455062e-03, 1.75904101e-03, 2.04332196e-03, 2.10581897e-03,\n",
       "        2.16449571e-03, 2.35097154e-03, 1.62829992e-03, 2.24315805e-03,\n",
       "        2.16112789e-03, 2.25352510e-03, 1.88921659e-03, 1.82009451e-03,\n",
       "        2.01025864e-03, 2.01098319e-03, 2.24964306e-03, 1.72812693e-03,\n",
       "        2.06459975e-03, 2.02829470e-03, 1.87217534e-03, 1.79023502e-03,\n",
       "        1.81207290e-03, 2.16382256e-03, 2.28561907e-03, 2.19125192e-03,\n",
       "        2.10789332e-03, 2.20912918e-03, 2.01098319e-03, 2.24055880e-03,\n",
       "        2.34165827e-03, 2.29515975e-03, 1.74239881e-03, 1.99279046e-03,\n",
       "        2.55639726e-03, 2.24834755e-03, 2.68914732e-03, 2.77761914e-03,\n",
       "        2.40488305e-03, 2.46353276e-03, 2.24315805e-03, 2.41093308e-03,\n",
       "        1.66545223e-03, 1.35267520e-03, 1.31886661e-03, 9.03218287e-04,\n",
       "        1.15390965e-03, 1.78779213e-03, 1.60759082e-03, 1.90610549e-03,\n",
       "        1.87139705e-03, 1.67069226e-03, 2.09611148e-03, 1.97221537e-03,\n",
       "        2.12715646e-03, 1.94768715e-03, 2.12715646e-03, 1.67678493e-03,\n",
       "        2.35097154e-03, 2.31349351e-03, 2.25158492e-03, 2.11272557e-03,\n",
       "        2.83934579e-03, 2.75338760e-03, 2.44274809e-03, 2.10927510e-03,\n",
       "        2.62610953e-03, 1.13224404e-03, 1.02130444e-03, 1.02699420e-03,\n",
       "        8.78691941e-04, 1.12320145e-03, 1.47626562e-03, 1.89691201e-03,\n",
       "        1.78860680e-03, 1.59027990e-03, 1.69235109e-03, 2.47179769e-03,\n",
       "        2.16247564e-03, 1.72644013e-03, 1.99644226e-03, 1.99279046e-03,\n",
       "        2.11823465e-03, 2.29325479e-03, 2.06812476e-03, 2.31349351e-03,\n",
       "        1.98179465e-03, 2.20450826e-03, 2.30086517e-03, 2.25158492e-03,\n",
       "        2.63054365e-03, 2.31097336e-03, 7.44030103e-04, 5.20541286e-04,\n",
       "        4.45110832e-04, 6.87022901e-04, 4.28434052e-04, 8.70362920e-04,\n",
       "        1.23442455e-03, 1.04805574e-03, 1.14757988e-03, 8.99986727e-04,\n",
       "        1.88148970e-03, 2.03044826e-03, 1.62202514e-03, 1.55788791e-03,\n",
       "        1.77224225e-03, 2.30149823e-03, 1.57092486e-03, 1.67678493e-03,\n",
       "        2.11272557e-03, 1.99571244e-03, 2.40003205e-03, 2.31349351e-03,\n",
       "        2.34849161e-03, 2.32980801e-03, 2.55924498e-03, 6.08296849e-04,\n",
       "        3.05343511e-04, 9.34919749e-05, 3.28333025e-04, 1.42811351e-04,\n",
       "        9.47303332e-04, 7.49881019e-04, 6.82768848e-04, 1.20938775e-03,\n",
       "        6.43217540e-04, 1.16145985e-03, 1.63988939e-03, 1.65051514e-03,\n",
       "        1.90228027e-03, 1.25432647e-03, 1.77798698e-03, 1.91068565e-03,\n",
       "        1.51522391e-03, 1.88535710e-03, 1.79673317e-03, 2.79070022e-03,\n",
       "        2.60662154e-03, 2.22358957e-03, 1.97073750e-03, 2.14352994e-03,\n",
       "        0.00000000e+00, 7.63358779e-05, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 7.96969963e-04, 5.96202265e-04, 7.76602670e-04,\n",
       "        5.06354930e-04, 7.09964704e-04, 1.25432647e-03, 1.14503817e-03,\n",
       "        1.52957747e-03, 1.11539231e-03, 1.46138853e-03, 1.70435981e-03,\n",
       "        2.08146537e-03, 1.80239984e-03, 2.20780990e-03, 1.71713311e-03,\n",
       "        2.23404742e-03, 2.13399401e-03, 2.39151911e-03, 1.84473984e-03,\n",
       "        2.25287856e-03, 7.63358779e-05, 3.05343511e-04, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.52671756e-04, 1.11022302e-16, 1.52671756e-04,\n",
       "        7.63358779e-05, 1.11022302e-16, 7.63358779e-05, 1.11022302e-16,\n",
       "        1.52671756e-04, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 7.63358779e-05, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.04108257e-03, 1.91981318e-03,\n",
       "        1.12837752e-03, 1.05911732e-03, 1.87606194e-03, 1.90839695e-03,\n",
       "        5.91295167e-04, 1.20455983e-03, 1.64786513e-03, 1.71967639e-03,\n",
       "        4.58015267e-04, 7.63358779e-04, 1.29770992e-03, 1.75572519e-03,\n",
       "        7.63358779e-04, 1.56162386e-03, 5.34351145e-04, 1.57185193e-03,\n",
       "        1.45038168e-03, 1.37404580e-03, 4.58015267e-04, 3.05343511e-04,\n",
       "        1.22137405e-03, 8.39694656e-04, 1.29770992e-03, 2.20714997e-03,\n",
       "        2.23013147e-03, 2.07304971e-03, 2.46471516e-03, 2.17121567e-03,\n",
       "        2.38480906e-03, 1.98179465e-03, 2.02685772e-03, 2.15910468e-03,\n",
       "        2.39699519e-03, 3.24764082e-03, 2.40063896e-03, 2.31852558e-03,\n",
       "        2.11960968e-03, 2.21899876e-03, 2.05327903e-03, 2.08566047e-03,\n",
       "        2.55069228e-03, 2.44215164e-03, 2.03903975e-03, 2.19789008e-03,\n",
       "        2.11617042e-03, 2.05682345e-03, 2.15437646e-03, 2.15775481e-03,\n",
       "        2.78913373e-03, 2.52716723e-03, 2.52428332e-03, 2.72573604e-03,\n",
       "        3.00873774e-03, 3.04387817e-03, 2.64049321e-03, 3.10312620e-03,\n",
       "        2.66247023e-03, 2.57003754e-03, 2.64049321e-03, 2.75074088e-03,\n",
       "        3.63017031e-03, 2.91529106e-03, 3.08523517e-03, 3.49273139e-03,\n",
       "        2.95006318e-03, 3.02611827e-03, 2.80216104e-03, 3.16816885e-03,\n",
       "        3.12557902e-03, 3.37823994e-03, 2.85775672e-03, 2.84856613e-03,\n",
       "        3.00146615e-03, 2.16112789e-03, 2.33605248e-03, 2.61777530e-03,\n",
       "        2.64435238e-03, 2.57060431e-03, 2.36948827e-03, 2.93917913e-03,\n",
       "        2.65699302e-03, 2.80320061e-03, 2.68100906e-03, 3.64778483e-03,\n",
       "        2.90026111e-03, 3.02322845e-03, 3.10218714e-03, 3.06866431e-03,\n",
       "        3.34182048e-03, 2.99660861e-03, 3.08287336e-03, 3.28776419e-03,\n",
       "        3.17643485e-03, 4.13801015e-03, 3.86043750e-03, 3.21925693e-03,\n",
       "        3.45541078e-03, 3.27310940e-03, 1.41992941e-03, 1.73653636e-03,\n",
       "        1.67504643e-03, 1.67938931e-03, 1.77962492e-03, 2.25804572e-03,\n",
       "        2.24055880e-03, 2.10789332e-03, 1.88767374e-03, 2.10927510e-03,\n",
       "        2.84191000e-03, 2.57569967e-03, 2.46589699e-03, 2.45108311e-03,\n",
       "        2.39151911e-03, 2.84498399e-03, 2.70804149e-03, 2.96631439e-03,\n",
       "        2.62943582e-03, 2.83421041e-03, 3.35052769e-03, 3.67880329e-03,\n",
       "        3.24898625e-03, 3.14648303e-03, 3.26865558e-03, 1.11015569e-03,\n",
       "        6.20155603e-04, 5.83857196e-04, 7.72841860e-04, 5.71245403e-04,\n",
       "        1.90228027e-03, 1.19728146e-03, 1.38460742e-03, 1.30331077e-03,\n",
       "        1.41272943e-03, 2.16382256e-03, 1.96333147e-03, 1.96629723e-03,\n",
       "        1.81046431e-03, 2.04688361e-03, 2.81512808e-03, 2.82133109e-03,\n",
       "        2.37562845e-03, 2.51329430e-03, 2.48414353e-03, 3.10312620e-03,\n",
       "        2.80631701e-03, 3.00680037e-03, 2.91329155e-03, 2.98443020e-03,\n",
       "        2.09054411e-04, 3.19335888e-04, 2.80475925e-04, 1.52671756e-04,\n",
       "        3.53954904e-04, 5.26108731e-04, 9.76084874e-04, 9.73095327e-04,\n",
       "        8.58566556e-04, 6.67666248e-04, 1.89152850e-03, 1.74323469e-03,\n",
       "        2.13876729e-03, 1.55226713e-03, 1.66194970e-03, 2.21702836e-03,\n",
       "        2.76921483e-03, 2.09541637e-03, 2.56776919e-03, 2.35468654e-03,\n",
       "        2.59317370e-03, 2.86894969e-03, 2.81098514e-03, 2.77709462e-03,\n",
       "        2.80320061e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 5.45147208e-04, 1.94619065e-04,\n",
       "        4.45110832e-04, 8.09664253e-04, 3.53954904e-04, 1.17641489e-03,\n",
       "        1.21539567e-03, 1.25083737e-03, 1.68717833e-03, 1.47330222e-03,\n",
       "        2.37317428e-03, 2.03761035e-03, 2.44274809e-03, 2.75867344e-03,\n",
       "        2.39151911e-03, 2.20384733e-03, 2.73374116e-03, 2.59541985e-03,\n",
       "        2.67556980e-03, 2.91429148e-03, 2.34538801e-03, 2.12304336e-03,\n",
       "        1.94619065e-03, 1.95515244e-03, 2.12372943e-03, 2.06812476e-03,\n",
       "        1.98546669e-03, 2.06036177e-03, 1.95515244e-03, 1.97590521e-03,\n",
       "        1.69836607e-03, 1.33860137e-03, 1.95142336e-03, 1.88690185e-03,\n",
       "        1.92208829e-03, 1.05636279e-03, 1.99205929e-03, 1.96703797e-03,\n",
       "        2.02829470e-03, 1.97811580e-03, 1.63008828e-03, 1.98473282e-03,\n",
       "        1.98473282e-03, 2.02829470e-03, 1.93267006e-03, 2.08566047e-03,\n",
       "        2.00880876e-03, 2.15031542e-03, 2.09541637e-03, 2.06036177e-03,\n",
       "        1.99279046e-03, 2.29833118e-03, 1.84236922e-03, 2.21899876e-03,\n",
       "        2.00735783e-03, 2.24705130e-03, 2.31978189e-03, 2.01025864e-03,\n",
       "        2.01604773e-03, 1.86828065e-03, 2.19058700e-03, 1.82009451e-03,\n",
       "        1.80401562e-03, 1.79186177e-03, 2.16112789e-03, 1.60849676e-03,\n",
       "        2.10996564e-03, 1.68112332e-03, 1.85654756e-03, 1.62650960e-03,\n",
       "        1.91220993e-03, 1.60759082e-03, 1.74657423e-03, 1.94244437e-03,\n",
       "        1.58936357e-03, 2.08566047e-03, 1.80885429e-03, 1.97369213e-03,\n",
       "        1.81689011e-03, 1.52193909e-03, 2.44513242e-03, 1.64343894e-03,\n",
       "        2.12029686e-03, 2.03617995e-03, 1.90686962e-03, 2.27539825e-03,\n",
       "        2.20384733e-03, 2.10581897e-03, 1.94768715e-03, 1.85811625e-03,\n",
       "        2.51908397e-03, 1.79267459e-03, 2.17791490e-03, 2.25610942e-03,\n",
       "        1.95515244e-03, 1.67938931e-03, 1.23913611e-03, 1.63098173e-03,\n",
       "        1.55695252e-03, 1.21659370e-03, 1.76317702e-03, 1.63455062e-03,\n",
       "        1.63008828e-03, 1.85183351e-03, 2.17054461e-03, 2.49817835e-03,\n",
       "        2.20450826e-03, 1.94843496e-03, 1.93267006e-03, 2.31034289e-03,\n",
       "        2.46057427e-03, 2.44513242e-03, 2.24705130e-03, 2.40609428e-03,\n",
       "        2.49817835e-03, 2.23078461e-03, 2.10581897e-03, 2.22096741e-03,\n",
       "        2.28816714e-03, 2.12852572e-03, 1.23913611e-03, 1.33860137e-03,\n",
       "        9.16030534e-04, 1.18012403e-03, 1.08224785e-03, 1.01987704e-03,\n",
       "        1.48512034e-03, 1.47132330e-03, 1.51906479e-03, 9.45764251e-04,\n",
       "        1.84789594e-03, 2.26255730e-03, 1.74323469e-03, 1.91068565e-03,\n",
       "        1.72390684e-03, 2.30466094e-03, 1.46537052e-03, 2.42178505e-03,\n",
       "        1.87606194e-03, 1.85968362e-03, 2.48120961e-03, 2.17121567e-03,\n",
       "        1.29658685e-03, 1.50461094e-03, 1.95142336e-03, 1.37933672e-03,\n",
       "        8.95117511e-04, 1.03547023e-03, 9.92366412e-04, 9.90897327e-04,\n",
       "        1.38880957e-03, 9.14438821e-04, 1.08627859e-03, 1.18873370e-03,\n",
       "        9.92366412e-04, 1.96333147e-03, 1.52957747e-03, 1.74657423e-03,\n",
       "        1.36019311e-03, 1.32767383e-03, 2.04332196e-03, 1.75323421e-03,\n",
       "        1.74323469e-03, 1.80804875e-03, 1.63988939e-03, 2.05753160e-03,\n",
       "        2.04688361e-03, 2.57569967e-03, 2.30086517e-03, 2.19722717e-03,\n",
       "        8.91856599e-04, 7.67166078e-04, 4.35181460e-04, 6.22500245e-04,\n",
       "        5.31617873e-04, 8.86942751e-04, 8.82001527e-04, 1.00693939e-03,\n",
       "        6.56666051e-04, 6.97544537e-04, 1.11669762e-03, 1.34186228e-03,\n",
       "        1.34619787e-03, 1.04248094e-03, 1.06186471e-03, 1.29095683e-03,\n",
       "        1.78779213e-03, 1.56162386e-03, 1.36233346e-03, 1.55320534e-03,\n",
       "        1.61662737e-03, 1.63455062e-03, 1.68976669e-03, 1.79592219e-03,\n",
       "        1.50073307e-03, 1.52671756e-04, 2.58867557e-04, 2.58867557e-04,\n",
       "        1.52671756e-04, 2.41395241e-04, 2.69888084e-04, 4.41825836e-04,\n",
       "        6.45478417e-04, 5.31617873e-04, 3.92962982e-04, 5.31617873e-04,\n",
       "        9.38030972e-04, 7.28197864e-04, 6.45478417e-04, 8.36217645e-04,\n",
       "        1.14884862e-03, 9.39582719e-04, 1.20334983e-03, 1.55695252e-03,\n",
       "        1.02699420e-03, 1.48119144e-03, 1.05636279e-03, 1.26358362e-03,\n",
       "        1.32547751e-03, 1.09695480e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.29007634e-04,\n",
       "        3.10077802e-04, 2.85622701e-04, 3.10077802e-04, 3.28333025e-04,\n",
       "        3.89238131e-04, 5.17735113e-04, 5.73789938e-04, 5.73789938e-04,\n",
       "        4.35181460e-04, 1.24617005e-03, 1.11539231e-03, 1.20938775e-03,\n",
       "        1.16145985e-03, 1.16771439e-03, 1.61301883e-03, 1.03406238e-03,\n",
       "        1.01414735e-03, 9.27096015e-04, 9.47303332e-04, 1.11022302e-16,\n",
       "        7.63358779e-05, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.11022302e-16, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16,\n",
       "        1.46039133e-03, 1.11669762e-03, 7.40103795e-04, 1.37404580e-03,\n",
       "        8.50040361e-04, 6.38671776e-04, 1.57185193e-03, 7.76602670e-04,\n",
       "        1.17269401e-03, 6.20155603e-04, 1.86437782e-03, 1.10357498e-03,\n",
       "        1.67504643e-03, 1.23324385e-03, 9.92366412e-04, 1.78860680e-03,\n",
       "        9.16030534e-04, 5.17735113e-04, 1.72390684e-03, 8.15044141e-04,\n",
       "        9.92366412e-04, 3.81679389e-04, 7.63358779e-04, 1.83206107e-03,\n",
       "        1.45038168e-03, 1.95589740e-03, 2.91329155e-03, 2.59036328e-03,\n",
       "        2.13057798e-03, 2.52428332e-03, 2.69618061e-03, 2.39273710e-03,\n",
       "        2.48941586e-03, 2.42298782e-03, 2.63441739e-03, 2.61499132e-03,\n",
       "        2.25610942e-03, 2.56493093e-03, 2.70804149e-03, 2.25998036e-03,\n",
       "        2.48355702e-03, 2.96729645e-03, 2.78547516e-03, 2.73800098e-03,\n",
       "        2.78024028e-03, 2.16785829e-03, 2.66465797e-03, 2.35097154e-03,\n",
       "        2.56208953e-03, 2.41817314e-03, 2.90327332e-03, 2.59822480e-03,\n",
       "        2.58416960e-03, 3.07388192e-03, 2.28179163e-03, 3.10781725e-03,\n",
       "        2.64545396e-03, 2.35159111e-03, 2.35777789e-03, 2.30086517e-03,\n",
       "        1.91829494e-03, 2.63165102e-03, 1.69407183e-03, 2.37930494e-03,\n",
       "        3.13256252e-03, 2.41576220e-03, 2.51561176e-03, 2.72733894e-03,\n",
       "        2.97367194e-03, 3.03573112e-03, 3.33265343e-03, 3.06628974e-03,\n",
       "        3.07861753e-03, 3.39973297e-03, 2.98930752e-03, 2.82958061e-03,\n",
       "        2.96139920e-03, 2.68426732e-03, 2.81668011e-03, 2.72413220e-03,\n",
       "        2.24380740e-03, 2.30781931e-03, 2.39456292e-03, 2.62888173e-03,\n",
       "        2.60662154e-03, 3.14184971e-03, 2.84088459e-03, 2.68914732e-03,\n",
       "        2.77499553e-03, 3.00437689e-03, 2.89070171e-03, 3.12790859e-03,\n",
       "        3.04483522e-03, 3.41683005e-03, 3.09701722e-03, 3.68276112e-03,\n",
       "        3.48019612e-03, 3.04244204e-03, 3.20246977e-03, 3.25436240e-03,\n",
       "        1.75904101e-03, 1.80239984e-03, 1.77552723e-03, 1.56162386e-03,\n",
       "        1.54850861e-03, 1.53148112e-03, 1.79267459e-03, 1.48119144e-03,\n",
       "        1.67069226e-03, 1.70862819e-03, 1.54756755e-03, 2.06106870e-03,\n",
       "        1.37298517e-03, 1.95887442e-03, 2.14352994e-03, 2.23078461e-03,\n",
       "        2.30718798e-03, 2.69509976e-03, 2.32667949e-03, 2.38480906e-03,\n",
       "        3.04770455e-03, 2.90076336e-03, 2.56208953e-03, 2.61944427e-03,\n",
       "        2.67066499e-03, 6.78488123e-04, 9.31798139e-04, 6.45478417e-04,\n",
       "        7.34174964e-04, 8.22162566e-04, 8.98366587e-04, 9.68593705e-04,\n",
       "        1.07278392e-03, 7.38132809e-04, 9.45764251e-04, 1.30331077e-03,\n",
       "        1.12190370e-03, 1.19240453e-03, 1.35804938e-03, 1.09695480e-03,\n",
       "        1.76977452e-03, 1.50461094e-03, 1.73065405e-03, 1.81448310e-03,\n",
       "        1.60759082e-03, 2.30718798e-03, 2.15234690e-03, 2.14080972e-03,\n",
       "        2.39395447e-03, 2.08496188e-03, 3.53954904e-04, 2.29007634e-04,\n",
       "        1.42811351e-04, 1.94619065e-04, 1.42811351e-04, 4.07522071e-04,\n",
       "        4.41825836e-04, 4.58015267e-04, 3.32740377e-04, 4.97649039e-04,\n",
       "        5.58348811e-04, 8.70362920e-04, 8.23932563e-04, 7.95139949e-04,\n",
       "        8.06057713e-04, 1.88535710e-03, 1.11277708e-03, 1.42095500e-03,\n",
       "        1.22256621e-03, 1.11277708e-03, 1.65492240e-03, 1.67417650e-03,\n",
       "        1.77962492e-03, 1.66632671e-03, 1.70093740e-03, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        2.22555416e-04, 1.94619065e-04, 2.22555416e-04, 4.91759493e-04,\n",
       "        3.32740377e-04, 3.05343511e-04, 4.11081283e-04, 3.10077802e-04,\n",
       "        3.28333025e-04, 3.10077802e-04, 1.09296344e-03, 4.35181460e-04,\n",
       "        9.84999076e-04, 5.47812981e-04, 7.24185724e-04, 1.20334983e-03,\n",
       "        1.52385227e-03, 1.47033285e-03, 1.53812532e-03, 1.18505150e-03])}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid Search\n",
    "\n",
    "# Usando um grid completo de todos os parâmetros\n",
    "param_grid = {\"max_depth\": [3, 4, 5, 6, 7, 8, 9, 10, None],\n",
    "              \"min_samples_leaf\": [1, 3, 5, 7, 9],\n",
    "              \"n_estimators\":[100, 200, 300, 400, 500],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# Executando o Grid Search\n",
    "grid_search = GridSearchCV(modelo4_multi, param_grid = param_grid, return_train_score = True)\n",
    "start = time.time()\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"GridSearchCV executou em %.2f segundos para todas as combinações de candidatos a parâmetros do modelo.\"\n",
    "      % (time.time() - start))\n",
    "grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6913febb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de confusão\n",
      " [[18  0  0  0  0  0]\n",
      " [ 0 14  0  0  0  0]\n",
      " [ 0  0 10  0  0  0]\n",
      " [ 0  0  0  8  0  0]\n",
      " [ 0  2  0  0  0  0]\n",
      " [ 0  6  0  0  0  3]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Modelo': 'Random Forest Grid Search',\n",
       " 'Versão': 'Otimizada',\n",
       " 'Precision': 0.8837555886736215,\n",
       " 'Recall': 0.8688524590163934,\n",
       " 'F1 Score': 0.8424408014571948,\n",
       " 'Acurácia': 0.8688524590163934}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsoes_multi = grid_search.predict(X_falha_val)\n",
    "\n",
    "# Avaliação do modelo\n",
    "# Matriz de confusão\n",
    "print('\\nMatriz de confusão\\n', confusion_matrix(y_falha_val, previsoes_multi))\n",
    "\n",
    "# Dicionário de métricas e metadados\n",
    "dict_model =   {'Modelo': 'Random Forest Grid Search',\n",
    "                'Versão': 'Otimizada',\n",
    "                'Precision':precision_score(y_falha_val, previsoes_multi, average = 'weighted', zero_division=0),\n",
    "                'Recall':recall_score(y_falha_val, previsoes_multi, average = 'weighted', zero_division=0),\n",
    "                'F1 Score':f1_score(y_falha_val, previsoes_multi, average = 'weighted', zero_division=0),\n",
    "                'Acurácia':accuracy_score(y_falha_val, previsoes_multi)}\n",
    "\n",
    "dict_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6e1e29",
   "metadata": {},
   "source": [
    "# Previsões para o conjunto sem labels\n",
    "\n",
    "O objetivo final da modelagem era utilizar o modelo para prever o tipo de falha em 3333 registros que estão armazenados na variável _df\\_teste_. Para isso, contudo, precisamos aplicar todas as transformações que foram feitas na etapa de pré-processamento, como encoding, padronização e normalização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fc9fe169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>udi</th>\n",
       "      <th>product_id</th>\n",
       "      <th>type</th>\n",
       "      <th>air_temperature_k</th>\n",
       "      <th>process_temperature_k</th>\n",
       "      <th>rotational_speed_rpm</th>\n",
       "      <th>torque_nm</th>\n",
       "      <th>tool_wear_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>446</td>\n",
       "      <td>L47625</td>\n",
       "      <td>L</td>\n",
       "      <td>297.5</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1793</td>\n",
       "      <td>26.7</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7076</td>\n",
       "      <td>L54255</td>\n",
       "      <td>L</td>\n",
       "      <td>300.7</td>\n",
       "      <td>310.5</td>\n",
       "      <td>1536</td>\n",
       "      <td>47.4</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1191</td>\n",
       "      <td>L48370</td>\n",
       "      <td>L</td>\n",
       "      <td>297.2</td>\n",
       "      <td>308.4</td>\n",
       "      <td>1460</td>\n",
       "      <td>42.1</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2618</td>\n",
       "      <td>L49797</td>\n",
       "      <td>L</td>\n",
       "      <td>299.4</td>\n",
       "      <td>309.1</td>\n",
       "      <td>1670</td>\n",
       "      <td>35.9</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5067</td>\n",
       "      <td>L52246</td>\n",
       "      <td>L</td>\n",
       "      <td>304.1</td>\n",
       "      <td>313.1</td>\n",
       "      <td>1550</td>\n",
       "      <td>30.9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3328</th>\n",
       "      <td>5554</td>\n",
       "      <td>L52733</td>\n",
       "      <td>L</td>\n",
       "      <td>302.5</td>\n",
       "      <td>311.9</td>\n",
       "      <td>1306</td>\n",
       "      <td>59.7</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3329</th>\n",
       "      <td>6961</td>\n",
       "      <td>L54140</td>\n",
       "      <td>L</td>\n",
       "      <td>300.7</td>\n",
       "      <td>311.0</td>\n",
       "      <td>1413</td>\n",
       "      <td>52.0</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3330</th>\n",
       "      <td>6914</td>\n",
       "      <td>L54093</td>\n",
       "      <td>L</td>\n",
       "      <td>300.8</td>\n",
       "      <td>311.2</td>\n",
       "      <td>1481</td>\n",
       "      <td>38.5</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3331</th>\n",
       "      <td>5510</td>\n",
       "      <td>L52689</td>\n",
       "      <td>L</td>\n",
       "      <td>302.8</td>\n",
       "      <td>312.2</td>\n",
       "      <td>1509</td>\n",
       "      <td>36.5</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3332</th>\n",
       "      <td>3066</td>\n",
       "      <td>M17925</td>\n",
       "      <td>M</td>\n",
       "      <td>300.1</td>\n",
       "      <td>309.2</td>\n",
       "      <td>1687</td>\n",
       "      <td>27.7</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3333 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       udi product_id type  air_temperature_k  process_temperature_k  \\\n",
       "0      446     L47625    L              297.5                  308.6   \n",
       "1     7076     L54255    L              300.7                  310.5   \n",
       "2     1191     L48370    L              297.2                  308.4   \n",
       "3     2618     L49797    L              299.4                  309.1   \n",
       "4     5067     L52246    L              304.1                  313.1   \n",
       "...    ...        ...  ...                ...                    ...   \n",
       "3328  5554     L52733    L              302.5                  311.9   \n",
       "3329  6961     L54140    L              300.7                  311.0   \n",
       "3330  6914     L54093    L              300.8                  311.2   \n",
       "3331  5510     L52689    L              302.8                  312.2   \n",
       "3332  3066     M17925    M              300.1                  309.2   \n",
       "\n",
       "      rotational_speed_rpm  torque_nm  tool_wear_min  \n",
       "0                     1793       26.7             70  \n",
       "1                     1536       47.4            192  \n",
       "2                     1460       42.1             41  \n",
       "3                     1670       35.9             68  \n",
       "4                     1550       30.9              9  \n",
       "...                    ...        ...            ...  \n",
       "3328                  1306       59.7            172  \n",
       "3329                  1413       52.0             91  \n",
       "3330                  1481       38.5            181  \n",
       "3331                  1509       36.5             52  \n",
       "3332                  1687       27.7             95  \n",
       "\n",
       "[3333 rows x 8 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a41e892",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
