{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58cf901c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.utils import class_weight, resample\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0ee2400",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treino = pd.read_csv(\"desafio_manutencao_preditiva_treino.csv\")\n",
    "df_teste = pd.read_csv(\"desafio_manutencao_preditiva_teste.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95c93f9",
   "metadata": {},
   "source": [
    "# Definição dos tipos de variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc9037b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['type', 'air_temperature_k', 'process_temperature_k',\n",
       "       'rotational_speed_rpm', 'torque_nm', 'tool_wear_min'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'failure_type'\n",
    "features = df_treino.columns.drop([target, 'udi', 'product_id'])\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a964eb3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['air_temperature_k', 'process_temperature_k', 'rotational_speed_rpm',\n",
       "       'torque_nm', 'tool_wear_min'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical = df_treino[features].select_dtypes('number').columns\n",
    "numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5802b5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = 'type'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7530cf",
   "metadata": {},
   "source": [
    "# Separação do dataset em entrada e saída (X e y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1ee4c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_treino[features]\n",
    "y = df_treino[target] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d619cb",
   "metadata": {},
   "source": [
    "# Divisão do dataset em treino e validação\n",
    "\n",
    "Como os dados de teste não possuem a variável target, é importante que separemos uma parte do dataset de treino para validar o modelo e garantir que não haja overfitting. Dividiremos então o dataset em treino e validação. Usaremos 25% dos dados para validação.\n",
    "\n",
    "Além disso, é importante dividir os dados antes do pré-processamento para evitar uma falha chamada _data leakage_, que é o compartilhamento de informações entre o conjunto de dados usado no treinamento do modelo e o dataset usado para avaliação do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1f02c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão em Dados de Treino e Validação.\n",
    "X_treino, X_val, y_treino, y_val = train_test_split(X, y, test_size = 0.25, random_state = 101, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fef7cc",
   "metadata": {},
   "source": [
    "# Pré-Processamento dos Dados\n",
    "\n",
    "Muitos algoritmos preditivos esperam receber os dados padronizados e codificados. Portanto, é necessário transformar os dados para adequá-los aos modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93bac177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cópia dos dados = boa prática\n",
    "X_treino_copy = X_treino.copy()\n",
    "y_treino_copy = y_treino.copy()\n",
    "X_val_copy = X_val.copy()\n",
    "y_val_copy = y_val.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d7b76e",
   "metadata": {},
   "source": [
    "## Encoding da variável categórica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b763c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Número de classes da variável categórica\n",
    "X_treino[categorical].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dfd070",
   "metadata": {},
   "source": [
    "A variável type possui apenas 3 classes, vamos aplicar a técnica de OneHotEncoding para sua codificação;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b5a0cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_temperature_k</th>\n",
       "      <th>process_temperature_k</th>\n",
       "      <th>rotational_speed_rpm</th>\n",
       "      <th>torque_nm</th>\n",
       "      <th>tool_wear_min</th>\n",
       "      <th>H</th>\n",
       "      <th>L</th>\n",
       "      <th>M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2685</th>\n",
       "      <td>302.1</td>\n",
       "      <td>311.2</td>\n",
       "      <td>1598</td>\n",
       "      <td>37.9</td>\n",
       "      <td>148</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2281</th>\n",
       "      <td>301.4</td>\n",
       "      <td>310.6</td>\n",
       "      <td>1630</td>\n",
       "      <td>30.3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>298.0</td>\n",
       "      <td>308.3</td>\n",
       "      <td>1473</td>\n",
       "      <td>42.6</td>\n",
       "      <td>107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6057</th>\n",
       "      <td>297.3</td>\n",
       "      <td>308.1</td>\n",
       "      <td>1709</td>\n",
       "      <td>30.6</td>\n",
       "      <td>196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>298.0</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1436</td>\n",
       "      <td>48.2</td>\n",
       "      <td>201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5535</th>\n",
       "      <td>298.8</td>\n",
       "      <td>310.0</td>\n",
       "      <td>1295</td>\n",
       "      <td>52.7</td>\n",
       "      <td>74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>299.5</td>\n",
       "      <td>309.1</td>\n",
       "      <td>1420</td>\n",
       "      <td>49.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>297.1</td>\n",
       "      <td>308.0</td>\n",
       "      <td>1348</td>\n",
       "      <td>58.0</td>\n",
       "      <td>162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6508</th>\n",
       "      <td>298.7</td>\n",
       "      <td>309.6</td>\n",
       "      <td>1424</td>\n",
       "      <td>50.4</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>297.2</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1636</td>\n",
       "      <td>31.3</td>\n",
       "      <td>192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      air_temperature_k  process_temperature_k  rotational_speed_rpm  \\\n",
       "2685              302.1                  311.2                  1598   \n",
       "2281              301.4                  310.6                  1630   \n",
       "202               298.0                  308.3                  1473   \n",
       "6057              297.3                  308.1                  1709   \n",
       "998               298.0                  308.7                  1436   \n",
       "...                 ...                    ...                   ...   \n",
       "5535              298.8                  310.0                  1295   \n",
       "1450              299.5                  309.1                  1420   \n",
       "769               297.1                  308.0                  1348   \n",
       "6508              298.7                  309.6                  1424   \n",
       "830               297.2                  308.6                  1636   \n",
       "\n",
       "      torque_nm  tool_wear_min    H    L    M  \n",
       "2685       37.9            148  1.0  0.0  0.0  \n",
       "2281       30.3              2  0.0  0.0  1.0  \n",
       "202        42.6            107  0.0  1.0  0.0  \n",
       "6057       30.6            196  0.0  0.0  1.0  \n",
       "998        48.2            201  0.0  0.0  1.0  \n",
       "...         ...            ...  ...  ...  ...  \n",
       "5535       52.7             74  0.0  0.0  1.0  \n",
       "1450       49.5              5  0.0  0.0  1.0  \n",
       "769        58.0            162  0.0  1.0  0.0  \n",
       "6508       50.4             32  0.0  0.0  1.0  \n",
       "830        31.3            192  0.0  1.0  0.0  \n",
       "\n",
       "[5000 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OneHotEncoding\n",
    "onehot = OneHotEncoder()\n",
    "cat_encoded = onehot.fit_transform(X_treino[[categorical]])\n",
    "X_treino[onehot.categories_[0]] = cat_encoded.toarray()\n",
    "X_treino.drop(columns='type', inplace = True)\n",
    "X_treino"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e669d6fc",
   "metadata": {},
   "source": [
    "## Padronização e normalização das variáveis numéricas\n",
    "\n",
    "Os dados podem ser padronizados ou normalizados. A padronização consiste em deixá-los numa distribuição normal com média 0 e desvio padrão 1. Já a normalização trata de deixar os dados numa escala única, geralmente de 0 a 1 ou de -1 a 1. \n",
    "\n",
    "Para os dados cuja distribuição não é gaussiana (ou normal), a normalização geralmente é uma melhor opção.\n",
    "\n",
    "Para os dados nesse problema, será aplicada a padronização para as variáveis numéricas cuja distribuição é normal e a normalização para a variável tool_wear_min que tem uma distribuição uniforme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "065430da",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = [col for col in numerical if col != 'tool_wear_min']\n",
    "scaler = StandardScaler()\n",
    "X_treino[scale] = scaler.fit_transform(X_treino[scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4020852a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_temperature_k</th>\n",
       "      <th>process_temperature_k</th>\n",
       "      <th>rotational_speed_rpm</th>\n",
       "      <th>torque_nm</th>\n",
       "      <th>tool_wear_min</th>\n",
       "      <th>H</th>\n",
       "      <th>L</th>\n",
       "      <th>M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2685</th>\n",
       "      <td>1.060613</td>\n",
       "      <td>0.813864</td>\n",
       "      <td>0.338430</td>\n",
       "      <td>-0.217692</td>\n",
       "      <td>148</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2281</th>\n",
       "      <td>0.709081</td>\n",
       "      <td>0.410828</td>\n",
       "      <td>0.518479</td>\n",
       "      <td>-0.978057</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>-0.998362</td>\n",
       "      <td>-1.134143</td>\n",
       "      <td>-0.364888</td>\n",
       "      <td>0.252533</td>\n",
       "      <td>107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6057</th>\n",
       "      <td>-1.349894</td>\n",
       "      <td>-1.268489</td>\n",
       "      <td>0.962976</td>\n",
       "      <td>-0.948043</td>\n",
       "      <td>196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-0.998362</td>\n",
       "      <td>-0.865453</td>\n",
       "      <td>-0.573070</td>\n",
       "      <td>0.812802</td>\n",
       "      <td>201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5535</th>\n",
       "      <td>-0.596610</td>\n",
       "      <td>0.007792</td>\n",
       "      <td>-1.366413</td>\n",
       "      <td>1.263018</td>\n",
       "      <td>74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>-0.245078</td>\n",
       "      <td>-0.596762</td>\n",
       "      <td>-0.663095</td>\n",
       "      <td>0.942865</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>-1.450332</td>\n",
       "      <td>-1.335661</td>\n",
       "      <td>-1.068206</td>\n",
       "      <td>1.793273</td>\n",
       "      <td>162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6508</th>\n",
       "      <td>-0.646829</td>\n",
       "      <td>-0.260899</td>\n",
       "      <td>-0.640589</td>\n",
       "      <td>1.032908</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>-1.400113</td>\n",
       "      <td>-0.932625</td>\n",
       "      <td>0.552238</td>\n",
       "      <td>-0.878009</td>\n",
       "      <td>192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      air_temperature_k  process_temperature_k  rotational_speed_rpm  \\\n",
       "2685           1.060613               0.813864              0.338430   \n",
       "2281           0.709081               0.410828              0.518479   \n",
       "202           -0.998362              -1.134143             -0.364888   \n",
       "6057          -1.349894              -1.268489              0.962976   \n",
       "998           -0.998362              -0.865453             -0.573070   \n",
       "...                 ...                    ...                   ...   \n",
       "5535          -0.596610               0.007792             -1.366413   \n",
       "1450          -0.245078              -0.596762             -0.663095   \n",
       "769           -1.450332              -1.335661             -1.068206   \n",
       "6508          -0.646829              -0.260899             -0.640589   \n",
       "830           -1.400113              -0.932625              0.552238   \n",
       "\n",
       "      torque_nm  tool_wear_min    H    L    M  \n",
       "2685  -0.217692            148  1.0  0.0  0.0  \n",
       "2281  -0.978057              2  0.0  0.0  1.0  \n",
       "202    0.252533            107  0.0  1.0  0.0  \n",
       "6057  -0.948043            196  0.0  0.0  1.0  \n",
       "998    0.812802            201  0.0  0.0  1.0  \n",
       "...         ...            ...  ...  ...  ...  \n",
       "5535   1.263018             74  0.0  0.0  1.0  \n",
       "1450   0.942865              5  0.0  0.0  1.0  \n",
       "769    1.793273            162  0.0  1.0  0.0  \n",
       "6508   1.032908             32  0.0  0.0  1.0  \n",
       "830   -0.878009            192  0.0  1.0  0.0  \n",
       "\n",
       "[5000 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5bf8374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_temperature_k</th>\n",
       "      <th>process_temperature_k</th>\n",
       "      <th>rotational_speed_rpm</th>\n",
       "      <th>torque_nm</th>\n",
       "      <th>tool_wear_min</th>\n",
       "      <th>H</th>\n",
       "      <th>L</th>\n",
       "      <th>M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2685</th>\n",
       "      <td>1.060613</td>\n",
       "      <td>0.813864</td>\n",
       "      <td>0.338430</td>\n",
       "      <td>-0.217692</td>\n",
       "      <td>0.601626</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2281</th>\n",
       "      <td>0.709081</td>\n",
       "      <td>0.410828</td>\n",
       "      <td>0.518479</td>\n",
       "      <td>-0.978057</td>\n",
       "      <td>0.008130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>-0.998362</td>\n",
       "      <td>-1.134143</td>\n",
       "      <td>-0.364888</td>\n",
       "      <td>0.252533</td>\n",
       "      <td>0.434959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6057</th>\n",
       "      <td>-1.349894</td>\n",
       "      <td>-1.268489</td>\n",
       "      <td>0.962976</td>\n",
       "      <td>-0.948043</td>\n",
       "      <td>0.796748</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-0.998362</td>\n",
       "      <td>-0.865453</td>\n",
       "      <td>-0.573070</td>\n",
       "      <td>0.812802</td>\n",
       "      <td>0.817073</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5535</th>\n",
       "      <td>-0.596610</td>\n",
       "      <td>0.007792</td>\n",
       "      <td>-1.366413</td>\n",
       "      <td>1.263018</td>\n",
       "      <td>0.300813</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>-0.245078</td>\n",
       "      <td>-0.596762</td>\n",
       "      <td>-0.663095</td>\n",
       "      <td>0.942865</td>\n",
       "      <td>0.020325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>-1.450332</td>\n",
       "      <td>-1.335661</td>\n",
       "      <td>-1.068206</td>\n",
       "      <td>1.793273</td>\n",
       "      <td>0.658537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6508</th>\n",
       "      <td>-0.646829</td>\n",
       "      <td>-0.260899</td>\n",
       "      <td>-0.640589</td>\n",
       "      <td>1.032908</td>\n",
       "      <td>0.130081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>-1.400113</td>\n",
       "      <td>-0.932625</td>\n",
       "      <td>0.552238</td>\n",
       "      <td>-0.878009</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      air_temperature_k  process_temperature_k  rotational_speed_rpm  \\\n",
       "2685           1.060613               0.813864              0.338430   \n",
       "2281           0.709081               0.410828              0.518479   \n",
       "202           -0.998362              -1.134143             -0.364888   \n",
       "6057          -1.349894              -1.268489              0.962976   \n",
       "998           -0.998362              -0.865453             -0.573070   \n",
       "...                 ...                    ...                   ...   \n",
       "5535          -0.596610               0.007792             -1.366413   \n",
       "1450          -0.245078              -0.596762             -0.663095   \n",
       "769           -1.450332              -1.335661             -1.068206   \n",
       "6508          -0.646829              -0.260899             -0.640589   \n",
       "830           -1.400113              -0.932625              0.552238   \n",
       "\n",
       "      torque_nm  tool_wear_min    H    L    M  \n",
       "2685  -0.217692       0.601626  1.0  0.0  0.0  \n",
       "2281  -0.978057       0.008130  0.0  0.0  1.0  \n",
       "202    0.252533       0.434959  0.0  1.0  0.0  \n",
       "6057  -0.948043       0.796748  0.0  0.0  1.0  \n",
       "998    0.812802       0.817073  0.0  0.0  1.0  \n",
       "...         ...            ...  ...  ...  ...  \n",
       "5535   1.263018       0.300813  0.0  0.0  1.0  \n",
       "1450   0.942865       0.020325  0.0  0.0  1.0  \n",
       "769    1.793273       0.658537  0.0  1.0  0.0  \n",
       "6508   1.032908       0.130081  0.0  0.0  1.0  \n",
       "830   -0.878009       0.780488  0.0  1.0  0.0  \n",
       "\n",
       "[5000 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize = ['tool_wear_min']\n",
    "normalizer = MinMaxScaler()\n",
    "X_treino[normalize] = normalizer.fit_transform(X_treino[normalize])\n",
    "X_treino"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd7f6a6",
   "metadata": {},
   "source": [
    "Na análise exploratória, vimos que as variáveis rotational_speed_rpm e torque_nm possuíam valores _outliers_, vamos verificar agora quantos valores desse existem no dataset de treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a53bb455",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_temperature_k</th>\n",
       "      <th>process_temperature_k</th>\n",
       "      <th>rotational_speed_rpm</th>\n",
       "      <th>torque_nm</th>\n",
       "      <th>tool_wear_min</th>\n",
       "      <th>H</th>\n",
       "      <th>L</th>\n",
       "      <th>M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.457986</td>\n",
       "      <td>0.007792</td>\n",
       "      <td>5.948093</td>\n",
       "      <td>-2.638855</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.206892</td>\n",
       "      <td>0.343655</td>\n",
       "      <td>4.985954</td>\n",
       "      <td>-2.558816</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.998362</td>\n",
       "      <td>-1.201316</td>\n",
       "      <td>3.106689</td>\n",
       "      <td>-2.108600</td>\n",
       "      <td>0.581301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.558424</td>\n",
       "      <td>0.746691</td>\n",
       "      <td>3.101062</td>\n",
       "      <td>-2.028562</td>\n",
       "      <td>0.658537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.349894</td>\n",
       "      <td>-1.134143</td>\n",
       "      <td>3.658090</td>\n",
       "      <td>-2.308696</td>\n",
       "      <td>0.130081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>-1.400113</td>\n",
       "      <td>-1.402834</td>\n",
       "      <td>-1.191990</td>\n",
       "      <td>3.534108</td>\n",
       "      <td>0.699187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.106454</td>\n",
       "      <td>0.679519</td>\n",
       "      <td>-1.591474</td>\n",
       "      <td>3.173936</td>\n",
       "      <td>0.605691</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.558424</td>\n",
       "      <td>0.276483</td>\n",
       "      <td>-1.270762</td>\n",
       "      <td>3.354022</td>\n",
       "      <td>0.199187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.257111</td>\n",
       "      <td>-0.126553</td>\n",
       "      <td>-1.203243</td>\n",
       "      <td>3.273984</td>\n",
       "      <td>0.646341</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1.412145</td>\n",
       "      <td>1.552764</td>\n",
       "      <td>-1.552089</td>\n",
       "      <td>3.043873</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    air_temperature_k  process_temperature_k  rotational_speed_rpm  torque_nm  \\\n",
       "0            0.457986               0.007792              5.948093  -2.638855   \n",
       "1            0.206892               0.343655              4.985954  -2.558816   \n",
       "2           -0.998362              -1.201316              3.106689  -2.108600   \n",
       "3            0.558424               0.746691              3.101062  -2.028562   \n",
       "4           -1.349894              -1.134143              3.658090  -2.308696   \n",
       "..                ...                    ...                   ...        ...   \n",
       "86          -1.400113              -1.402834             -1.191990   3.534108   \n",
       "87           0.106454               0.679519             -1.591474   3.173936   \n",
       "88           0.558424               0.276483             -1.270762   3.354022   \n",
       "89           0.257111              -0.126553             -1.203243   3.273984   \n",
       "90           1.412145               1.552764             -1.552089   3.043873   \n",
       "\n",
       "    tool_wear_min    H    L    M  \n",
       "0        0.841463  0.0  1.0  0.0  \n",
       "1        0.048780  0.0  1.0  0.0  \n",
       "2        0.581301  0.0  0.0  1.0  \n",
       "3        0.658537  0.0  0.0  1.0  \n",
       "4        0.130081  0.0  1.0  0.0  \n",
       "..            ...  ...  ...  ...  \n",
       "86       0.699187  0.0  1.0  0.0  \n",
       "87       0.605691  0.0  1.0  0.0  \n",
       "88       0.199187  0.0  1.0  0.0  \n",
       "89       0.646341  1.0  0.0  0.0  \n",
       "90       0.951220  0.0  0.0  1.0  \n",
       "\n",
       "[91 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# União de todas as linhas onde uma das duas variáveis possui um outlier\n",
    "outliers = pd.merge(X_treino.loc[abs(X_treino['rotational_speed_rpm']) > 3],\n",
    "                    X_treino.loc[abs(X_treino['torque_nm']) > 3],\n",
    "                    how='outer')\n",
    "outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f52e192f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0182"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proporção de outliers\n",
    "len(outliers)/len(X_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c701175e",
   "metadata": {},
   "source": [
    "Como a proporção de outliers é de menos de 2%, não há grande prejuízo em apenas remover essas linhas para que elas não comprometam o treinamento do modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8a2a97f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_temperature_k</th>\n",
       "      <th>process_temperature_k</th>\n",
       "      <th>rotational_speed_rpm</th>\n",
       "      <th>torque_nm</th>\n",
       "      <th>tool_wear_min</th>\n",
       "      <th>H</th>\n",
       "      <th>L</th>\n",
       "      <th>M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2685</th>\n",
       "      <td>1.060613</td>\n",
       "      <td>0.813864</td>\n",
       "      <td>0.338430</td>\n",
       "      <td>-0.217692</td>\n",
       "      <td>0.601626</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2281</th>\n",
       "      <td>0.709081</td>\n",
       "      <td>0.410828</td>\n",
       "      <td>0.518479</td>\n",
       "      <td>-0.978057</td>\n",
       "      <td>0.008130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>-0.998362</td>\n",
       "      <td>-1.134143</td>\n",
       "      <td>-0.364888</td>\n",
       "      <td>0.252533</td>\n",
       "      <td>0.434959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6057</th>\n",
       "      <td>-1.349894</td>\n",
       "      <td>-1.268489</td>\n",
       "      <td>0.962976</td>\n",
       "      <td>-0.948043</td>\n",
       "      <td>0.796748</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-0.998362</td>\n",
       "      <td>-0.865453</td>\n",
       "      <td>-0.573070</td>\n",
       "      <td>0.812802</td>\n",
       "      <td>0.817073</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5535</th>\n",
       "      <td>-0.596610</td>\n",
       "      <td>0.007792</td>\n",
       "      <td>-1.366413</td>\n",
       "      <td>1.263018</td>\n",
       "      <td>0.300813</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>-0.245078</td>\n",
       "      <td>-0.596762</td>\n",
       "      <td>-0.663095</td>\n",
       "      <td>0.942865</td>\n",
       "      <td>0.020325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>-1.450332</td>\n",
       "      <td>-1.335661</td>\n",
       "      <td>-1.068206</td>\n",
       "      <td>1.793273</td>\n",
       "      <td>0.658537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6508</th>\n",
       "      <td>-0.646829</td>\n",
       "      <td>-0.260899</td>\n",
       "      <td>-0.640589</td>\n",
       "      <td>1.032908</td>\n",
       "      <td>0.130081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>-1.400113</td>\n",
       "      <td>-0.932625</td>\n",
       "      <td>0.552238</td>\n",
       "      <td>-0.878009</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4909 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      air_temperature_k  process_temperature_k  rotational_speed_rpm  \\\n",
       "2685           1.060613               0.813864              0.338430   \n",
       "2281           0.709081               0.410828              0.518479   \n",
       "202           -0.998362              -1.134143             -0.364888   \n",
       "6057          -1.349894              -1.268489              0.962976   \n",
       "998           -0.998362              -0.865453             -0.573070   \n",
       "...                 ...                    ...                   ...   \n",
       "5535          -0.596610               0.007792             -1.366413   \n",
       "1450          -0.245078              -0.596762             -0.663095   \n",
       "769           -1.450332              -1.335661             -1.068206   \n",
       "6508          -0.646829              -0.260899             -0.640589   \n",
       "830           -1.400113              -0.932625              0.552238   \n",
       "\n",
       "      torque_nm  tool_wear_min    H    L    M  \n",
       "2685  -0.217692       0.601626  1.0  0.0  0.0  \n",
       "2281  -0.978057       0.008130  0.0  0.0  1.0  \n",
       "202    0.252533       0.434959  0.0  1.0  0.0  \n",
       "6057  -0.948043       0.796748  0.0  0.0  1.0  \n",
       "998    0.812802       0.817073  0.0  0.0  1.0  \n",
       "...         ...            ...  ...  ...  ...  \n",
       "5535   1.263018       0.300813  0.0  0.0  1.0  \n",
       "1450   0.942865       0.020325  0.0  0.0  1.0  \n",
       "769    1.793273       0.658537  0.0  1.0  0.0  \n",
       "6508   1.032908       0.130081  0.0  0.0  1.0  \n",
       "830   -0.878009       0.780488  0.0  1.0  0.0  \n",
       "\n",
       "[4909 rows x 8 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_treino = X_treino.loc[abs(X_treino['rotational_speed_rpm']) < 3]\n",
    "X_treino = X_treino.loc[abs(X_treino['torque_nm']) < 3]\n",
    "X_treino"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177add46",
   "metadata": {},
   "source": [
    "Se removemos essas linhas do dataset de entrada X, também as removeremos da saída y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53b1826e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2685    No Failure\n",
       "2281    No Failure\n",
       "202     No Failure\n",
       "6057    No Failure\n",
       "998     No Failure\n",
       "           ...    \n",
       "5535    No Failure\n",
       "1450    No Failure\n",
       "769     No Failure\n",
       "6508    No Failure\n",
       "830     No Failure\n",
       "Name: failure_type, Length: 4909, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removendo as mesmas linhas do dataset y\n",
    "y_treino = y_treino.loc[y_treino_copy.index.isin(X_treino.index)]\n",
    "y_treino"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ea2c0a",
   "metadata": {},
   "source": [
    "## Encoding da variável target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7092f413",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Número de classes da variável target\n",
    "y_treino.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cd9ea6",
   "metadata": {},
   "source": [
    "A variável target failure_type possui 6 classes distintas. Vamos aplicar a técnica de label encoding para sua codificação, a fim de que haja apenas uma coluna para a variável a ser prevista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47512bc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2685    1\n",
       "2281    1\n",
       "202     1\n",
       "6057    1\n",
       "998     1\n",
       "       ..\n",
       "5535    1\n",
       "1450    1\n",
       "769     1\n",
       "6508    1\n",
       "830     1\n",
       "Length: 4909, dtype: int32"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y_treino = pd.Series(le.fit_transform(y_treino), index = y_treino.index)\n",
    "y_treino"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29995548",
   "metadata": {},
   "source": [
    "## Pré-processamento do dataset de validação\n",
    "\n",
    "Agora, com as transformações treinadas, é preciso transformar todos os dados de validação da mesma forma que os dados de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5735ed37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variável target\n",
    "y_val = pd.Series(le.transform(y_val), index = y_val.index)\n",
    "\n",
    "# One Hot Encoding\n",
    "cat_encoded_val = onehot.transform(X_val[[categorical]])\n",
    "X_val[onehot.categories_[0]] = cat_encoded_val.toarray()\n",
    "X_val.drop(columns='type', inplace = True)\n",
    "\n",
    "# Scaling\n",
    "X_val[scale] = scaler.transform(X_val[scale])\n",
    "\n",
    "# Normalizing\n",
    "X_val[normalize] = normalizer.transform(X_val[normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92beb2a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5089    1\n",
       "2028    1\n",
       "2438    1\n",
       "4076    1\n",
       "2330    4\n",
       "       ..\n",
       "6252    1\n",
       "6532    1\n",
       "6002    1\n",
       "664     1\n",
       "454     1\n",
       "Length: 1667, dtype: int32"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42b32358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_temperature_k</th>\n",
       "      <th>process_temperature_k</th>\n",
       "      <th>rotational_speed_rpm</th>\n",
       "      <th>torque_nm</th>\n",
       "      <th>tool_wear_min</th>\n",
       "      <th>H</th>\n",
       "      <th>L</th>\n",
       "      <th>M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5089</th>\n",
       "      <td>0.206892</td>\n",
       "      <td>0.948209</td>\n",
       "      <td>0.698529</td>\n",
       "      <td>-1.078106</td>\n",
       "      <td>0.524390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028</th>\n",
       "      <td>0.307330</td>\n",
       "      <td>-0.059381</td>\n",
       "      <td>-0.499925</td>\n",
       "      <td>0.232524</td>\n",
       "      <td>0.686992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>1.060613</td>\n",
       "      <td>0.881037</td>\n",
       "      <td>-0.691228</td>\n",
       "      <td>0.402605</td>\n",
       "      <td>0.174797</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4076</th>\n",
       "      <td>0.457986</td>\n",
       "      <td>0.612346</td>\n",
       "      <td>-0.342382</td>\n",
       "      <td>0.142480</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2330</th>\n",
       "      <td>0.809518</td>\n",
       "      <td>0.343655</td>\n",
       "      <td>0.360936</td>\n",
       "      <td>-0.777961</td>\n",
       "      <td>0.008130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6252</th>\n",
       "      <td>-1.249456</td>\n",
       "      <td>-1.335661</td>\n",
       "      <td>2.785976</td>\n",
       "      <td>-2.338711</td>\n",
       "      <td>0.520325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6532</th>\n",
       "      <td>-0.747267</td>\n",
       "      <td>-0.529589</td>\n",
       "      <td>1.030495</td>\n",
       "      <td>-1.068101</td>\n",
       "      <td>0.691057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6002</th>\n",
       "      <td>-1.400113</td>\n",
       "      <td>-1.335661</td>\n",
       "      <td>0.940470</td>\n",
       "      <td>-1.408264</td>\n",
       "      <td>0.813008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>-1.902302</td>\n",
       "      <td>-2.141734</td>\n",
       "      <td>0.659143</td>\n",
       "      <td>-0.898019</td>\n",
       "      <td>0.552846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>-1.098799</td>\n",
       "      <td>-0.663935</td>\n",
       "      <td>-0.460539</td>\n",
       "      <td>0.112466</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1667 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      air_temperature_k  process_temperature_k  rotational_speed_rpm  \\\n",
       "5089           0.206892               0.948209              0.698529   \n",
       "2028           0.307330              -0.059381             -0.499925   \n",
       "2438           1.060613               0.881037             -0.691228   \n",
       "4076           0.457986               0.612346             -0.342382   \n",
       "2330           0.809518               0.343655              0.360936   \n",
       "...                 ...                    ...                   ...   \n",
       "6252          -1.249456              -1.335661              2.785976   \n",
       "6532          -0.747267              -0.529589              1.030495   \n",
       "6002          -1.400113              -1.335661              0.940470   \n",
       "664           -1.902302              -2.141734              0.659143   \n",
       "454           -1.098799              -0.663935             -0.460539   \n",
       "\n",
       "      torque_nm  tool_wear_min    H    L    M  \n",
       "5089  -1.078106       0.524390  0.0  1.0  0.0  \n",
       "2028   0.232524       0.686992  0.0  0.0  1.0  \n",
       "2438   0.402605       0.174797  0.0  1.0  0.0  \n",
       "4076   0.142480       0.406504  0.0  1.0  0.0  \n",
       "2330  -0.777961       0.008130  1.0  0.0  0.0  \n",
       "...         ...            ...  ...  ...  ...  \n",
       "6252  -2.338711       0.520325  0.0  0.0  1.0  \n",
       "6532  -1.068101       0.691057  0.0  0.0  1.0  \n",
       "6002  -1.408264       0.813008  0.0  1.0  0.0  \n",
       "664   -0.898019       0.552846  0.0  1.0  0.0  \n",
       "454    0.112466       0.000000  0.0  1.0  0.0  \n",
       "\n",
       "[1667 rows x 8 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc8a0b5",
   "metadata": {},
   "source": [
    "## Balanceamento das classes da variável target\n",
    "\n",
    "A última etapa do pré-processamento é balancear as instâncias da variável target. Como visto na Análise Exploratória, há muito mais máquinas sem falhas do que com os 5 tipos de falhas apresentados. Se o modelo preditivo for alimentado dessa forma, ele aprenderá muito melhor sobre máquinas sem falhas do que sobre máquinas com falhas, portanto, é preciso aplicar alguma técnica de balanceamento de classes.\n",
    "\n",
    "Pode-se aplicar o _oversampling_, que cria mais registros das classes que minoritárias ou o _undersampling_, que remove registros das classes majoritárias. \n",
    "\n",
    "O dataset possui poucos registros - apenas cerca de 6,5 mil - portanto, se aplicado o _undersampling_, teremos ainda menos dados para o treinamento e perderemos características demais sobre os dados.\n",
    "\n",
    "O _oversampling_ também não funcionaria muito bem para esse modelo, visto que a diferença entre as classes é muito grande e são muitas classes, o que faria com que fossem seriam criados registros artificias demais para resolver a diferença.\n",
    "\n",
    "A abordagem que faremos será a de converter o problema de classificação multiclasse em um problema de classificação binário, respondendo a pergunta: \"Há ou não falha nas máquinas?\". Com essa mudança na pergunta-chave do problema, haverão apenas duas classes a serem balanceadas, e poderemos então aplicar uma técnica de _oversampling_, nesse caso o SMOTE. Após respondido esse primeiro questionamento, abordaremos então, para as máquinas em que o modelo previu falha, qual o tipo de falha presente, se houver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bdc8f368",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.countplot(x=y_treino)\n",
    "plt.title('Tipos de falha por máquina');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9a81c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 3808, 0: 3808, 3: 3808, 4: 3808, 5: 3808}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote_dict = {k: int(np.ceil(0.8*len(y_treino[y_treino == 1]))) for k in y_treino[y_treino != 1].unique()}\n",
    "smote_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc58164",
   "metadata": {},
   "source": [
    "Aplicando SMOTE para que todas as classes tenham 80% dos registros da classe majoritária."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21701183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o objeto balanceador\n",
    "smote = SMOTE(random_state = 1337, sampling_strategy=smote_dict)\n",
    "\n",
    "# Aplica o balanceador\n",
    "X_res, y_res = smote.fit_resample(X_treino, y_treino)\n",
    "\n",
    "y_treino = y_res\n",
    "X_treino = X_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0bf7126",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Definindo o y_treino binário - falha ou não falha\n",
    "y_treino_bin, y_val_bin = y_treino.where(y_treino == 1, 0), y_val.where(y_val == 1, 0)\n",
    "\n",
    "# Plot\n",
    "sns.countplot(x=y_treino_bin)\n",
    "plt.title('Falha (0) ou Não Falha (1)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "542c8d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o objeto balanceador\n",
    "smote = SMOTE(random_state = 1337)\n",
    "\n",
    "# Aplica o balanceador\n",
    "X_res, y_res = smote.fit_resample(X_treino, y_treino_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e47070f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=y_res)\n",
    "plt.title('Falha (0) ou Não Falha (1) - depois do oversampling');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a48498",
   "metadata": {},
   "source": [
    "# Criação do Modelo Preditivo - Classificação Binária\n",
    "\n",
    "Após toda a etapa de Análise Exploratória e Pré-Processamento de Dados, podemos finalmente começar a criar e avaliar os modelos preditivos para esse problema. Como o problema é para prever uma classe, um tipo de falha, então é um problema de classificação. Mais especificamente, classificação multiclasse, visto que a variável target possui mais de 2 classes possíveis. No entanto, como mencionado anteriormente, primeiro transformaremos essa classificação multiclasse em classificação binária, e depois faremos a mudança para classificação multiclasse apenas daquelas máquinas em que uma falha for prevista.\n",
    "\n",
    "Entre os algoritmos mais comuns para esse tipo de problema estão:\n",
    "Regressão Logística, KNN, Naive Bayes, Decision Tree, SVM (Support Vector Machines) e Redes Neurais.\n",
    "\n",
    "Criaremos alguns modelos e utilizaremos algumas métricas de avaliação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1bf1114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a função que treina e avalia o modelo\n",
    "def train_and_score_model(algoritmo, X_treino, y_treino, X_teste, y_teste, nome = None, version = '1'):\n",
    "    # Cria o modelo\n",
    "    modelo = algoritmo\n",
    "    \n",
    "    # Treinamento\n",
    "    start = time.time()\n",
    "    modelo.fit(X_treino, y_treino)\n",
    "    end = time.time()\n",
    "    print('Tempo de Treinamento do Modelo:', end - start)\n",
    "    \n",
    "    # Fazendo as previsões para o dataset de teste\n",
    "    previsoes = modelo.predict(X_teste)\n",
    "    \n",
    "    # Avaliação do modelo\n",
    "    # Matriz de confusão\n",
    "    print('\\nMatriz de confusão\\n', confusion_matrix(y_teste, previsoes))\n",
    "    \n",
    "    # Dicionário de métricas e metadados\n",
    "    dict_model =   {'Modelo': nome,\n",
    "                    'Versão': version,\n",
    "                    'Precision':precision_score(y_teste, previsoes),\n",
    "                    'Recall':recall_score(y_teste, previsoes),\n",
    "                    'F1 Score':f1_score(y_teste, previsoes),\n",
    "                    'Acurácia':accuracy_score(y_teste, previsoes)}\n",
    "        \n",
    "    return modelo, dict_model, previsoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d24a3d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de Treinamento do Modelo: 0.06998848915100098\n",
      "\n",
      "Matriz de confusão\n",
      " [[  37   21]\n",
      " [ 159 1450]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Modelo': 'KNN',\n",
       " 'Versão': 'Binary Classification 1',\n",
       " 'Precision': 0.9857239972807614,\n",
       " 'Recall': 0.9011808576755749,\n",
       " 'F1 Score': 0.9415584415584416,\n",
       " 'Acurácia': 0.8920215956808638}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo 1 - KNN\n",
    "modelo1, dict1, previsoes1 = train_and_score_model(KNeighborsClassifier(), X_treino, y_treino_bin, X_val, y_val_bin, nome = 'KNN', \n",
    "                              version = 'Binary Classification 1')\n",
    "dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b85033a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de Treinamento do Modelo: 0.009006261825561523\n",
      "\n",
      "Matriz de confusão\n",
      " [[ 42  16]\n",
      " [885 724]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Modelo': 'Naive Bayes',\n",
       " 'Versão': 'Binary Classification 1',\n",
       " 'Precision': 0.9783783783783784,\n",
       " 'Recall': 0.4499689247980112,\n",
       " 'F1 Score': 0.6164325244785015,\n",
       " 'Acurácia': 0.4595080983803239}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo 2 - Naive Bayes\n",
    "modelo2, dict2, previsoes2 = train_and_score_model(GaussianNB(), X_treino, y_treino_bin, X_val, y_val_bin, nome = 'Naive Bayes', \n",
    "                              version = 'Binary Classification 1')\n",
    "dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "06659399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de Treinamento do Modelo: 0.19499659538269043\n",
      "\n",
      "Matriz de confusão\n",
      " [[  29   29]\n",
      " [  67 1542]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Modelo': 'Decision Tree Classifier',\n",
       " 'Versão': 'Binary Classification 1',\n",
       " 'Precision': 0.9815404201145767,\n",
       " 'Recall': 0.9583592293349906,\n",
       " 'F1 Score': 0.969811320754717,\n",
       " 'Acurácia': 0.9424115176964607}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo 3 - Decision Tree Classifier\n",
    "modelo3, dict3, previsoes3 = train_and_score_model(DecisionTreeClassifier(), X_treino, y_treino_bin, X_val, y_val_bin, nome = 'Decision Tree Classifier', \n",
    "                              version = 'Binary Classification 1')\n",
    "dict3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "218739c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de Treinamento do Modelo: 4.302996635437012\n",
      "\n",
      "Matriz de confusão\n",
      " [[  32   26]\n",
      " [  53 1556]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Modelo': 'Random Forest Classifier',\n",
       " 'Versão': 'Binary Classification 1',\n",
       " 'Precision': 0.9835651074589128,\n",
       " 'Recall': 0.9670602858918583,\n",
       " 'F1 Score': 0.9752428705734879,\n",
       " 'Acurácia': 0.9526094781043791}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo 4 - Decision Tree Classifier\n",
    "modelo4, dict4, previsoes4 = train_and_score_model(RandomForestClassifier(), X_treino, y_treino_bin, X_val, y_val_bin, nome = 'Random Forest Classifier', \n",
    "                              version = 'Binary Classification 1')\n",
    "dict4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "50ab2b5e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de Treinamento do Modelo: 4.012996196746826\n",
      "\n",
      "Matriz de confusão\n",
      " [[  45   13]\n",
      " [ 310 1299]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Modelo': 'SVM Classifier',\n",
       " 'Versão': 'Binary Classification 1',\n",
       " 'Precision': 0.9900914634146342,\n",
       " 'Recall': 0.8073337476693598,\n",
       " 'F1 Score': 0.8894214310167751,\n",
       " 'Acurácia': 0.8062387522495501}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo 5 - SVM Classifier\n",
    "modelo5, dict5, previsoes5 = train_and_score_model(svm.SVC(), X_treino, y_treino_bin, X_val, y_val_bin, nome = 'SVM Classifier', \n",
    "                                      version = 'Binary Classification 1')\n",
    "dict5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b980db05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de Treinamento do Modelo: 4.12099552154541\n",
      "\n",
      "Matriz de confusão\n",
      " [[  45   13]\n",
      " [ 310 1299]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Modelo': 'XGBoost Classifier',\n",
       " 'Versão': 'Binary Classification 1',\n",
       " 'Precision': 0.9900914634146342,\n",
       " 'Recall': 0.8073337476693598,\n",
       " 'F1 Score': 0.8894214310167751,\n",
       " 'Acurácia': 0.8062387522495501}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo 6 - XGBoost Classifier\n",
    "modelo6, dict6, previsoes = train_and_score_model(svm.SVC(), X_treino, y_treino_bin, X_val, y_val_bin, nome = 'XGBoost Classifier', \n",
    "                              version = 'Binary Classification 1')\n",
    "dict6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "82afacc0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dict1</th>\n",
       "      <th>dict2</th>\n",
       "      <th>dict3</th>\n",
       "      <th>dict4</th>\n",
       "      <th>dict5</th>\n",
       "      <th>dict6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Modelo</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>SVM Classifier</td>\n",
       "      <td>XGBoost Classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Versão</th>\n",
       "      <td>Binary Classification 1</td>\n",
       "      <td>Binary Classification 1</td>\n",
       "      <td>Binary Classification 1</td>\n",
       "      <td>Binary Classification 1</td>\n",
       "      <td>Binary Classification 1</td>\n",
       "      <td>Binary Classification 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.985724</td>\n",
       "      <td>0.978378</td>\n",
       "      <td>0.98154</td>\n",
       "      <td>0.983565</td>\n",
       "      <td>0.990091</td>\n",
       "      <td>0.990091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.901181</td>\n",
       "      <td>0.449969</td>\n",
       "      <td>0.958359</td>\n",
       "      <td>0.96706</td>\n",
       "      <td>0.807334</td>\n",
       "      <td>0.807334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.941558</td>\n",
       "      <td>0.616433</td>\n",
       "      <td>0.969811</td>\n",
       "      <td>0.975243</td>\n",
       "      <td>0.889421</td>\n",
       "      <td>0.889421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acurácia</th>\n",
       "      <td>0.892022</td>\n",
       "      <td>0.459508</td>\n",
       "      <td>0.942412</td>\n",
       "      <td>0.952609</td>\n",
       "      <td>0.806239</td>\n",
       "      <td>0.806239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             dict1                    dict2  \\\n",
       "Modelo                         KNN              Naive Bayes   \n",
       "Versão     Binary Classification 1  Binary Classification 1   \n",
       "Precision                 0.985724                 0.978378   \n",
       "Recall                    0.901181                 0.449969   \n",
       "F1 Score                  0.941558                 0.616433   \n",
       "Acurácia                  0.892022                 0.459508   \n",
       "\n",
       "                              dict3                     dict4  \\\n",
       "Modelo     Decision Tree Classifier  Random Forest Classifier   \n",
       "Versão      Binary Classification 1   Binary Classification 1   \n",
       "Precision                   0.98154                  0.983565   \n",
       "Recall                     0.958359                   0.96706   \n",
       "F1 Score                   0.969811                  0.975243   \n",
       "Acurácia                   0.942412                  0.952609   \n",
       "\n",
       "                             dict5                    dict6  \n",
       "Modelo              SVM Classifier       XGBoost Classifier  \n",
       "Versão     Binary Classification 1  Binary Classification 1  \n",
       "Precision                 0.990091                 0.990091  \n",
       "Recall                    0.807334                 0.807334  \n",
       "F1 Score                  0.889421                 0.889421  \n",
       "Acurácia                  0.806239                 0.806239  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatena todos os dicionários em um dataframe do Pandas\n",
    "resumo_bin1 = pd.DataFrame({'dict1':pd.Series(dict1),\n",
    "                           'dict2':pd.Series(dict2),\n",
    "                           'dict3':pd.Series(dict3),\n",
    "                           'dict4':pd.Series(dict4),\n",
    "                           'dict5':pd.Series(dict5),\n",
    "                           'dict6':pd.Series(dict6)})\n",
    "\n",
    "resumo_bin1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4058c484",
   "metadata": {},
   "source": [
    "## Repetindo os modelos com o balanceamento de classes (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5408f73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de Treinamento do Modelo: 0.1489861011505127\n",
      "\n",
      "Matriz de confusão\n",
      " [[  29   29]\n",
      " [  84 1525]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Modelo': 'KNN',\n",
       " 'Versão': 'Binary Classification 2',\n",
       " 'Precision': 0.9813384813384813,\n",
       " 'Recall': 0.9477936606587943,\n",
       " 'F1 Score': 0.9642744230161239,\n",
       " 'Acurácia': 0.9322135572885423}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo 1 - KNN - com SMOTE\n",
    "modelo1, dict1, previsoes1 = train_and_score_model(KNeighborsClassifier(), X_res, y_res, X_val, y_val_bin, nome = 'KNN', \n",
    "                                          version = 'Binary Classification 2')\n",
    "dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aa628f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de Treinamento do Modelo: 0.010003328323364258\n",
      "\n",
      "Matriz de confusão\n",
      " [[  41   17]\n",
      " [ 527 1082]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Modelo': 'Naive Bayes',\n",
       " 'Versão': 'Binary Classification 2',\n",
       " 'Precision': 0.9845313921747043,\n",
       " 'Recall': 0.6724673710379118,\n",
       " 'F1 Score': 0.7991137370753325,\n",
       " 'Acurácia': 0.6736652669466107}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo 2 - Naive Bayes - com SMOTE\n",
    "modelo2, dict2, previsoes2 = train_and_score_model(GaussianNB(), X_res, y_res, X_val, y_val_bin, nome = 'Naive Bayes', \n",
    "                                          version = 'Binary Classification 2')\n",
    "dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "763bd13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de Treinamento do Modelo: 0.21900081634521484\n",
      "\n",
      "Matriz de confusão\n",
      " [[  26   32]\n",
      " [  52 1557]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Modelo': 'Decision Tree Classifier',\n",
       " 'Versão': 'Binary Classification 2',\n",
       " 'Precision': 0.9798615481434865,\n",
       " 'Recall': 0.9676817899316346,\n",
       " 'F1 Score': 0.9737335834896811,\n",
       " 'Acurácia': 0.9496100779844031}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo 3 - Decision Tree - com SMOTE\n",
    "modelo3, dict3, previsoes3 = train_and_score_model(DecisionTreeClassifier(), X_res, y_res, X_val, y_val_bin, nome = 'Decision Tree Classifier', \n",
    "                                          version = 'Binary Classification 2')\n",
    "dict3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8e83ca28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de Treinamento do Modelo: 5.639994144439697\n",
      "\n",
      "Matriz de confusão\n",
      " [[  29   29]\n",
      " [  31 1578]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Modelo': 'Random Forest Classifier',\n",
       " 'Versão': 'Binary Classification 2',\n",
       " 'Precision': 0.9819539514623522,\n",
       " 'Recall': 0.980733374766936,\n",
       " 'F1 Score': 0.9813432835820896,\n",
       " 'Acurácia': 0.9640071985602879}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo 4 - Random Forest - com SMOTE\n",
    "modelo4, dict4, previsoes4 = train_and_score_model(RandomForestClassifier(), X_res, y_res, X_val, y_val_bin, nome = 'Random Forest Classifier', \n",
    "                                          version = 'Binary Classification 2')\n",
    "dict4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1ad66d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de Treinamento do Modelo: 5.66099214553833\n",
      "\n",
      "Matriz de confusão\n",
      " [[  29   29]\n",
      " [  28 1581]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Modelo': 'SVM Classifier',\n",
       " 'Versão': 'Binary Classification 2',\n",
       " 'Precision': 0.9819875776397515,\n",
       " 'Recall': 0.9825978868862648,\n",
       " 'F1 Score': 0.9822926374650512,\n",
       " 'Acurácia': 0.9658068386322736}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo 5 - SVM Classifier - com SMOTE\n",
    "modelo5, dict5, previsoes5 = train_and_score_model(RandomForestClassifier(), X_res, y_res, X_val, y_val_bin, nome = 'SVM Classifier', \n",
    "                                          version = 'Binary Classification 2')\n",
    "dict5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "63bec297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de Treinamento do Modelo: 1.3009989261627197\n",
      "\n",
      "Matriz de confusão\n",
      " [[  33   25]\n",
      " [  36 1573]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Modelo': 'XGBoost Classifier',\n",
       " 'Versão': 'Binary Classification 2',\n",
       " 'Precision': 0.9843554443053817,\n",
       " 'Recall': 0.9776258545680547,\n",
       " 'F1 Score': 0.9809791082008108,\n",
       " 'Acurácia': 0.9634073185362927}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo 6 - XGBoost Classifier - com SMOTE\n",
    "modelo6, dict6, previsoes6 = train_and_score_model(XGBClassifier(), X_res, y_res, X_val, y_val_bin, nome = 'XGBoost Classifier', \n",
    "                                          version = 'Binary Classification 2')\n",
    "dict6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "81e15857",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dict1</th>\n",
       "      <th>dict2</th>\n",
       "      <th>dict3</th>\n",
       "      <th>dict4</th>\n",
       "      <th>dict5</th>\n",
       "      <th>dict6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Modelo</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>SVM Classifier</td>\n",
       "      <td>XGBoost Classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Versão</th>\n",
       "      <td>Binary Classification 2</td>\n",
       "      <td>Binary Classification 2</td>\n",
       "      <td>Binary Classification 2</td>\n",
       "      <td>Binary Classification 2</td>\n",
       "      <td>Binary Classification 2</td>\n",
       "      <td>Binary Classification 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.981338</td>\n",
       "      <td>0.984531</td>\n",
       "      <td>0.979862</td>\n",
       "      <td>0.981954</td>\n",
       "      <td>0.981988</td>\n",
       "      <td>0.984355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.947794</td>\n",
       "      <td>0.672467</td>\n",
       "      <td>0.967682</td>\n",
       "      <td>0.980733</td>\n",
       "      <td>0.982598</td>\n",
       "      <td>0.977626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.964274</td>\n",
       "      <td>0.799114</td>\n",
       "      <td>0.973734</td>\n",
       "      <td>0.981343</td>\n",
       "      <td>0.982293</td>\n",
       "      <td>0.980979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acurácia</th>\n",
       "      <td>0.932214</td>\n",
       "      <td>0.673665</td>\n",
       "      <td>0.94961</td>\n",
       "      <td>0.964007</td>\n",
       "      <td>0.965807</td>\n",
       "      <td>0.963407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             dict1                    dict2  \\\n",
       "Modelo                         KNN              Naive Bayes   \n",
       "Versão     Binary Classification 2  Binary Classification 2   \n",
       "Precision                 0.981338                 0.984531   \n",
       "Recall                    0.947794                 0.672467   \n",
       "F1 Score                  0.964274                 0.799114   \n",
       "Acurácia                  0.932214                 0.673665   \n",
       "\n",
       "                              dict3                     dict4  \\\n",
       "Modelo     Decision Tree Classifier  Random Forest Classifier   \n",
       "Versão      Binary Classification 2   Binary Classification 2   \n",
       "Precision                  0.979862                  0.981954   \n",
       "Recall                     0.967682                  0.980733   \n",
       "F1 Score                   0.973734                  0.981343   \n",
       "Acurácia                    0.94961                  0.964007   \n",
       "\n",
       "                             dict5                    dict6  \n",
       "Modelo              SVM Classifier       XGBoost Classifier  \n",
       "Versão     Binary Classification 2  Binary Classification 2  \n",
       "Precision                 0.981988                 0.984355  \n",
       "Recall                    0.982598                 0.977626  \n",
       "F1 Score                  0.982293                 0.980979  \n",
       "Acurácia                  0.965807                 0.963407  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatena todos os dicionários em um dataframe do Pandas\n",
    "resumo_bin2 = pd.DataFrame({'dict1':pd.Series(dict1),\n",
    "                           'dict2':pd.Series(dict2),\n",
    "                           'dict3':pd.Series(dict3),\n",
    "                           'dict4':pd.Series(dict4),\n",
    "                           'dict5':pd.Series(dict5),\n",
    "                           'dict6':pd.Series(dict6)})\n",
    "\n",
    "resumo_bin2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f1af1eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dict1</th>\n",
       "      <th>dict2</th>\n",
       "      <th>dict3</th>\n",
       "      <th>dict4</th>\n",
       "      <th>dict5</th>\n",
       "      <th>dict6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Modelo</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>SVM Classifier</td>\n",
       "      <td>XGBoost Classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Versão</th>\n",
       "      <td>Binary Classification 1</td>\n",
       "      <td>Binary Classification 1</td>\n",
       "      <td>Binary Classification 1</td>\n",
       "      <td>Binary Classification 1</td>\n",
       "      <td>Binary Classification 1</td>\n",
       "      <td>Binary Classification 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.985724</td>\n",
       "      <td>0.978378</td>\n",
       "      <td>0.98154</td>\n",
       "      <td>0.983565</td>\n",
       "      <td>0.990091</td>\n",
       "      <td>0.990091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.901181</td>\n",
       "      <td>0.449969</td>\n",
       "      <td>0.958359</td>\n",
       "      <td>0.96706</td>\n",
       "      <td>0.807334</td>\n",
       "      <td>0.807334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.941558</td>\n",
       "      <td>0.616433</td>\n",
       "      <td>0.969811</td>\n",
       "      <td>0.975243</td>\n",
       "      <td>0.889421</td>\n",
       "      <td>0.889421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acurácia</th>\n",
       "      <td>0.892022</td>\n",
       "      <td>0.459508</td>\n",
       "      <td>0.942412</td>\n",
       "      <td>0.952609</td>\n",
       "      <td>0.806239</td>\n",
       "      <td>0.806239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             dict1                    dict2  \\\n",
       "Modelo                         KNN              Naive Bayes   \n",
       "Versão     Binary Classification 1  Binary Classification 1   \n",
       "Precision                 0.985724                 0.978378   \n",
       "Recall                    0.901181                 0.449969   \n",
       "F1 Score                  0.941558                 0.616433   \n",
       "Acurácia                  0.892022                 0.459508   \n",
       "\n",
       "                              dict3                     dict4  \\\n",
       "Modelo     Decision Tree Classifier  Random Forest Classifier   \n",
       "Versão      Binary Classification 1   Binary Classification 1   \n",
       "Precision                   0.98154                  0.983565   \n",
       "Recall                     0.958359                   0.96706   \n",
       "F1 Score                   0.969811                  0.975243   \n",
       "Acurácia                   0.942412                  0.952609   \n",
       "\n",
       "                             dict5                    dict6  \n",
       "Modelo              SVM Classifier       XGBoost Classifier  \n",
       "Versão     Binary Classification 1  Binary Classification 1  \n",
       "Precision                 0.990091                 0.990091  \n",
       "Recall                    0.807334                 0.807334  \n",
       "F1 Score                  0.889421                 0.889421  \n",
       "Acurácia                  0.806239                 0.806239  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumo_bin1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041ea186",
   "metadata": {},
   "source": [
    "## Avaliando as métricas\n",
    "\n",
    "Para avaliar as métricas é necessário definir: qual a classe positiva e qual a classe negativa do problema?\n",
    "\n",
    "Classe positiva: Máquinas sem falha (1)\n",
    "Classe negativa: Máquinas com falha (0)\n",
    "\n",
    "**Precision**: Essa métrica responde à pergunta: que proporção das previsões positivas são realmente positivas? Para esse problema, significa quantas máquinas que foram previstas como sem falhas realmente não possuem falhas. É necessário otimizar essa métrica se o problema requerer um baixo número de **falsos positivos**. Estes significariam máquinas que têm falhas mas foram previstas como se não tivessem. Como nosso problema é de manutenção preditiva, esse tipo de falha é muito mais grave do que prever falhas nas máquinas que não a possuem, ou falsos negativos.\n",
    "\n",
    "**Recall**: Responde à pergunta: que proporção dos verdadeiros positivos estão corretamente classificados? Para esse problema, significa as máquinas que não possuem falhas e foram classificadas corretamente. É necessário otimizar essa métrica se o problema requerer um baixo número de **falsos negativos**. Estes significariam máquinas que não possuem falhas mas foram previstas como se tivessem. Como nosso problema é de manutenção preditiva, esse tipo de falha é menos grave do que prever falsos positivos.\n",
    "\n",
    "**F1 Score**: É a média harmônica entre precision e recall. Fortemente afetado caso uma das duas métricas seja muito baixa. É necessário otimizar essa métrica quando o problema requerer um bom equilíbrio de falsos positivos e negativos.\n",
    "\n",
    "**Acurácia**: É simplesmente o percentual de acerto do modelo. \n",
    "\n",
    "Considerando nosso problema, Precision será nossa métrica base para a classificação binária. \n",
    "Posteriormente, na avaliação da classificação das falhas, utilizaremos a métrica de ROC AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813d7b04",
   "metadata": {},
   "source": [
    "# Criação do Modelo Preditivo - Classificação Multiclasse\n",
    "\n",
    "O melhor modelo encontrado para a classificação binária foi o Decision Tree com aplicação de SMOTE, com Precision de 0.987967. Seguido pelo modelo XGBoost Classifier, também com aplicação de SMOTE e Precision de 0.986259.\n",
    "\n",
    "Agora, criaremos outro modelo usando dados de treinamento apenas nos casos em que há falha, para prever qual o tipo de falha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f3b4213f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrando os dados em que há falha - Treino\n",
    "y_falha_treino = y_treino[y_treino != 1]\n",
    "X_falha_treino = X_treino.loc[y_falha_treino.index]\n",
    "\n",
    "# Filtrando os dados em que há falha - Validação\n",
    "y_falha_val = y_val[y_val != 1]\n",
    "X_falha_val = X_val.loc[y_falha_val.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4129a74a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_temperature_k</th>\n",
       "      <th>process_temperature_k</th>\n",
       "      <th>rotational_speed_rpm</th>\n",
       "      <th>torque_nm</th>\n",
       "      <th>tool_wear_min</th>\n",
       "      <th>H</th>\n",
       "      <th>L</th>\n",
       "      <th>M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.864115</td>\n",
       "      <td>1.821454</td>\n",
       "      <td>-1.006314</td>\n",
       "      <td>1.673215</td>\n",
       "      <td>0.788618</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>-0.646829</td>\n",
       "      <td>-0.126553</td>\n",
       "      <td>-1.034447</td>\n",
       "      <td>1.323047</td>\n",
       "      <td>0.861789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1.512583</td>\n",
       "      <td>0.881037</td>\n",
       "      <td>-0.972555</td>\n",
       "      <td>1.613186</td>\n",
       "      <td>0.593496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1.311707</td>\n",
       "      <td>0.276483</td>\n",
       "      <td>-1.006314</td>\n",
       "      <td>1.713234</td>\n",
       "      <td>0.272358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>1.211270</td>\n",
       "      <td>0.679519</td>\n",
       "      <td>-1.124471</td>\n",
       "      <td>2.753734</td>\n",
       "      <td>0.788618</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23794</th>\n",
       "      <td>-0.314943</td>\n",
       "      <td>-0.556360</td>\n",
       "      <td>1.854960</td>\n",
       "      <td>-1.639149</td>\n",
       "      <td>0.901134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132845</td>\n",
       "      <td>0.867155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23795</th>\n",
       "      <td>0.653578</td>\n",
       "      <td>0.060826</td>\n",
       "      <td>1.984929</td>\n",
       "      <td>-1.637845</td>\n",
       "      <td>0.847668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23796</th>\n",
       "      <td>0.924893</td>\n",
       "      <td>0.549169</td>\n",
       "      <td>0.733998</td>\n",
       "      <td>-0.732812</td>\n",
       "      <td>0.897649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.313504</td>\n",
       "      <td>0.686496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23797</th>\n",
       "      <td>0.991891</td>\n",
       "      <td>0.612346</td>\n",
       "      <td>0.291043</td>\n",
       "      <td>-0.243489</td>\n",
       "      <td>0.872486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.842112</td>\n",
       "      <td>0.157888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23798</th>\n",
       "      <td>-0.560344</td>\n",
       "      <td>-0.709547</td>\n",
       "      <td>-0.491449</td>\n",
       "      <td>0.127288</td>\n",
       "      <td>0.849769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.919759</td>\n",
       "      <td>0.080241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19040 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       air_temperature_k  process_temperature_k  rotational_speed_rpm  \\\n",
       "7               1.864115               1.821454             -1.006314   \n",
       "39             -0.646829              -0.126553             -1.034447   \n",
       "76              1.512583               0.881037             -0.972555   \n",
       "99              1.311707               0.276483             -1.006314   \n",
       "109             1.211270               0.679519             -1.124471   \n",
       "...                  ...                    ...                   ...   \n",
       "23794          -0.314943              -0.556360              1.854960   \n",
       "23795           0.653578               0.060826              1.984929   \n",
       "23796           0.924893               0.549169              0.733998   \n",
       "23797           0.991891               0.612346              0.291043   \n",
       "23798          -0.560344              -0.709547             -0.491449   \n",
       "\n",
       "       torque_nm  tool_wear_min    H         L         M  \n",
       "7       1.673215       0.788618  0.0  1.000000  0.000000  \n",
       "39      1.323047       0.861789  0.0  1.000000  0.000000  \n",
       "76      1.613186       0.593496  0.0  1.000000  0.000000  \n",
       "99      1.713234       0.272358  0.0  1.000000  0.000000  \n",
       "109     2.753734       0.788618  0.0  1.000000  0.000000  \n",
       "...          ...            ...  ...       ...       ...  \n",
       "23794  -1.639149       0.901134  0.0  0.132845  0.867155  \n",
       "23795  -1.637845       0.847668  0.0  0.000000  1.000000  \n",
       "23796  -0.732812       0.897649  0.0  0.313504  0.686496  \n",
       "23797  -0.243489       0.872486  0.0  0.842112  0.157888  \n",
       "23798   0.127288       0.849769  0.0  0.919759  0.080241  \n",
       "\n",
       "[19040 rows x 8 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_falha_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2134f5c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7        2\n",
       "39       2\n",
       "76       0\n",
       "99       0\n",
       "109      3\n",
       "        ..\n",
       "23794    5\n",
       "23795    5\n",
       "23796    5\n",
       "23797    5\n",
       "23798    5\n",
       "Length: 19040, dtype: int32"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_falha_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "75ade596",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_temperature_k</th>\n",
       "      <th>process_temperature_k</th>\n",
       "      <th>rotational_speed_rpm</th>\n",
       "      <th>torque_nm</th>\n",
       "      <th>tool_wear_min</th>\n",
       "      <th>H</th>\n",
       "      <th>L</th>\n",
       "      <th>M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2330</th>\n",
       "      <td>0.809518</td>\n",
       "      <td>0.343655</td>\n",
       "      <td>0.360936</td>\n",
       "      <td>-0.777961</td>\n",
       "      <td>0.008130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3156</th>\n",
       "      <td>1.663240</td>\n",
       "      <td>1.082555</td>\n",
       "      <td>-1.130098</td>\n",
       "      <td>1.673215</td>\n",
       "      <td>0.760163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4667</th>\n",
       "      <td>0.257111</td>\n",
       "      <td>0.343655</td>\n",
       "      <td>6.161902</td>\n",
       "      <td>-2.788927</td>\n",
       "      <td>0.069106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4938</th>\n",
       "      <td>0.006016</td>\n",
       "      <td>0.948209</td>\n",
       "      <td>0.867325</td>\n",
       "      <td>-1.108120</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6274</th>\n",
       "      <td>-0.948143</td>\n",
       "      <td>-0.932625</td>\n",
       "      <td>-1.034447</td>\n",
       "      <td>1.383076</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3038</th>\n",
       "      <td>1.261488</td>\n",
       "      <td>0.276483</td>\n",
       "      <td>-1.062579</td>\n",
       "      <td>1.503134</td>\n",
       "      <td>0.760163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>1.010394</td>\n",
       "      <td>0.813864</td>\n",
       "      <td>-1.507076</td>\n",
       "      <td>2.523623</td>\n",
       "      <td>0.739837</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5720</th>\n",
       "      <td>-1.249456</td>\n",
       "      <td>-1.268489</td>\n",
       "      <td>-1.146978</td>\n",
       "      <td>3.193945</td>\n",
       "      <td>0.613821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2982</th>\n",
       "      <td>1.211270</td>\n",
       "      <td>0.209310</td>\n",
       "      <td>-0.899410</td>\n",
       "      <td>1.423095</td>\n",
       "      <td>0.670732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2961</th>\n",
       "      <td>1.311707</td>\n",
       "      <td>0.142137</td>\n",
       "      <td>6.403843</td>\n",
       "      <td>-2.928994</td>\n",
       "      <td>0.341463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>-1.801864</td>\n",
       "      <td>-1.738698</td>\n",
       "      <td>7.287211</td>\n",
       "      <td>-3.449244</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>-0.395735</td>\n",
       "      <td>-0.596762</td>\n",
       "      <td>-1.085086</td>\n",
       "      <td>2.063402</td>\n",
       "      <td>0.776423</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6433</th>\n",
       "      <td>-0.445954</td>\n",
       "      <td>0.007792</td>\n",
       "      <td>-0.961302</td>\n",
       "      <td>1.623191</td>\n",
       "      <td>0.825203</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3188</th>\n",
       "      <td>1.864115</td>\n",
       "      <td>1.284073</td>\n",
       "      <td>-1.158231</td>\n",
       "      <td>1.263018</td>\n",
       "      <td>0.268293</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6005</th>\n",
       "      <td>-1.349894</td>\n",
       "      <td>-1.268489</td>\n",
       "      <td>0.434081</td>\n",
       "      <td>-0.467813</td>\n",
       "      <td>0.882114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1424</th>\n",
       "      <td>-0.345516</td>\n",
       "      <td>-0.731107</td>\n",
       "      <td>-1.574595</td>\n",
       "      <td>2.933820</td>\n",
       "      <td>0.483740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2425</th>\n",
       "      <td>0.859737</td>\n",
       "      <td>0.612346</td>\n",
       "      <td>-0.747493</td>\n",
       "      <td>0.632716</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3164</th>\n",
       "      <td>1.713458</td>\n",
       "      <td>1.216900</td>\n",
       "      <td>-1.304521</td>\n",
       "      <td>2.093417</td>\n",
       "      <td>0.873984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td>-0.395735</td>\n",
       "      <td>-0.932625</td>\n",
       "      <td>-1.523956</td>\n",
       "      <td>2.813763</td>\n",
       "      <td>0.308943</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2771</th>\n",
       "      <td>0.960175</td>\n",
       "      <td>0.276483</td>\n",
       "      <td>-1.417052</td>\n",
       "      <td>2.273503</td>\n",
       "      <td>0.089431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2568</th>\n",
       "      <td>1.161051</td>\n",
       "      <td>0.612346</td>\n",
       "      <td>-0.966928</td>\n",
       "      <td>0.832812</td>\n",
       "      <td>0.528455</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3611</th>\n",
       "      <td>1.361926</td>\n",
       "      <td>1.619936</td>\n",
       "      <td>-0.342382</td>\n",
       "      <td>0.622711</td>\n",
       "      <td>1.020325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3048</th>\n",
       "      <td>1.361926</td>\n",
       "      <td>0.545173</td>\n",
       "      <td>-1.478944</td>\n",
       "      <td>1.493129</td>\n",
       "      <td>0.101626</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5338</th>\n",
       "      <td>0.357548</td>\n",
       "      <td>1.284073</td>\n",
       "      <td>-0.781252</td>\n",
       "      <td>1.012898</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2763</th>\n",
       "      <td>1.060613</td>\n",
       "      <td>0.478001</td>\n",
       "      <td>-0.978181</td>\n",
       "      <td>0.772783</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5166</th>\n",
       "      <td>0.206892</td>\n",
       "      <td>1.216900</td>\n",
       "      <td>-1.495823</td>\n",
       "      <td>1.913330</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4842</th>\n",
       "      <td>-0.044203</td>\n",
       "      <td>0.142137</td>\n",
       "      <td>-1.405799</td>\n",
       "      <td>2.953830</td>\n",
       "      <td>0.252033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3238</th>\n",
       "      <td>1.713458</td>\n",
       "      <td>1.284073</td>\n",
       "      <td>-1.349533</td>\n",
       "      <td>2.383556</td>\n",
       "      <td>0.239837</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3162</th>\n",
       "      <td>1.713458</td>\n",
       "      <td>1.216900</td>\n",
       "      <td>-1.107592</td>\n",
       "      <td>0.692745</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>-0.445954</td>\n",
       "      <td>-0.798280</td>\n",
       "      <td>-1.175110</td>\n",
       "      <td>1.353062</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5238</th>\n",
       "      <td>0.206892</td>\n",
       "      <td>1.284073</td>\n",
       "      <td>-0.561817</td>\n",
       "      <td>0.662730</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>-0.998362</td>\n",
       "      <td>-1.201316</td>\n",
       "      <td>-0.972555</td>\n",
       "      <td>1.283028</td>\n",
       "      <td>0.886179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>-1.299675</td>\n",
       "      <td>-0.865453</td>\n",
       "      <td>7.517899</td>\n",
       "      <td>-3.589311</td>\n",
       "      <td>0.479675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2738</th>\n",
       "      <td>1.010394</td>\n",
       "      <td>0.276483</td>\n",
       "      <td>-1.017567</td>\n",
       "      <td>1.793273</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2901</th>\n",
       "      <td>0.809518</td>\n",
       "      <td>0.074965</td>\n",
       "      <td>-1.191990</td>\n",
       "      <td>0.812802</td>\n",
       "      <td>0.313008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>-1.500550</td>\n",
       "      <td>-1.470007</td>\n",
       "      <td>-0.860024</td>\n",
       "      <td>1.633196</td>\n",
       "      <td>0.821138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2796</th>\n",
       "      <td>1.110832</td>\n",
       "      <td>0.410828</td>\n",
       "      <td>-1.028820</td>\n",
       "      <td>1.142961</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>-1.500550</td>\n",
       "      <td>-1.134143</td>\n",
       "      <td>-0.781252</td>\n",
       "      <td>0.632716</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3235</th>\n",
       "      <td>1.713458</td>\n",
       "      <td>1.284073</td>\n",
       "      <td>-0.905036</td>\n",
       "      <td>0.152485</td>\n",
       "      <td>0.138211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4221</th>\n",
       "      <td>0.257111</td>\n",
       "      <td>-0.059381</td>\n",
       "      <td>-0.792505</td>\n",
       "      <td>0.582692</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3226</th>\n",
       "      <td>1.713458</td>\n",
       "      <td>1.351246</td>\n",
       "      <td>-0.094814</td>\n",
       "      <td>-0.417789</td>\n",
       "      <td>0.873984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2787</th>\n",
       "      <td>1.010394</td>\n",
       "      <td>0.343655</td>\n",
       "      <td>-1.546462</td>\n",
       "      <td>2.053398</td>\n",
       "      <td>0.365854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>-2.153396</td>\n",
       "      <td>-2.544770</td>\n",
       "      <td>4.119467</td>\n",
       "      <td>-2.548811</td>\n",
       "      <td>0.605691</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749</th>\n",
       "      <td>1.512583</td>\n",
       "      <td>1.485591</td>\n",
       "      <td>-1.580221</td>\n",
       "      <td>3.123912</td>\n",
       "      <td>0.495935</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534</th>\n",
       "      <td>-0.295297</td>\n",
       "      <td>-0.865453</td>\n",
       "      <td>-0.516805</td>\n",
       "      <td>2.283508</td>\n",
       "      <td>0.544715</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3055</th>\n",
       "      <td>1.512583</td>\n",
       "      <td>0.813864</td>\n",
       "      <td>-0.921916</td>\n",
       "      <td>0.812802</td>\n",
       "      <td>0.264228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3610</th>\n",
       "      <td>1.412145</td>\n",
       "      <td>1.619936</td>\n",
       "      <td>-0.713734</td>\n",
       "      <td>1.373071</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>1.361926</td>\n",
       "      <td>0.343655</td>\n",
       "      <td>-0.516805</td>\n",
       "      <td>0.082452</td>\n",
       "      <td>0.857724</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4160</th>\n",
       "      <td>0.407767</td>\n",
       "      <td>0.074965</td>\n",
       "      <td>-0.747493</td>\n",
       "      <td>2.113426</td>\n",
       "      <td>0.768293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4113</th>\n",
       "      <td>0.558424</td>\n",
       "      <td>0.612346</td>\n",
       "      <td>-1.439558</td>\n",
       "      <td>2.783748</td>\n",
       "      <td>0.040650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>-0.897924</td>\n",
       "      <td>-1.066971</td>\n",
       "      <td>-1.282015</td>\n",
       "      <td>2.093417</td>\n",
       "      <td>0.768293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>-1.651207</td>\n",
       "      <td>-1.470007</td>\n",
       "      <td>-1.574595</td>\n",
       "      <td>2.893801</td>\n",
       "      <td>0.426829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3173</th>\n",
       "      <td>1.613021</td>\n",
       "      <td>0.948209</td>\n",
       "      <td>-1.051326</td>\n",
       "      <td>1.373071</td>\n",
       "      <td>0.032520</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2702</th>\n",
       "      <td>1.010394</td>\n",
       "      <td>0.545173</td>\n",
       "      <td>0.434081</td>\n",
       "      <td>-1.108120</td>\n",
       "      <td>0.955285</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2847</th>\n",
       "      <td>1.261488</td>\n",
       "      <td>0.612346</td>\n",
       "      <td>-1.023194</td>\n",
       "      <td>1.543153</td>\n",
       "      <td>0.410569</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3189</th>\n",
       "      <td>1.864115</td>\n",
       "      <td>1.351246</td>\n",
       "      <td>6.330698</td>\n",
       "      <td>-2.868965</td>\n",
       "      <td>0.288618</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2850</th>\n",
       "      <td>1.311707</td>\n",
       "      <td>0.679519</td>\n",
       "      <td>-1.428305</td>\n",
       "      <td>2.793753</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4771</th>\n",
       "      <td>0.156673</td>\n",
       "      <td>0.209310</td>\n",
       "      <td>-0.989434</td>\n",
       "      <td>2.023383</td>\n",
       "      <td>0.837398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      air_temperature_k  process_temperature_k  rotational_speed_rpm  \\\n",
       "2330           0.809518               0.343655              0.360936   \n",
       "3156           1.663240               1.082555             -1.130098   \n",
       "4667           0.257111               0.343655              6.161902   \n",
       "4938           0.006016               0.948209              0.867325   \n",
       "6274          -0.948143              -0.932625             -1.034447   \n",
       "3038           1.261488               0.276483             -1.062579   \n",
       "2473           1.010394               0.813864             -1.507076   \n",
       "5720          -1.249456              -1.268489             -1.146978   \n",
       "2982           1.211270               0.209310             -0.899410   \n",
       "2961           1.311707               0.142137              6.403843   \n",
       "570           -1.801864              -1.738698              7.287211   \n",
       "1726          -0.395735              -0.596762             -1.085086   \n",
       "6433          -0.445954               0.007792             -0.961302   \n",
       "3188           1.864115               1.284073             -1.158231   \n",
       "6005          -1.349894              -1.268489              0.434081   \n",
       "1424          -0.345516              -0.731107             -1.574595   \n",
       "2425           0.859737               0.612346             -0.747493   \n",
       "3164           1.713458               1.216900             -1.304521   \n",
       "1633          -0.395735              -0.932625             -1.523956   \n",
       "2771           0.960175               0.276483             -1.417052   \n",
       "2568           1.161051               0.612346             -0.966928   \n",
       "3611           1.361926               1.619936             -0.342382   \n",
       "3048           1.361926               0.545173             -1.478944   \n",
       "5338           0.357548               1.284073             -0.781252   \n",
       "2763           1.060613               0.478001             -0.978181   \n",
       "5166           0.206892               1.216900             -1.495823   \n",
       "4842          -0.044203               0.142137             -1.405799   \n",
       "3238           1.713458               1.284073             -1.349533   \n",
       "3162           1.713458               1.216900             -1.107592   \n",
       "1665          -0.445954              -0.798280             -1.175110   \n",
       "5238           0.206892               1.284073             -0.561817   \n",
       "1061          -0.998362              -1.201316             -0.972555   \n",
       "320           -1.299675              -0.865453              7.517899   \n",
       "2738           1.010394               0.276483             -1.017567   \n",
       "2901           0.809518               0.074965             -1.191990   \n",
       "730           -1.500550              -1.470007             -0.860024   \n",
       "2796           1.110832               0.410828             -1.028820   \n",
       "817           -1.500550              -1.134143             -0.781252   \n",
       "3235           1.713458               1.284073             -0.905036   \n",
       "4221           0.257111              -0.059381             -0.792505   \n",
       "3226           1.713458               1.351246             -0.094814   \n",
       "2787           1.010394               0.343655             -1.546462   \n",
       "609           -2.153396              -2.544770              4.119467   \n",
       "3749           1.512583               1.485591             -1.580221   \n",
       "1534          -0.295297              -0.865453             -0.516805   \n",
       "3055           1.512583               0.813864             -0.921916   \n",
       "3610           1.412145               1.619936             -0.713734   \n",
       "2994           1.361926               0.343655             -0.516805   \n",
       "4160           0.407767               0.074965             -0.747493   \n",
       "4113           0.558424               0.612346             -1.439558   \n",
       "1053          -0.897924              -1.066971             -1.282015   \n",
       "752           -1.651207              -1.470007             -1.574595   \n",
       "3173           1.613021               0.948209             -1.051326   \n",
       "2702           1.010394               0.545173              0.434081   \n",
       "2847           1.261488               0.612346             -1.023194   \n",
       "3189           1.864115               1.351246              6.330698   \n",
       "2850           1.311707               0.679519             -1.428305   \n",
       "4771           0.156673               0.209310             -0.989434   \n",
       "\n",
       "      torque_nm  tool_wear_min    H    L    M  \n",
       "2330  -0.777961       0.008130  1.0  0.0  0.0  \n",
       "3156   1.673215       0.760163  0.0  1.0  0.0  \n",
       "4667  -2.788927       0.069106  0.0  1.0  0.0  \n",
       "4938  -1.108120       0.878049  0.0  0.0  1.0  \n",
       "6274   1.383076       0.841463  0.0  1.0  0.0  \n",
       "3038   1.503134       0.760163  0.0  1.0  0.0  \n",
       "2473   2.523623       0.739837  0.0  1.0  0.0  \n",
       "5720   3.193945       0.613821  0.0  0.0  1.0  \n",
       "2982   1.423095       0.670732  0.0  0.0  1.0  \n",
       "2961  -2.928994       0.341463  0.0  0.0  1.0  \n",
       "570   -3.449244       0.865854  0.0  1.0  0.0  \n",
       "1726   2.063402       0.776423  0.0  1.0  0.0  \n",
       "6433   1.623191       0.825203  0.0  1.0  0.0  \n",
       "3188   1.263018       0.268293  1.0  0.0  0.0  \n",
       "6005  -0.467813       0.882114  0.0  1.0  0.0  \n",
       "1424   2.933820       0.483740  0.0  1.0  0.0  \n",
       "2425   0.632716       0.841463  0.0  1.0  0.0  \n",
       "3164   2.093417       0.873984  0.0  1.0  0.0  \n",
       "1633   2.813763       0.308943  0.0  1.0  0.0  \n",
       "2771   2.273503       0.089431  0.0  1.0  0.0  \n",
       "2568   0.832812       0.528455  1.0  0.0  0.0  \n",
       "3611   0.622711       1.020325  0.0  1.0  0.0  \n",
       "3048   1.493129       0.101626  1.0  0.0  0.0  \n",
       "5338   1.012898       0.902439  0.0  1.0  0.0  \n",
       "2763   0.772783       0.865854  0.0  0.0  1.0  \n",
       "5166   1.913330       0.804878  0.0  1.0  0.0  \n",
       "4842   2.953830       0.252033  0.0  1.0  0.0  \n",
       "3238   2.383556       0.239837  0.0  1.0  0.0  \n",
       "3162   0.692745       0.853659  0.0  0.0  1.0  \n",
       "1665   1.353062       0.841463  0.0  1.0  0.0  \n",
       "5238   0.662730       0.166667  1.0  0.0  0.0  \n",
       "1061   1.283028       0.886179  0.0  1.0  0.0  \n",
       "320   -3.589311       0.479675  0.0  1.0  0.0  \n",
       "2738   1.793273       0.439024  0.0  1.0  0.0  \n",
       "2901   0.812802       0.313008  0.0  1.0  0.0  \n",
       "730    1.633196       0.821138  0.0  1.0  0.0  \n",
       "2796   1.142961       0.512195  0.0  0.0  1.0  \n",
       "817    0.632716       0.536585  0.0  0.0  1.0  \n",
       "3235   0.152485       0.138211  0.0  1.0  0.0  \n",
       "4221   0.582692       0.853659  1.0  0.0  0.0  \n",
       "3226  -0.417789       0.873984  0.0  1.0  0.0  \n",
       "2787   2.053398       0.365854  0.0  1.0  0.0  \n",
       "609   -2.548811       0.605691  0.0  1.0  0.0  \n",
       "3749   3.123912       0.495935  0.0  0.0  1.0  \n",
       "1534   2.283508       0.544715  0.0  1.0  0.0  \n",
       "3055   0.812802       0.264228  0.0  1.0  0.0  \n",
       "3610   1.373071       1.000000  1.0  0.0  0.0  \n",
       "2994   0.082452       0.857724  0.0  1.0  0.0  \n",
       "4160   2.113426       0.768293  0.0  1.0  0.0  \n",
       "4113   2.783748       0.040650  0.0  1.0  0.0  \n",
       "1053   2.093417       0.768293  0.0  1.0  0.0  \n",
       "752    2.893801       0.426829  0.0  0.0  1.0  \n",
       "3173   1.373071       0.032520  0.0  1.0  0.0  \n",
       "2702  -1.108120       0.955285  0.0  1.0  0.0  \n",
       "2847   1.543153       0.410569  1.0  0.0  0.0  \n",
       "3189  -2.868965       0.288618  0.0  0.0  1.0  \n",
       "2850   2.793753       0.463415  0.0  1.0  0.0  \n",
       "4771   2.023383       0.837398  0.0  1.0  0.0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_falha_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b7b2f0e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2330    4\n",
       "3156    0\n",
       "4667    3\n",
       "4938    5\n",
       "6274    2\n",
       "3038    0\n",
       "2473    2\n",
       "5720    3\n",
       "2982    0\n",
       "2961    3\n",
       "570     3\n",
       "1726    2\n",
       "6433    2\n",
       "3188    0\n",
       "6005    5\n",
       "1424    3\n",
       "2425    5\n",
       "3164    0\n",
       "1633    3\n",
       "2771    0\n",
       "2568    0\n",
       "3611    2\n",
       "3048    0\n",
       "5338    2\n",
       "2763    0\n",
       "5166    2\n",
       "4842    3\n",
       "3238    0\n",
       "3162    0\n",
       "1665    2\n",
       "5238    4\n",
       "1061    2\n",
       "320     3\n",
       "2738    0\n",
       "2901    0\n",
       "730     2\n",
       "2796    0\n",
       "817     4\n",
       "3235    0\n",
       "4221    5\n",
       "3226    5\n",
       "2787    0\n",
       "609     3\n",
       "3749    3\n",
       "1534    3\n",
       "3055    0\n",
       "3610    2\n",
       "2994    5\n",
       "4160    3\n",
       "4113    3\n",
       "1053    2\n",
       "752     3\n",
       "3173    0\n",
       "2702    5\n",
       "2847    0\n",
       "3189    3\n",
       "2850    3\n",
       "4771    2\n",
       "dtype: int32"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_falha_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7f475379",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot das falhas no dataset de treino\n",
    "sns.countplot(x=y_falha_treino)\n",
    "plt.title('Tipo de falha nas máquinas no dataset de treino');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b09764c",
   "metadata": {},
   "source": [
    "Nesse caso já possuímos um dataset com classes melhor balanceadas, não precisamos de _oversampling_. No entanto, alguns algoritmos de Machine Learning, como XGBoost, não aceitam receber os labels das _n_ classes fora da ordem 0 até a classe _n_-1. Então faremos um novo encoding, que será desfeito após a previsão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1e0f4b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_falha_treino_copia = y_falha_treino.copy()\n",
    "y_falha_val_copia = y_falha_val.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fb9329d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Novo encoding para ficar no intervalo (0,4)\n",
    "y_falha_treino[y_falha_treino > 0] = y_falha_treino - 1\n",
    "y_falha_val[y_falha_val > 0] = y_falha_val - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cd6717d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot das falhas no dataset de treino - Após novo encoding\n",
    "sns.countplot(x=y_falha_treino)\n",
    "plt.title('Tipo de falha nas máquinas no dataset de treino');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "10277491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a função que treina e avalia o modelo multiclasse\n",
    "def train_and_score_multiclass_model(algoritmo, X_treino, y_treino, X_teste, y_teste, nome = None, version = '1', auc = False):\n",
    "    # Cria o modelo\n",
    "    modelo = algoritmo\n",
    "    \n",
    "    # Treinamento\n",
    "    start = time.time()\n",
    "    modelo.fit(X_treino, y_treino)\n",
    "    end = time.time()\n",
    "    print('Tempo de Treinamento do Modelo:', end - start)\n",
    "    \n",
    "    # Fazendo as previsões para o dataset de teste\n",
    "    previsoes = modelo.predict(X_teste)\n",
    "    \n",
    "    # Avaliação do modelo\n",
    "    # Matriz de confusão\n",
    "    print('\\nMatriz de confusão\\n', confusion_matrix(y_teste, previsoes))\n",
    "    \n",
    "    # Dicionário de métricas e metadados\n",
    "    dict_model =   {'Modelo': nome,\n",
    "                    'Versão': version,\n",
    "                    'Precision':precision_score(y_teste, previsoes, average = 'macro', zero_division=0),\n",
    "                    'Recall':recall_score(y_teste, previsoes, average = 'macro', zero_division=0),\n",
    "                    'F1 Score':f1_score(y_teste, previsoes, average = 'macro', zero_division=0),\n",
    "                    'Acurácia':accuracy_score(y_teste, previsoes)}\n",
    "    \n",
    "    if auc:\n",
    "        dict_model['ROC AUC'] = roc_auc_score(y_teste, previsoes, multi_class='ovr')\n",
    "        \n",
    "    return modelo, dict_model, previsoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "26efaa0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de Treinamento do Modelo: 0.04399228096008301\n",
      "\n",
      "Matriz de confusão\n",
      " [[17  1  1  0  0]\n",
      " [ 1 10  1  1  0]\n",
      " [ 0  3  7  0  6]\n",
      " [ 0  0  0  2  1]\n",
      " [ 1  0  0  3  3]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Modelo': 'KNN',\n",
       " 'Versão': 'Multiclass Classification 1',\n",
       " 'Precision': 0.6040267335004177,\n",
       " 'Recall': 0.6393411413148254,\n",
       " 'F1 Score': 0.5985726407522074,\n",
       " 'Acurácia': 0.6724137931034483}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo 1 - KNN - Multiclasse\n",
    "modelo1_multi, dict1, previsoes1 = train_and_score_multiclass_model(KNeighborsClassifier(), X_falha_treino, y_falha_treino, \n",
    "                                                                       X_falha_val, y_falha_val,\n",
    "                                                                       nome = 'KNN',\n",
    "                                                                       version = 'Multiclass Classification 1')\n",
    "dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bca94286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de Treinamento do Modelo: 0.006008625030517578\n",
      "\n",
      "Matriz de confusão\n",
      " [[ 2  3  0 12  2]\n",
      " [ 0 11  0  2  0]\n",
      " [ 0  1  3  7  5]\n",
      " [ 0  0  1  2  0]\n",
      " [ 0  1  0  3  3]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Modelo': 'Naive Bayes',\n",
       " 'Versão': 'Multiclass Classification 1',\n",
       " 'Precision': 0.5628846153846154,\n",
       " 'Recall': 0.4468310198573356,\n",
       " 'F1 Score': 0.347993818216942,\n",
       " 'Acurácia': 0.3620689655172414}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo 2 - Naive Bayes - Multiclasse\n",
    "modelo2_multi, dict2, previsoes2 = train_and_score_multiclass_model(GaussianNB(), X_falha_treino, y_falha_treino, \n",
    "                                                                       X_falha_val, y_falha_val,\n",
    "                                                                       nome = 'Naive Bayes',\n",
    "                                                                       version = 'Multiclass Classification 1')\n",
    "dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3e03b252",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de Treinamento do Modelo: 0.09099721908569336\n",
      "\n",
      "Matriz de confusão\n",
      " [[17  0  0  1  1]\n",
      " [ 2 10  0  1  0]\n",
      " [ 4  2  6  3  1]\n",
      " [ 0  0  1  2  0]\n",
      " [ 1  0  0  2  4]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Modelo': 'Decision Tree Classifier',\n",
       " 'Versão': 'Multiclass Classification 1',\n",
       " 'Precision': 0.6575396825396825,\n",
       " 'Recall': 0.6554125698862541,\n",
       " 'F1 Score': 0.6122309507142673,\n",
       " 'Acurácia': 0.6724137931034483}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo 3 - Decision Tree - Multiclasse\n",
    "modelo3_multi, dict3, previsoes3 = train_and_score_multiclass_model(DecisionTreeClassifier(), X_falha_treino, y_falha_treino, \n",
    "                                                                       X_falha_val, y_falha_val,\n",
    "                                                                       nome = 'Decision Tree Classifier',\n",
    "                                                                       version = 'Multiclass Classification 1')\n",
    "dict3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d67c9eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de Treinamento do Modelo: 2.2969884872436523\n",
      "\n",
      "Matriz de confusão\n",
      " [[18  0  1  0  0]\n",
      " [ 1 11  0  1  0]\n",
      " [ 2  1  8  3  2]\n",
      " [ 0  0  1  2  0]\n",
      " [ 0  0  0  1  6]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Modelo': 'Random Forest Classifier',\n",
       " 'Versão': 'Multiclass Classification 1',\n",
       " 'Precision': 0.7219047619047618,\n",
       " 'Recall': 0.7634663582032003,\n",
       " 'F1 Score': 0.719076923076923,\n",
       " 'Acurácia': 0.7758620689655172}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo 4 - Decision Tree - Multiclasse\n",
    "modelo4_multi, dict4, previsoes4 = train_and_score_multiclass_model(RandomForestClassifier(), X_falha_treino, y_falha_treino, \n",
    "                                                                       X_falha_val, y_falha_val,\n",
    "                                                                       nome = 'Random Forest Classifier',\n",
    "                                                                       version = 'Multiclass Classification 1')\n",
    "dict4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3c07325f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de Treinamento do Modelo: 0.8709943294525146\n",
      "\n",
      "Matriz de confusão\n",
      " [[18  1  0  0  0]\n",
      " [ 0 12  0  1  0]\n",
      " [ 0  1 14  0  1]\n",
      " [ 0  0  0  2  1]\n",
      " [ 0  1  0  2  4]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Modelo': 'SVM Classifier',\n",
       " 'Versão': 'Multiclass Classification 1',\n",
       " 'Precision': 0.7733333333333332,\n",
       " 'Recall': 0.7967081164449585,\n",
       " 'F1 Score': 0.7757667557667557,\n",
       " 'Acurácia': 0.8620689655172413}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo 5 - SVM Classifier - Multiclasse\n",
    "modelo5_multi, dict5, previsoes5 = train_and_score_multiclass_model(svm.SVC(), X_falha_treino, y_falha_treino, \n",
    "                                                                       X_falha_val, y_falha_val,\n",
    "                                                                       nome = 'SVM Classifier',\n",
    "                                                                       version = 'Multiclass Classification 1')\n",
    "dict5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f76a8c80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de Treinamento do Modelo: 1.1719884872436523\n",
      "\n",
      "Matriz de confusão\n",
      " [[17  1  1  0  0]\n",
      " [ 1 11  0  0  1]\n",
      " [ 1  0  9  5  1]\n",
      " [ 0  0  0  3  0]\n",
      " [ 0  0  0  1  6]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Modelo': 'XGBoost Classifier',\n",
       " 'Versão': 'Multiclass Classification 1',\n",
       " 'Precision': 0.7589473684210526,\n",
       " 'Recall': 0.8321067090803933,\n",
       " 'F1 Score': 0.753408906882591,\n",
       " 'Acurácia': 0.7931034482758621}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo 6 - SVM Classifier - Multiclasse\n",
    "modelo6_multi, dict6, previsoes6 = train_and_score_multiclass_model(XGBClassifier(), X_falha_treino, y_falha_treino, \n",
    "                                                                       X_falha_val, y_falha_val,\n",
    "                                                                       nome = 'XGBoost Classifier',\n",
    "                                                                       version = 'Multiclass Classification 1')\n",
    "dict6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eaab7dfe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dict1</th>\n",
       "      <th>dict2</th>\n",
       "      <th>dict3</th>\n",
       "      <th>dict4</th>\n",
       "      <th>dict5</th>\n",
       "      <th>dict6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Modelo</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>SVM Classifier</td>\n",
       "      <td>XGBoost Classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Versão</th>\n",
       "      <td>Multiclass Classification 1</td>\n",
       "      <td>Multiclass Classification 1</td>\n",
       "      <td>Multiclass Classification 1</td>\n",
       "      <td>Multiclass Classification 1</td>\n",
       "      <td>Multiclass Classification 1</td>\n",
       "      <td>Multiclass Classification 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.604027</td>\n",
       "      <td>0.562885</td>\n",
       "      <td>0.65754</td>\n",
       "      <td>0.721905</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.758947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.639341</td>\n",
       "      <td>0.446831</td>\n",
       "      <td>0.655413</td>\n",
       "      <td>0.763466</td>\n",
       "      <td>0.796708</td>\n",
       "      <td>0.832107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.598573</td>\n",
       "      <td>0.347994</td>\n",
       "      <td>0.612231</td>\n",
       "      <td>0.719077</td>\n",
       "      <td>0.775767</td>\n",
       "      <td>0.753409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acurácia</th>\n",
       "      <td>0.672414</td>\n",
       "      <td>0.362069</td>\n",
       "      <td>0.672414</td>\n",
       "      <td>0.775862</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.793103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 dict1                        dict2  \\\n",
       "Modelo                             KNN                  Naive Bayes   \n",
       "Versão     Multiclass Classification 1  Multiclass Classification 1   \n",
       "Precision                     0.604027                     0.562885   \n",
       "Recall                        0.639341                     0.446831   \n",
       "F1 Score                      0.598573                     0.347994   \n",
       "Acurácia                      0.672414                     0.362069   \n",
       "\n",
       "                                 dict3                        dict4  \\\n",
       "Modelo        Decision Tree Classifier     Random Forest Classifier   \n",
       "Versão     Multiclass Classification 1  Multiclass Classification 1   \n",
       "Precision                      0.65754                     0.721905   \n",
       "Recall                        0.655413                     0.763466   \n",
       "F1 Score                      0.612231                     0.719077   \n",
       "Acurácia                      0.672414                     0.775862   \n",
       "\n",
       "                                 dict5                        dict6  \n",
       "Modelo                  SVM Classifier           XGBoost Classifier  \n",
       "Versão     Multiclass Classification 1  Multiclass Classification 1  \n",
       "Precision                     0.773333                     0.758947  \n",
       "Recall                        0.796708                     0.832107  \n",
       "F1 Score                      0.775767                     0.753409  \n",
       "Acurácia                      0.862069                     0.793103  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumo_multi1 = pd.DataFrame({'dict1':pd.Series(dict1),\n",
    "                           'dict2':pd.Series(dict2),\n",
    "                           'dict3':pd.Series(dict3),\n",
    "                           'dict4':pd.Series(dict4),\n",
    "                           'dict5':pd.Series(dict5),\n",
    "                           'dict6':pd.Series(dict6)})\n",
    "\n",
    "resumo_multi1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993f845b",
   "metadata": {},
   "source": [
    "Para o modelo de classificação multiclasse, utilizaremos a métrica F1 Score, que é a média harmônica entre precision e recall para avaliar o modelo. Como agora não temos exatamente uma falha como mais ou menos grave que outra, um bom equilíbrio de falsos positivos e falsos negativos pode ser útil.\n",
    "\n",
    "Dentre os modelos utilizados para a classificação multiclasse, o Random Forest foi o que melhor respondeu. Vamos utilizar esse modelo como base e fazer um GridSearchCV para encontrar os melhores hiperparâmetros para ele e tentar melhorar a resposta final do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "9bb66e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV executou em 784.36 segundos para todas as combinações de candidatos a parâmetros do modelo.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([1.29479876, 1.63279967, 1.74940224, 1.86160011, 1.09639997,\n",
       "        1.13039989, 1.17039938, 1.18839836, 0.94999695, 0.94499917,\n",
       "        0.91939979, 0.93120036, 0.83439879, 0.79240012, 0.80840087,\n",
       "        0.79559999, 0.76140113, 0.68379936, 0.69599957, 0.692799  ,\n",
       "        0.70600052, 0.6447998 , 0.62339754, 0.63179874, 0.64719915,\n",
       "        0.59439797, 0.57599907, 0.58720069, 0.62380185, 0.57119884,\n",
       "        0.54899812, 0.55040016, 0.58739743, 0.52419701, 0.52279968,\n",
       "        0.50879774, 1.2573988 , 1.61039982, 1.78060174, 1.85020056,\n",
       "        1.11220093, 1.24159918, 1.28380423, 1.30240107, 1.00179682,\n",
       "        1.07840176, 1.11239939, 1.10339894, 0.92859931, 1.08120127,\n",
       "        0.99679971, 1.00299983, 0.92279973, 0.93759909, 0.93579779,\n",
       "        1.07739863, 1.07179961, 1.12339802, 1.1190001 , 1.08980021,\n",
       "        0.87659874, 1.0975987 , 0.86539965, 0.84499989, 0.84039936,\n",
       "        0.85400028, 0.82919936, 0.83899779, 0.88519998, 0.86219668,\n",
       "        0.78719945, 0.81740055, 1.2625937 , 1.61779847, 1.77320032,\n",
       "        1.93780136, 1.13100133, 1.29879866, 1.47259769, 1.55199757,\n",
       "        1.0413991 , 1.20640268, 1.19759903, 1.22020044, 0.99419823,\n",
       "        1.22940035, 1.11519895, 1.11220074, 0.95719614, 1.06499915,\n",
       "        1.05059886, 1.17179923, 0.91720152, 1.03560019, 1.01399188,\n",
       "        1.05379829, 1.24141665, 1.13459954, 0.99479904, 0.96059966,\n",
       "        0.88259864, 0.99919996, 0.95259895, 0.97159882, 1.0193995 ,\n",
       "        0.9617979 , 0.94219947, 0.92199926, 1.24140067, 1.62459927,\n",
       "        1.8558002 , 1.82159934, 1.11599774, 1.33379984, 1.41720023,\n",
       "        1.53459949, 1.06500201, 1.24120049, 1.27399936, 1.29779892,\n",
       "        1.10539827, 1.17380033, 1.19559951, 1.20900049, 0.97500029,\n",
       "        1.13200011, 1.2601994 , 1.18600049, 0.96579847, 1.10979886,\n",
       "        1.09719906, 1.13719897, 1.02920017, 1.1000001 , 1.08919954,\n",
       "        1.10999832, 0.9305985 , 1.11199765, 1.05359998, 1.18639793,\n",
       "        0.93719988, 1.03459926, 1.04439645, 1.02579937]),\n",
       " 'std_fit_time': array([0.02251556, 0.04212042, 0.04796937, 0.04758317, 0.0155628 ,\n",
       "        0.01492016, 0.0185329 , 0.00915916, 0.03598227, 0.0731467 ,\n",
       "        0.01555052, 0.01519753, 0.02112407, 0.0184456 , 0.04065961,\n",
       "        0.01484083, 0.01318531, 0.00391789, 0.01227997, 0.00724932,\n",
       "        0.01375444, 0.02232027, 0.00922103, 0.01334769, 0.00775639,\n",
       "        0.01943423, 0.01345886, 0.02147069, 0.01316637, 0.02048854,\n",
       "        0.01946113, 0.02337131, 0.02133347, 0.01554802, 0.02088572,\n",
       "        0.00271367, 0.02233047, 0.02726052, 0.02224541, 0.090797  ,\n",
       "        0.02877203, 0.03193109, 0.02993049, 0.02496821, 0.01994423,\n",
       "        0.01312332, 0.03394356, 0.01618219, 0.01128954, 0.12359515,\n",
       "        0.02146863, 0.02737353, 0.0341223 , 0.02098724, 0.03105925,\n",
       "        0.11205141, 0.00803196, 0.01958251, 0.02579058, 0.07481906,\n",
       "        0.03777362, 0.11757293, 0.02897258, 0.02795727, 0.02838788,\n",
       "        0.0246452 , 0.04282497, 0.01316212, 0.08280723, 0.06757519,\n",
       "        0.03029417, 0.01510758, 0.01480474, 0.01951998, 0.02789637,\n",
       "        0.1578588 , 0.02909953, 0.01770084, 0.06447945, 0.16732234,\n",
       "        0.01660806, 0.04144953, 0.02043231, 0.02449017, 0.01969395,\n",
       "        0.15127553, 0.01963041, 0.02135823, 0.01613058, 0.01697   ,\n",
       "        0.0270757 , 0.15398776, 0.02093597, 0.01674099, 0.02502511,\n",
       "        0.02654218, 0.45078452, 0.15587727, 0.03542415, 0.03627416,\n",
       "        0.02247244, 0.03379784, 0.03827732, 0.05310692, 0.06381546,\n",
       "        0.01401876, 0.02516622, 0.04832417, 0.02200568, 0.02776884,\n",
       "        0.13415404, 0.01502848, 0.01179881, 0.02182086, 0.02265073,\n",
       "        0.15089159, 0.03090119, 0.01121125, 0.02996819, 0.02486226,\n",
       "        0.09685633, 0.02558426, 0.01824917, 0.02998004, 0.01857935,\n",
       "        0.03023576, 0.13973174, 0.00715395, 0.02006349, 0.02223059,\n",
       "        0.04443295, 0.03627087, 0.11998591, 0.02188051, 0.02224001,\n",
       "        0.04962619, 0.01482681, 0.08759839, 0.02127692, 0.1468982 ,\n",
       "        0.01173787, 0.02729741, 0.03359724, 0.03305483]),\n",
       " 'mean_score_time': array([0.00819898, 0.00960188, 0.00959907, 0.01040282, 0.00800223,\n",
       "        0.00859985, 0.00860147, 0.0085999 , 0.00760136, 0.00779958,\n",
       "        0.00700026, 0.00740042, 0.00760036, 0.0072    , 0.00759897,\n",
       "        0.00739951, 0.00700002, 0.006601  , 0.00659986, 0.00640011,\n",
       "        0.00699992, 0.00680141, 0.00659981, 0.00660086, 0.00700235,\n",
       "        0.00660291, 0.00599957, 0.00620036, 0.00700116, 0.00580029,\n",
       "        0.00620108, 0.00640159, 0.00640163, 0.00580134, 0.00559998,\n",
       "        0.00600119, 0.00840054, 0.00920014, 0.00939765, 0.00980353,\n",
       "        0.00739908, 0.00819845, 0.00819817, 0.0074007 , 0.00660024,\n",
       "        0.00720086, 0.00699964, 0.0064002 , 0.00700092, 0.00659933,\n",
       "        0.00659995, 0.00619998, 0.00599933, 0.00579944, 0.00660105,\n",
       "        0.00700021, 0.0082006 , 0.0074017 , 0.00720005, 0.00679574,\n",
       "        0.00660176, 0.006604  , 0.00600209, 0.00520024, 0.00560026,\n",
       "        0.00559998, 0.00580225, 0.00560122, 0.0064003 , 0.00600114,\n",
       "        0.00580096, 0.00520043, 0.00800319, 0.00880098, 0.00920138,\n",
       "        0.0100018 , 0.00839968, 0.00700054, 0.00780087, 0.00799913,\n",
       "        0.00679955, 0.00639901, 0.00639982, 0.00679913, 0.00600142,\n",
       "        0.00640039, 0.00580034, 0.00600061, 0.00580082, 0.00600109,\n",
       "        0.00560017, 0.00640087, 0.00599976, 0.00579987, 0.00560002,\n",
       "        0.00580044, 0.00660052, 0.00600076, 0.00560088, 0.00560136,\n",
       "        0.00560203, 0.00539923, 0.00599899, 0.00560198, 0.0064024 ,\n",
       "        0.00520134, 0.0053998 , 0.00499978, 0.00780058, 0.00880184,\n",
       "        0.00960021, 0.0088016 , 0.00699916, 0.0064002 , 0.00700035,\n",
       "        0.00740004, 0.00619812, 0.00679779, 0.00600047, 0.00680127,\n",
       "        0.00619965, 0.00599961, 0.00620208, 0.00620036, 0.00540042,\n",
       "        0.00559945, 0.00620003, 0.00600195, 0.00559978, 0.00539989,\n",
       "        0.00579948, 0.00580082, 0.00640178, 0.00579939, 0.00500083,\n",
       "        0.0056026 , 0.00560088, 0.00559998, 0.00540085, 0.00600104,\n",
       "        0.00599914, 0.00580196, 0.00560036, 0.00540066]),\n",
       " 'std_score_time': array([7.48526177e-04, 1.20053467e-03, 4.90454859e-04, 4.90548868e-04,\n",
       "        1.89178795e-06, 4.89960113e-04, 8.02900531e-04, 7.99965963e-04,\n",
       "        4.88698388e-04, 7.48953089e-04, 1.03814798e-06, 4.90645315e-04,\n",
       "        1.02102187e-03, 4.00066461e-04, 1.20254072e-03, 8.00157508e-04,\n",
       "        2.44259805e-06, 4.90780475e-04, 7.99632135e-04, 4.89687455e-04,\n",
       "        1.55539574e-06, 7.48470121e-04, 4.91948891e-04, 4.88619738e-04,\n",
       "        3.51697710e-06, 8.04023589e-04, 6.32637507e-04, 3.99926636e-04,\n",
       "        1.26553720e-03, 3.99615013e-04, 4.00282610e-04, 8.00349549e-04,\n",
       "        4.91070339e-04, 4.00738912e-04, 4.90662493e-04, 1.14242063e-06,\n",
       "        7.99609091e-04, 3.99808420e-04, 4.88127711e-04, 7.52475158e-04,\n",
       "        4.89590773e-04, 1.46637654e-03, 1.16330983e-03, 4.89054529e-04,\n",
       "        4.90836622e-04, 9.80858029e-04, 6.32034111e-04, 4.90973791e-04,\n",
       "        6.32562710e-04, 1.19933398e-03, 7.99799044e-04, 4.01664102e-04,\n",
       "        1.45415789e-06, 3.99914106e-04, 1.02093913e-03, 8.96128611e-04,\n",
       "        3.99615411e-04, 4.90274821e-04, 9.79608232e-04, 4.02277547e-04,\n",
       "        4.91598908e-04, 4.92471092e-04, 6.35055150e-04, 4.00861789e-04,\n",
       "        4.90312000e-04, 8.00491762e-04, 1.16521583e-03, 4.89534399e-04,\n",
       "        8.00752675e-04, 2.26986508e-06, 4.00068337e-04, 3.99923566e-04,\n",
       "        6.33026487e-04, 4.00425491e-04, 4.01331676e-04, 1.54797456e-03,\n",
       "        1.49587270e-03, 1.27592928e-06, 1.16614779e-03, 1.26738436e-03,\n",
       "        7.48353994e-04, 4.88834296e-04, 4.89920847e-04, 3.99662696e-04,\n",
       "        1.86149800e-06, 8.00704999e-04, 7.47653364e-04, 6.31882242e-04,\n",
       "        4.00353500e-04, 1.54218308e-06, 4.89940502e-04, 1.35703310e-03,\n",
       "        1.99703136e-06, 3.99878228e-04, 4.89531566e-04, 3.99092403e-04,\n",
       "        2.24356613e-03, 1.09680253e-03, 4.90625081e-04, 4.90431767e-04,\n",
       "        4.89318494e-04, 4.89395610e-04, 6.32486369e-04, 4.91225680e-04,\n",
       "        1.01903087e-03, 3.99352444e-04, 4.89998769e-04, 8.06404806e-07,\n",
       "        4.00187414e-04, 1.16882093e-03, 1.74355903e-03, 4.00616736e-04,\n",
       "        1.76236330e-06, 4.91265740e-04, 1.09540973e-03, 1.35672638e-03,\n",
       "        3.99974561e-04, 9.79284350e-04, 9.46494734e-07, 1.16755409e-03,\n",
       "        3.99208154e-04, 3.45961707e-06, 9.83151713e-04, 3.99685958e-04,\n",
       "        4.89300334e-04, 4.89653567e-04, 1.16643297e-03, 1.10015756e-03,\n",
       "        4.92363135e-04, 4.89920917e-04, 4.01234637e-04, 7.48736633e-04,\n",
       "        4.88528337e-04, 3.99882606e-04, 1.79686009e-06, 4.90763921e-04,\n",
       "        4.89649992e-04, 7.99655943e-04, 4.90119652e-04, 8.94096328e-04,\n",
       "        1.10189629e-06, 7.51466790e-04, 7.99549075e-04, 4.90371715e-04]),\n",
       " 'param_gamma': masked_array(data=[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "                    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "                    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "                    0.0, 0.0, 0.0, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.30000000000000004, 0.30000000000000004,\n",
       "                    0.30000000000000004, 0.30000000000000004,\n",
       "                    0.30000000000000004, 0.30000000000000004,\n",
       "                    0.30000000000000004, 0.30000000000000004,\n",
       "                    0.30000000000000004, 0.30000000000000004,\n",
       "                    0.30000000000000004, 0.30000000000000004,\n",
       "                    0.30000000000000004, 0.30000000000000004,\n",
       "                    0.30000000000000004, 0.30000000000000004,\n",
       "                    0.30000000000000004, 0.30000000000000004,\n",
       "                    0.30000000000000004, 0.30000000000000004,\n",
       "                    0.30000000000000004, 0.30000000000000004,\n",
       "                    0.30000000000000004, 0.30000000000000004,\n",
       "                    0.30000000000000004, 0.30000000000000004,\n",
       "                    0.30000000000000004, 0.30000000000000004,\n",
       "                    0.30000000000000004, 0.30000000000000004,\n",
       "                    0.30000000000000004, 0.30000000000000004,\n",
       "                    0.30000000000000004, 0.30000000000000004,\n",
       "                    0.30000000000000004, 0.30000000000000004],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learning_rate': masked_array(data=[0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.30000000000000004, 0.30000000000000004,\n",
       "                    0.30000000000000004, 0.30000000000000004, 0.4, 0.4,\n",
       "                    0.4, 0.4, 0.5, 0.5, 0.5, 0.5, 0.6, 0.6, 0.6, 0.6,\n",
       "                    0.7000000000000001, 0.7000000000000001,\n",
       "                    0.7000000000000001, 0.7000000000000001, 0.8, 0.8, 0.8,\n",
       "                    0.8, 0.9, 0.9, 0.9, 0.9, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.30000000000000004, 0.30000000000000004,\n",
       "                    0.30000000000000004, 0.30000000000000004, 0.4, 0.4,\n",
       "                    0.4, 0.4, 0.5, 0.5, 0.5, 0.5, 0.6, 0.6, 0.6, 0.6,\n",
       "                    0.7000000000000001, 0.7000000000000001,\n",
       "                    0.7000000000000001, 0.7000000000000001, 0.8, 0.8, 0.8,\n",
       "                    0.8, 0.9, 0.9, 0.9, 0.9, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.30000000000000004, 0.30000000000000004,\n",
       "                    0.30000000000000004, 0.30000000000000004, 0.4, 0.4,\n",
       "                    0.4, 0.4, 0.5, 0.5, 0.5, 0.5, 0.6, 0.6, 0.6, 0.6,\n",
       "                    0.7000000000000001, 0.7000000000000001,\n",
       "                    0.7000000000000001, 0.7000000000000001, 0.8, 0.8, 0.8,\n",
       "                    0.8, 0.9, 0.9, 0.9, 0.9, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.30000000000000004, 0.30000000000000004,\n",
       "                    0.30000000000000004, 0.30000000000000004, 0.4, 0.4,\n",
       "                    0.4, 0.4, 0.5, 0.5, 0.5, 0.5, 0.6, 0.6, 0.6, 0.6,\n",
       "                    0.7000000000000001, 0.7000000000000001,\n",
       "                    0.7000000000000001, 0.7000000000000001, 0.8, 0.8, 0.8,\n",
       "                    0.8, 0.9, 0.9, 0.9, 0.9],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[3, 5, 7, 9, 3, 5, 7, 9, 3, 5, 7, 9, 3, 5, 7, 9, 3, 5,\n",
       "                    7, 9, 3, 5, 7, 9, 3, 5, 7, 9, 3, 5, 7, 9, 3, 5, 7, 9,\n",
       "                    3, 5, 7, 9, 3, 5, 7, 9, 3, 5, 7, 9, 3, 5, 7, 9, 3, 5,\n",
       "                    7, 9, 3, 5, 7, 9, 3, 5, 7, 9, 3, 5, 7, 9, 3, 5, 7, 9,\n",
       "                    3, 5, 7, 9, 3, 5, 7, 9, 3, 5, 7, 9, 3, 5, 7, 9, 3, 5,\n",
       "                    7, 9, 3, 5, 7, 9, 3, 5, 7, 9, 3, 5, 7, 9, 3, 5, 7, 9,\n",
       "                    3, 5, 7, 9, 3, 5, 7, 9, 3, 5, 7, 9, 3, 5, 7, 9, 3, 5,\n",
       "                    7, 9, 3, 5, 7, 9, 3, 5, 7, 9, 3, 5, 7, 9, 3, 5, 7, 9],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'gamma': 0.0, 'learning_rate': 0.1, 'max_depth': 3},\n",
       "  {'gamma': 0.0, 'learning_rate': 0.1, 'max_depth': 5},\n",
       "  {'gamma': 0.0, 'learning_rate': 0.1, 'max_depth': 7},\n",
       "  {'gamma': 0.0, 'learning_rate': 0.1, 'max_depth': 9},\n",
       "  {'gamma': 0.0, 'learning_rate': 0.2, 'max_depth': 3},\n",
       "  {'gamma': 0.0, 'learning_rate': 0.2, 'max_depth': 5},\n",
       "  {'gamma': 0.0, 'learning_rate': 0.2, 'max_depth': 7},\n",
       "  {'gamma': 0.0, 'learning_rate': 0.2, 'max_depth': 9},\n",
       "  {'gamma': 0.0, 'learning_rate': 0.30000000000000004, 'max_depth': 3},\n",
       "  {'gamma': 0.0, 'learning_rate': 0.30000000000000004, 'max_depth': 5},\n",
       "  {'gamma': 0.0, 'learning_rate': 0.30000000000000004, 'max_depth': 7},\n",
       "  {'gamma': 0.0, 'learning_rate': 0.30000000000000004, 'max_depth': 9},\n",
       "  {'gamma': 0.0, 'learning_rate': 0.4, 'max_depth': 3},\n",
       "  {'gamma': 0.0, 'learning_rate': 0.4, 'max_depth': 5},\n",
       "  {'gamma': 0.0, 'learning_rate': 0.4, 'max_depth': 7},\n",
       "  {'gamma': 0.0, 'learning_rate': 0.4, 'max_depth': 9},\n",
       "  {'gamma': 0.0, 'learning_rate': 0.5, 'max_depth': 3},\n",
       "  {'gamma': 0.0, 'learning_rate': 0.5, 'max_depth': 5},\n",
       "  {'gamma': 0.0, 'learning_rate': 0.5, 'max_depth': 7},\n",
       "  {'gamma': 0.0, 'learning_rate': 0.5, 'max_depth': 9},\n",
       "  {'gamma': 0.0, 'learning_rate': 0.6, 'max_depth': 3},\n",
       "  {'gamma': 0.0, 'learning_rate': 0.6, 'max_depth': 5},\n",
       "  {'gamma': 0.0, 'learning_rate': 0.6, 'max_depth': 7},\n",
       "  {'gamma': 0.0, 'learning_rate': 0.6, 'max_depth': 9},\n",
       "  {'gamma': 0.0, 'learning_rate': 0.7000000000000001, 'max_depth': 3},\n",
       "  {'gamma': 0.0, 'learning_rate': 0.7000000000000001, 'max_depth': 5},\n",
       "  {'gamma': 0.0, 'learning_rate': 0.7000000000000001, 'max_depth': 7},\n",
       "  {'gamma': 0.0, 'learning_rate': 0.7000000000000001, 'max_depth': 9},\n",
       "  {'gamma': 0.0, 'learning_rate': 0.8, 'max_depth': 3},\n",
       "  {'gamma': 0.0, 'learning_rate': 0.8, 'max_depth': 5},\n",
       "  {'gamma': 0.0, 'learning_rate': 0.8, 'max_depth': 7},\n",
       "  {'gamma': 0.0, 'learning_rate': 0.8, 'max_depth': 9},\n",
       "  {'gamma': 0.0, 'learning_rate': 0.9, 'max_depth': 3},\n",
       "  {'gamma': 0.0, 'learning_rate': 0.9, 'max_depth': 5},\n",
       "  {'gamma': 0.0, 'learning_rate': 0.9, 'max_depth': 7},\n",
       "  {'gamma': 0.0, 'learning_rate': 0.9, 'max_depth': 9},\n",
       "  {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 3},\n",
       "  {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 5},\n",
       "  {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 7},\n",
       "  {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 9},\n",
       "  {'gamma': 0.1, 'learning_rate': 0.2, 'max_depth': 3},\n",
       "  {'gamma': 0.1, 'learning_rate': 0.2, 'max_depth': 5},\n",
       "  {'gamma': 0.1, 'learning_rate': 0.2, 'max_depth': 7},\n",
       "  {'gamma': 0.1, 'learning_rate': 0.2, 'max_depth': 9},\n",
       "  {'gamma': 0.1, 'learning_rate': 0.30000000000000004, 'max_depth': 3},\n",
       "  {'gamma': 0.1, 'learning_rate': 0.30000000000000004, 'max_depth': 5},\n",
       "  {'gamma': 0.1, 'learning_rate': 0.30000000000000004, 'max_depth': 7},\n",
       "  {'gamma': 0.1, 'learning_rate': 0.30000000000000004, 'max_depth': 9},\n",
       "  {'gamma': 0.1, 'learning_rate': 0.4, 'max_depth': 3},\n",
       "  {'gamma': 0.1, 'learning_rate': 0.4, 'max_depth': 5},\n",
       "  {'gamma': 0.1, 'learning_rate': 0.4, 'max_depth': 7},\n",
       "  {'gamma': 0.1, 'learning_rate': 0.4, 'max_depth': 9},\n",
       "  {'gamma': 0.1, 'learning_rate': 0.5, 'max_depth': 3},\n",
       "  {'gamma': 0.1, 'learning_rate': 0.5, 'max_depth': 5},\n",
       "  {'gamma': 0.1, 'learning_rate': 0.5, 'max_depth': 7},\n",
       "  {'gamma': 0.1, 'learning_rate': 0.5, 'max_depth': 9},\n",
       "  {'gamma': 0.1, 'learning_rate': 0.6, 'max_depth': 3},\n",
       "  {'gamma': 0.1, 'learning_rate': 0.6, 'max_depth': 5},\n",
       "  {'gamma': 0.1, 'learning_rate': 0.6, 'max_depth': 7},\n",
       "  {'gamma': 0.1, 'learning_rate': 0.6, 'max_depth': 9},\n",
       "  {'gamma': 0.1, 'learning_rate': 0.7000000000000001, 'max_depth': 3},\n",
       "  {'gamma': 0.1, 'learning_rate': 0.7000000000000001, 'max_depth': 5},\n",
       "  {'gamma': 0.1, 'learning_rate': 0.7000000000000001, 'max_depth': 7},\n",
       "  {'gamma': 0.1, 'learning_rate': 0.7000000000000001, 'max_depth': 9},\n",
       "  {'gamma': 0.1, 'learning_rate': 0.8, 'max_depth': 3},\n",
       "  {'gamma': 0.1, 'learning_rate': 0.8, 'max_depth': 5},\n",
       "  {'gamma': 0.1, 'learning_rate': 0.8, 'max_depth': 7},\n",
       "  {'gamma': 0.1, 'learning_rate': 0.8, 'max_depth': 9},\n",
       "  {'gamma': 0.1, 'learning_rate': 0.9, 'max_depth': 3},\n",
       "  {'gamma': 0.1, 'learning_rate': 0.9, 'max_depth': 5},\n",
       "  {'gamma': 0.1, 'learning_rate': 0.9, 'max_depth': 7},\n",
       "  {'gamma': 0.1, 'learning_rate': 0.9, 'max_depth': 9},\n",
       "  {'gamma': 0.2, 'learning_rate': 0.1, 'max_depth': 3},\n",
       "  {'gamma': 0.2, 'learning_rate': 0.1, 'max_depth': 5},\n",
       "  {'gamma': 0.2, 'learning_rate': 0.1, 'max_depth': 7},\n",
       "  {'gamma': 0.2, 'learning_rate': 0.1, 'max_depth': 9},\n",
       "  {'gamma': 0.2, 'learning_rate': 0.2, 'max_depth': 3},\n",
       "  {'gamma': 0.2, 'learning_rate': 0.2, 'max_depth': 5},\n",
       "  {'gamma': 0.2, 'learning_rate': 0.2, 'max_depth': 7},\n",
       "  {'gamma': 0.2, 'learning_rate': 0.2, 'max_depth': 9},\n",
       "  {'gamma': 0.2, 'learning_rate': 0.30000000000000004, 'max_depth': 3},\n",
       "  {'gamma': 0.2, 'learning_rate': 0.30000000000000004, 'max_depth': 5},\n",
       "  {'gamma': 0.2, 'learning_rate': 0.30000000000000004, 'max_depth': 7},\n",
       "  {'gamma': 0.2, 'learning_rate': 0.30000000000000004, 'max_depth': 9},\n",
       "  {'gamma': 0.2, 'learning_rate': 0.4, 'max_depth': 3},\n",
       "  {'gamma': 0.2, 'learning_rate': 0.4, 'max_depth': 5},\n",
       "  {'gamma': 0.2, 'learning_rate': 0.4, 'max_depth': 7},\n",
       "  {'gamma': 0.2, 'learning_rate': 0.4, 'max_depth': 9},\n",
       "  {'gamma': 0.2, 'learning_rate': 0.5, 'max_depth': 3},\n",
       "  {'gamma': 0.2, 'learning_rate': 0.5, 'max_depth': 5},\n",
       "  {'gamma': 0.2, 'learning_rate': 0.5, 'max_depth': 7},\n",
       "  {'gamma': 0.2, 'learning_rate': 0.5, 'max_depth': 9},\n",
       "  {'gamma': 0.2, 'learning_rate': 0.6, 'max_depth': 3},\n",
       "  {'gamma': 0.2, 'learning_rate': 0.6, 'max_depth': 5},\n",
       "  {'gamma': 0.2, 'learning_rate': 0.6, 'max_depth': 7},\n",
       "  {'gamma': 0.2, 'learning_rate': 0.6, 'max_depth': 9},\n",
       "  {'gamma': 0.2, 'learning_rate': 0.7000000000000001, 'max_depth': 3},\n",
       "  {'gamma': 0.2, 'learning_rate': 0.7000000000000001, 'max_depth': 5},\n",
       "  {'gamma': 0.2, 'learning_rate': 0.7000000000000001, 'max_depth': 7},\n",
       "  {'gamma': 0.2, 'learning_rate': 0.7000000000000001, 'max_depth': 9},\n",
       "  {'gamma': 0.2, 'learning_rate': 0.8, 'max_depth': 3},\n",
       "  {'gamma': 0.2, 'learning_rate': 0.8, 'max_depth': 5},\n",
       "  {'gamma': 0.2, 'learning_rate': 0.8, 'max_depth': 7},\n",
       "  {'gamma': 0.2, 'learning_rate': 0.8, 'max_depth': 9},\n",
       "  {'gamma': 0.2, 'learning_rate': 0.9, 'max_depth': 3},\n",
       "  {'gamma': 0.2, 'learning_rate': 0.9, 'max_depth': 5},\n",
       "  {'gamma': 0.2, 'learning_rate': 0.9, 'max_depth': 7},\n",
       "  {'gamma': 0.2, 'learning_rate': 0.9, 'max_depth': 9},\n",
       "  {'gamma': 0.30000000000000004, 'learning_rate': 0.1, 'max_depth': 3},\n",
       "  {'gamma': 0.30000000000000004, 'learning_rate': 0.1, 'max_depth': 5},\n",
       "  {'gamma': 0.30000000000000004, 'learning_rate': 0.1, 'max_depth': 7},\n",
       "  {'gamma': 0.30000000000000004, 'learning_rate': 0.1, 'max_depth': 9},\n",
       "  {'gamma': 0.30000000000000004, 'learning_rate': 0.2, 'max_depth': 3},\n",
       "  {'gamma': 0.30000000000000004, 'learning_rate': 0.2, 'max_depth': 5},\n",
       "  {'gamma': 0.30000000000000004, 'learning_rate': 0.2, 'max_depth': 7},\n",
       "  {'gamma': 0.30000000000000004, 'learning_rate': 0.2, 'max_depth': 9},\n",
       "  {'gamma': 0.30000000000000004,\n",
       "   'learning_rate': 0.30000000000000004,\n",
       "   'max_depth': 3},\n",
       "  {'gamma': 0.30000000000000004,\n",
       "   'learning_rate': 0.30000000000000004,\n",
       "   'max_depth': 5},\n",
       "  {'gamma': 0.30000000000000004,\n",
       "   'learning_rate': 0.30000000000000004,\n",
       "   'max_depth': 7},\n",
       "  {'gamma': 0.30000000000000004,\n",
       "   'learning_rate': 0.30000000000000004,\n",
       "   'max_depth': 9},\n",
       "  {'gamma': 0.30000000000000004, 'learning_rate': 0.4, 'max_depth': 3},\n",
       "  {'gamma': 0.30000000000000004, 'learning_rate': 0.4, 'max_depth': 5},\n",
       "  {'gamma': 0.30000000000000004, 'learning_rate': 0.4, 'max_depth': 7},\n",
       "  {'gamma': 0.30000000000000004, 'learning_rate': 0.4, 'max_depth': 9},\n",
       "  {'gamma': 0.30000000000000004, 'learning_rate': 0.5, 'max_depth': 3},\n",
       "  {'gamma': 0.30000000000000004, 'learning_rate': 0.5, 'max_depth': 5},\n",
       "  {'gamma': 0.30000000000000004, 'learning_rate': 0.5, 'max_depth': 7},\n",
       "  {'gamma': 0.30000000000000004, 'learning_rate': 0.5, 'max_depth': 9},\n",
       "  {'gamma': 0.30000000000000004, 'learning_rate': 0.6, 'max_depth': 3},\n",
       "  {'gamma': 0.30000000000000004, 'learning_rate': 0.6, 'max_depth': 5},\n",
       "  {'gamma': 0.30000000000000004, 'learning_rate': 0.6, 'max_depth': 7},\n",
       "  {'gamma': 0.30000000000000004, 'learning_rate': 0.6, 'max_depth': 9},\n",
       "  {'gamma': 0.30000000000000004,\n",
       "   'learning_rate': 0.7000000000000001,\n",
       "   'max_depth': 3},\n",
       "  {'gamma': 0.30000000000000004,\n",
       "   'learning_rate': 0.7000000000000001,\n",
       "   'max_depth': 5},\n",
       "  {'gamma': 0.30000000000000004,\n",
       "   'learning_rate': 0.7000000000000001,\n",
       "   'max_depth': 7},\n",
       "  {'gamma': 0.30000000000000004,\n",
       "   'learning_rate': 0.7000000000000001,\n",
       "   'max_depth': 9},\n",
       "  {'gamma': 0.30000000000000004, 'learning_rate': 0.8, 'max_depth': 3},\n",
       "  {'gamma': 0.30000000000000004, 'learning_rate': 0.8, 'max_depth': 5},\n",
       "  {'gamma': 0.30000000000000004, 'learning_rate': 0.8, 'max_depth': 7},\n",
       "  {'gamma': 0.30000000000000004, 'learning_rate': 0.8, 'max_depth': 9},\n",
       "  {'gamma': 0.30000000000000004, 'learning_rate': 0.9, 'max_depth': 3},\n",
       "  {'gamma': 0.30000000000000004, 'learning_rate': 0.9, 'max_depth': 5},\n",
       "  {'gamma': 0.30000000000000004, 'learning_rate': 0.9, 'max_depth': 7},\n",
       "  {'gamma': 0.30000000000000004, 'learning_rate': 0.9, 'max_depth': 9}],\n",
       " 'split0_test_score': array([0.99947472, 0.99973736, 0.99921208, 0.99921208, 0.99947472,\n",
       "        0.99973736, 0.99947472, 0.99947472, 0.99947472, 0.99947472,\n",
       "        0.99947472, 0.99947472, 1.        , 0.99973736, 0.99947472,\n",
       "        0.99947472, 1.        , 0.99947472, 0.99947472, 0.99947472,\n",
       "        1.        , 0.99947472, 0.99947472, 0.99947472, 0.99973736,\n",
       "        0.99947472, 0.99947472, 0.99947472, 1.        , 0.99947472,\n",
       "        0.99947472, 0.99921208, 0.99973753, 0.99947472, 0.99947472,\n",
       "        0.99947472, 0.99947472, 0.99973736, 0.99921208, 0.99921208,\n",
       "        0.99947472, 0.99973736, 0.99921208, 0.99921208, 0.99947472,\n",
       "        0.99947472, 0.99947472, 0.99921208, 0.99973736, 0.99947472,\n",
       "        0.99947472, 0.99921208, 0.99973736, 0.99947472, 0.99947472,\n",
       "        0.99921208, 0.99973736, 0.99947472, 0.99947472, 0.99921208,\n",
       "        0.99973736, 0.99947472, 0.99921208, 0.99921208, 0.99947472,\n",
       "        0.99947472, 0.99921208, 0.99921208, 0.99921225, 0.99947472,\n",
       "        0.99947472, 0.99947472, 0.99973736, 0.99973736, 0.99921208,\n",
       "        0.99921208, 0.99947472, 0.99973736, 0.99921208, 0.99921208,\n",
       "        0.99973736, 0.99947472, 0.99921208, 0.99921208, 0.99973736,\n",
       "        0.99947472, 0.99921208, 0.99921208, 1.        , 0.99947472,\n",
       "        0.99894944, 0.99894944, 0.99947472, 0.99947472, 0.99894961,\n",
       "        0.99947472, 0.99973736, 0.99947472, 0.99868697, 0.99921208,\n",
       "        0.99973736, 0.99947472, 0.99868697, 0.99921208, 0.99947489,\n",
       "        0.99947472, 0.99894961, 0.99947472, 0.99947472, 0.99947472,\n",
       "        0.99921208, 0.99921208, 0.99947472, 0.99947472, 0.99921208,\n",
       "        0.99921208, 0.99947472, 0.99947472, 0.99921208, 0.99921208,\n",
       "        0.99973736, 0.99947472, 0.99921208, 0.99921208, 0.99973736,\n",
       "        0.99947472, 0.99921208, 0.99921208, 0.99947472, 0.99947472,\n",
       "        0.99894961, 0.99894944, 0.99973736, 0.99947472, 0.99894961,\n",
       "        0.99921208, 0.99973736, 0.99947472, 0.99868697, 0.99921208,\n",
       "        0.99921225, 0.99947472, 0.99921225, 0.99921208]),\n",
       " 'split1_test_score': array([1.        , 1.        , 0.99973736, 0.99973736, 1.        ,\n",
       "        1.        , 0.99973736, 0.99973736, 1.        , 1.        ,\n",
       "        0.99973736, 0.99973736, 1.        , 1.        , 0.99973736,\n",
       "        0.99973736, 1.        , 1.        , 0.99973736, 0.99973736,\n",
       "        1.        , 1.        , 0.99973736, 0.99973736, 1.        ,\n",
       "        1.        , 0.99973736, 0.99973736, 1.        , 1.        ,\n",
       "        0.99973736, 0.99973736, 1.        , 1.        , 0.99973736,\n",
       "        0.99973736, 1.        , 1.        , 0.99973736, 0.99973736,\n",
       "        1.        , 1.        , 0.99973736, 0.99973736, 1.        ,\n",
       "        1.        , 0.99973736, 0.99973736, 1.        , 1.        ,\n",
       "        0.99973736, 0.99973736, 1.        , 1.        , 0.99973736,\n",
       "        0.99973736, 1.        , 1.        , 0.99973736, 0.99973736,\n",
       "        1.        , 1.        , 0.99973736, 0.99973736, 1.        ,\n",
       "        0.99973736, 0.99973736, 0.99973736, 1.        , 0.99973736,\n",
       "        0.99973736, 0.99973736, 1.        , 1.        , 0.99973736,\n",
       "        0.99973736, 1.        , 1.        , 0.99973736, 0.99973736,\n",
       "        1.        , 0.99973736, 0.99973736, 0.99973736, 1.        ,\n",
       "        1.        , 0.99973736, 0.99973736, 1.        , 1.        ,\n",
       "        0.99973736, 0.99973736, 1.        , 0.99973736, 0.99973736,\n",
       "        0.99973736, 1.        , 0.99973736, 0.99973736, 0.99973736,\n",
       "        1.        , 0.99973736, 0.99973736, 0.99973736, 1.        ,\n",
       "        0.99973736, 0.99973736, 0.99973736, 1.        , 1.        ,\n",
       "        0.99973736, 0.99973736, 1.        , 1.        , 0.99973736,\n",
       "        0.99973736, 1.        , 0.99973736, 0.99973736, 0.99973736,\n",
       "        1.        , 1.        , 0.99973736, 0.99973736, 1.        ,\n",
       "        0.99973736, 0.99973736, 0.99973736, 1.        , 0.99973736,\n",
       "        0.99973736, 0.99973736, 1.        , 0.99973736, 0.99973736,\n",
       "        0.99973736, 1.        , 0.99973736, 0.99973736, 0.99973736,\n",
       "        1.        , 0.99973736, 0.99973736, 0.99973736]),\n",
       " 'split2_test_score': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.99973719, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.99973719, 1.        , 1.        ]),\n",
       " 'split3_test_score': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.99973736, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.99973736,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split4_test_score': array([0.9992126 , 1.        , 0.9992126 , 0.9992126 , 1.        ,\n",
       "        1.        , 0.9992126 , 0.9992126 , 0.99973753, 0.99973753,\n",
       "        0.9992126 , 0.9992126 , 0.99947506, 0.99947506, 0.9992126 ,\n",
       "        0.9992126 , 1.        , 1.        , 0.9992126 , 0.9992126 ,\n",
       "        1.        , 0.99947506, 0.9992126 , 0.9992126 , 0.99973753,\n",
       "        0.99947506, 0.9992126 , 0.9992126 , 1.        , 1.        ,\n",
       "        0.9992126 , 0.9992126 , 1.        , 1.        , 0.9992126 ,\n",
       "        0.9992126 , 0.9992126 , 1.        , 0.9992126 , 0.9992126 ,\n",
       "        0.99973753, 1.        , 0.9992126 , 0.9992126 , 0.99947506,\n",
       "        1.        , 0.9992126 , 0.9992126 , 0.99973753, 0.99973753,\n",
       "        0.9992126 , 0.9992126 , 1.        , 1.        , 0.9992126 ,\n",
       "        0.9992126 , 1.        , 0.99947506, 0.9992126 , 0.9992126 ,\n",
       "        1.        , 0.99947506, 0.9992126 , 0.9992126 , 1.        ,\n",
       "        1.        , 0.9992126 , 0.9992126 , 1.        , 1.        ,\n",
       "        0.99868732, 0.9992126 , 0.9992126 , 1.        , 0.9992126 ,\n",
       "        0.9992126 , 0.9992126 , 1.        , 0.9992126 , 0.9992126 ,\n",
       "        0.99973753, 0.99973753, 0.9992126 , 0.9992126 , 0.99973753,\n",
       "        0.99947506, 0.9992126 , 0.9992126 , 1.        , 1.        ,\n",
       "        0.9992126 , 0.9992126 , 1.        , 0.99973753, 0.99947506,\n",
       "        0.9992126 , 1.        , 0.99947506, 0.9992126 , 0.9992126 ,\n",
       "        1.        , 1.        , 0.9992126 , 0.9992126 , 1.        ,\n",
       "        0.99973736, 0.99868732, 0.9992126 , 0.9992126 , 1.        ,\n",
       "        0.9992126 , 0.9992126 , 0.9992126 , 1.        , 0.99947506,\n",
       "        0.9992126 , 0.9992126 , 0.99973753, 0.9992126 , 0.9992126 ,\n",
       "        0.99947506, 0.99973753, 0.9992126 , 0.9992126 , 1.        ,\n",
       "        1.        , 0.99973753, 0.9992126 , 1.        , 1.        ,\n",
       "        0.99973753, 0.9992126 , 1.        , 0.99947506, 0.9992126 ,\n",
       "        0.9992126 , 1.        , 0.99973736, 0.9992126 , 0.9992126 ,\n",
       "        1.        , 1.        , 0.99868732, 0.99868732]),\n",
       " 'mean_test_score': array([0.99973746, 0.99994747, 0.99963241, 0.99963241, 0.99989494,\n",
       "        0.99994747, 0.99968494, 0.99968494, 0.99984245, 0.99984245,\n",
       "        0.99968494, 0.99968494, 0.99989501, 0.99984248, 0.99968494,\n",
       "        0.99968494, 1.        , 0.99989494, 0.99968494, 0.99968494,\n",
       "        1.        , 0.99978996, 0.99968494, 0.99968494, 0.99989498,\n",
       "        0.99978996, 0.99968494, 0.99968494, 1.        , 0.99989494,\n",
       "        0.99968494, 0.99963241, 0.99994751, 0.99989494, 0.99968494,\n",
       "        0.99968494, 0.99973746, 0.99994747, 0.99963241, 0.99963241,\n",
       "        0.99984245, 0.99994747, 0.99963241, 0.99963241, 0.99978996,\n",
       "        0.99989494, 0.99968494, 0.99963241, 0.99989498, 0.99984245,\n",
       "        0.99968494, 0.99963241, 0.99994747, 0.99989494, 0.99968494,\n",
       "        0.99963241, 0.99994747, 0.99978996, 0.99968494, 0.99963241,\n",
       "        0.99994747, 0.99978996, 0.99963241, 0.99963241, 0.99989494,\n",
       "        0.99984242, 0.99963241, 0.99963241, 0.99984245, 0.99984242,\n",
       "        0.99957988, 0.99968494, 0.99978999, 0.99994747, 0.99963241,\n",
       "        0.99963241, 0.99973746, 0.99994747, 0.99963241, 0.99963241,\n",
       "        0.99989498, 0.99978992, 0.99963241, 0.99963241, 0.99989498,\n",
       "        0.99978996, 0.99963241, 0.99963241, 1.        , 0.99989494,\n",
       "        0.99957988, 0.99957988, 0.99989494, 0.99978992, 0.99963241,\n",
       "        0.99968494, 0.99994747, 0.99973743, 0.99947486, 0.99963241,\n",
       "        0.99994747, 0.99984242, 0.99952739, 0.99963241, 0.99989498,\n",
       "        0.99973733, 0.99947486, 0.99968494, 0.99973746, 0.99989494,\n",
       "        0.99963241, 0.99963241, 0.99973746, 0.99989494, 0.9996849 ,\n",
       "        0.99963241, 0.99973746, 0.99978992, 0.99963241, 0.99963241,\n",
       "        0.99984249, 0.99984245, 0.99963241, 0.99963241, 0.99994747,\n",
       "        0.99984242, 0.99973739, 0.99963241, 0.99989494, 0.99984242,\n",
       "        0.9996849 , 0.99957988, 0.99994747, 0.99973743, 0.99952739,\n",
       "        0.99963241, 0.99994747, 0.99978989, 0.99952739, 0.99963241,\n",
       "        0.99984245, 0.99978985, 0.99952739, 0.99952735]),\n",
       " 'std_test_score': array([0.00033205, 0.00010506, 0.00035614, 0.00035614, 0.00021011,\n",
       "        0.00010506, 0.00030613, 0.00030613, 0.00021009, 0.00021009,\n",
       "        0.00030613, 0.00030613, 0.00020997, 0.00020999, 0.00030613,\n",
       "        0.00030613, 0.        , 0.00021011, 0.00030613, 0.00030613,\n",
       "        0.        , 0.00025725, 0.00030613, 0.00030613, 0.00012862,\n",
       "        0.00025725, 0.00030613, 0.00030613, 0.        , 0.00021011,\n",
       "        0.00030613, 0.00035614, 0.00010499, 0.00021011, 0.00030613,\n",
       "        0.00030613, 0.00033205, 0.00010506, 0.00035614, 0.00035614,\n",
       "        0.00021009, 0.00010506, 0.00035614, 0.00035614, 0.00025725,\n",
       "        0.00021011, 0.00030613, 0.00035614, 0.00012862, 0.00021009,\n",
       "        0.00030613, 0.00035614, 0.00010506, 0.00021011, 0.00030613,\n",
       "        0.00035614, 0.00010506, 0.00025725, 0.00030613, 0.00035614,\n",
       "        0.00010506, 0.00025725, 0.00035614, 0.00035614, 0.00021011,\n",
       "        0.00021011, 0.00035614, 0.00035614, 0.0003151 , 0.00021011,\n",
       "        0.00048694, 0.00030613, 0.00030609, 0.00010506, 0.00035614,\n",
       "        0.00035614, 0.00033205, 0.00010506, 0.00035614, 0.00035614,\n",
       "        0.00012862, 0.00019653, 0.00035614, 0.00035614, 0.00012862,\n",
       "        0.00025725, 0.00035614, 0.00035614, 0.        , 0.00021011,\n",
       "        0.00042665, 0.00042665, 0.00021011, 0.00019653, 0.000393  ,\n",
       "        0.00030613, 0.00010506, 0.00023484, 0.00046971, 0.00035614,\n",
       "        0.00010506, 0.00021011, 0.00050916, 0.00035614, 0.00021004,\n",
       "        0.00016611, 0.00055074, 0.00030613, 0.00033205, 0.00021011,\n",
       "        0.00035614, 0.00035614, 0.00033205, 0.00021011, 0.00030624,\n",
       "        0.00035614, 0.00033205, 0.00019653, 0.00035614, 0.00035614,\n",
       "        0.00020999, 0.00021009, 0.00035614, 0.00035614, 0.00010506,\n",
       "        0.00021011, 0.00028771, 0.00035614, 0.00021011, 0.00021011,\n",
       "        0.00038594, 0.00042665, 0.00010506, 0.00023484, 0.00038586,\n",
       "        0.00035614, 0.00010506, 0.00019654, 0.00050916, 0.00035614,\n",
       "        0.0003151 , 0.00019655, 0.00050909, 0.00050911]),\n",
       " 'rank_test_score': array([ 64,  14,  99,  99,  26,  14,  74,  74,  42,  42,  74,  74,  20,\n",
       "         39,  74,  74,   1,  26,  74,  74,   1,  53,  74,  74,  21,  53,\n",
       "         74,  74,   1,  26,  74,  99,   5,  26,  74,  74,  64,  14,  99,\n",
       "         99,  42,  14,  99,  99,  53,  26,  74,  99,  21,  42,  74,  99,\n",
       "          6,  26,  74,  99,   6,  53,  74,  99,   6,  53,  99,  99,  26,\n",
       "         47,  99,  99,  40,  47, 134,  74,  52,  14,  99,  99,  64,  14,\n",
       "         99,  99,  25,  59,  99,  99,  21,  53,  99,  99,   1,  26, 135,\n",
       "        135,  26,  59,  98,  74,   6,  70, 144,  99,   6,  47, 140,  99,\n",
       "         24,  73, 143,  74,  64,  26,  99,  99,  64,  26,  97,  99,  64,\n",
       "         59,  99,  99,  38,  42,  99,  99,   6,  47,  72,  99,  26,  47,\n",
       "         96, 135,   6,  70, 138,  99,   6,  62, 140,  99,  40,  63, 138,\n",
       "        142]),\n",
       " 'split0_train_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split1_train_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split2_train_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split3_train_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split4_train_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'mean_train_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'std_train_score': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid Search\n",
    "\n",
    "# Usando um grid completo de todos os parâmetros\n",
    "param_grid = {\"max_depth\": range(3,10,2),\n",
    "              \"learning_rate\": np.arange(0.1,1,0.1),\n",
    "              \"gamma\": np.arange(0,0.4,0.1)}\n",
    "\n",
    "# Executando o Grid Search\n",
    "grid_search = GridSearchCV(modelo6_multi, param_grid = param_grid, return_train_score = True, scoring='f1_macro')\n",
    "start = time.time()\n",
    "grid_search.fit(X_falha_treino, y_falha_treino)\n",
    "\n",
    "print(\"GridSearchCV executou em %.2f segundos para todas as combinações de candidatos a parâmetros do modelo.\"\n",
    "      % (time.time() - start))\n",
    "grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "dd6baf5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 0.0, 'learning_rate': 0.5, 'max_depth': 3}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "3d84f432",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da00bfc7",
   "metadata": {},
   "source": [
    "A primeira tentativa de otimização dos hiperparâmetros, chegamos a 77,66% de F1 Score. Vamos fazer uma segunda otimização de hiperparâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "9bf3a139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV executou em 1874.75 segundos para todas as combinações de candidatos a parâmetros do modelo.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.6378046 , 0.82475739, 0.65942569, 0.76480265, 0.59600387,\n",
       "        0.77120061, 0.57159724, 0.82260065, 0.60000119, 0.76899819,\n",
       "        0.6056035 , 0.74199829, 0.59379764, 0.75039768, 0.55179825,\n",
       "        0.70119791, 0.55579958, 0.82980151, 0.60359893, 0.72480063,\n",
       "        0.57900023, 0.7455946 , 0.57980156, 0.69960375, 0.56540251,\n",
       "        0.820401  , 0.61619601, 0.77401891, 0.62479825, 0.76859727,\n",
       "        0.62899857, 0.78559723, 0.65479922, 0.7969934 , 0.64279652,\n",
       "        0.76799974, 0.58220296, 0.71059899, 0.56259632, 0.73879638,\n",
       "        0.62019911, 0.71140018, 0.60019755, 0.75760322, 0.62459993,\n",
       "        0.75619812, 0.6152019 , 0.71999979, 0.58059745, 0.71460128,\n",
       "        0.57879653, 0.72479887, 0.56259775, 0.73180995, 0.59039946,\n",
       "        0.79100089, 0.60880055, 0.82379794, 0.56859837, 0.72360229,\n",
       "        0.57660017, 0.72619705, 0.57999973, 0.70640016, 0.57000008,\n",
       "        0.71459737, 0.5891993 , 0.75540128, 0.62739849, 0.76220107,\n",
       "        0.58379998, 0.72700338, 0.61979446, 0.80100155, 0.62180252,\n",
       "        0.72960191, 0.57839293, 0.71300144, 0.62879686, 0.74000187,\n",
       "        0.58000131, 0.72419906, 0.55039797, 0.68819871, 0.56599994,\n",
       "        0.73359632, 0.58080001, 0.74480186, 0.56599674, 0.71959863,\n",
       "        0.57359734, 0.69660053, 0.54560037, 0.73219738, 0.56060095,\n",
       "        0.70460119, 0.56520319, 0.71339726, 0.56260247, 0.69499784,\n",
       "        0.62899852, 0.72660017, 0.56979651, 0.78040423, 0.63180013,\n",
       "        0.79199753, 0.58450651, 0.71539555, 0.62259855, 0.74319658,\n",
       "        0.62519922, 0.73719501, 0.63919816, 0.77319202, 0.5843997 ,\n",
       "        0.77079792, 0.62319713, 0.75639615, 0.59519992, 0.80359793,\n",
       "        0.62580051, 0.87579989, 0.64939857, 0.78380208, 0.70579853,\n",
       "        0.71139746, 0.64690733, 0.7821979 , 0.69762578, 0.84120078,\n",
       "        0.60100088, 0.82700176, 0.67880077, 0.91159768, 0.71759982,\n",
       "        0.97710419, 0.75759988, 0.9385972 , 0.69760308, 0.91519966,\n",
       "        0.68999619, 0.9499929 , 0.79380112, 0.82900238, 0.65740447,\n",
       "        0.88220053, 0.68619318, 0.82079916, 0.65180054, 0.81139965,\n",
       "        0.66559973, 0.8171958 , 0.65760126, 0.92860699, 0.66799974,\n",
       "        0.92420387, 0.75719786, 0.82439823, 0.66920295, 0.91700268,\n",
       "        0.69619656, 0.80400052, 0.66479506, 0.83820381, 0.70028939,\n",
       "        0.84528089, 0.71038718, 0.92813888, 0.59830508, 0.71439905,\n",
       "        0.57198853, 0.70860157, 0.58219905, 0.76472478, 0.62939553,\n",
       "        0.82507648, 0.69720764, 0.81601777, 0.60439696, 0.7423986 ,\n",
       "        0.66180329, 0.8526011 , 0.72760243, 1.0690022 , 0.68040299,\n",
       "        0.77899737, 0.66559658, 0.852001  , 0.64659982, 1.06866574,\n",
       "        0.62599773, 0.93416967, 0.78761206, 0.9200613 , 0.62208061,\n",
       "        0.77632322, 0.64310889, 0.90453014, 0.83276916, 0.92917037,\n",
       "        0.62941704, 0.80290408, 0.65049062, 0.84499683, 0.63786197,\n",
       "        0.78512611, 0.77272749, 0.83290162, 0.76015415, 0.94519877,\n",
       "        0.78948317, 0.84610066, 0.63087821, 0.79432425, 0.62809854,\n",
       "        1.00566163, 0.78734694, 0.82640572, 0.63100162, 0.84201741,\n",
       "        0.72680564, 0.9134088 , 0.69873848, 0.94839935, 0.80138912,\n",
       "        0.96875749, 0.64282346, 0.79453816, 0.64636402, 1.02929029,\n",
       "        0.66650958, 0.86722875, 0.79846859, 1.01271992, 0.80640798,\n",
       "        0.92916689, 0.63498139, 0.88940248, 0.6290391 , 0.87159748,\n",
       "        0.66420298, 0.87259998, 0.71500196, 0.79459715, 0.65959864,\n",
       "        0.83627996, 0.63300071, 0.79777212, 0.65619903, 0.81799541,\n",
       "        0.70011425, 0.81659851, 0.47760267, 0.63280358, 0.46339951,\n",
       "        0.59379864, 0.53240018, 0.81240101, 0.54623008, 0.65672898,\n",
       "        0.51742773, 0.62269697, 0.62669182, 0.61934977, 0.56005821,\n",
       "        0.5905633 , 0.53120084, 0.55780072, 0.43239827, 0.53159814,\n",
       "        0.43539491, 0.57659774, 0.56938648, 0.57426925, 0.54101477,\n",
       "        0.67170005, 0.51819715, 0.59160271, 0.48980403, 0.61240144,\n",
       "        0.44059463, 0.61799655, 0.55379925, 0.66940012, 0.45540156,\n",
       "        0.58339992, 0.49760141, 0.55399842, 0.47499933, 0.63919663,\n",
       "        0.43240018, 0.70820255, 0.51099935, 0.60179791, 0.51940041,\n",
       "        0.6360014 , 0.4905931 , 0.62159824, 0.49020104, 0.6811975 ,\n",
       "        0.48320117, 0.81280079, 0.63480229, 0.57019749, 0.43519893,\n",
       "        0.55300231, 0.45319657, 0.59339681, 0.48419833, 0.69519901,\n",
       "        0.61159725, 0.65099773, 0.4913959 , 0.57519884, 0.53579535,\n",
       "        0.61780095, 0.49220109, 0.57920394, 0.52340097, 0.6597959 ,\n",
       "        0.47040005, 0.58700309, 0.47800059, 0.62480006, 0.5127996 ,\n",
       "        0.67599831, 0.49080296, 0.7803997 , 0.57439771, 0.60181856,\n",
       "        0.51686721, 0.61840572, 0.49259925, 0.64620547, 0.50439782,\n",
       "        0.58379798, 0.46379728, 0.59840293, 0.43900156, 0.53760142,\n",
       "        0.45440459, 0.58079925, 0.51019425, 0.62719512, 0.47979703,\n",
       "        0.59120522, 0.46920033, 0.60920129, 0.55879722, 0.67479887,\n",
       "        0.54400105, 0.6790019 , 0.49860373, 0.58400126, 0.56779947,\n",
       "        0.74359832, 0.6185957 , 0.71340094, 0.50700502, 0.66979856,\n",
       "        0.53219914, 0.62519655, 0.50759487, 0.64240026, 0.53839931,\n",
       "        0.6743969 , 0.63160553, 0.64699988, 0.51039891, 0.61219764,\n",
       "        0.48580532, 0.78279781, 0.49459853, 0.63799887, 0.47919598,\n",
       "        0.61059928, 0.47240229, 0.65440006, 0.50320287, 0.63720365,\n",
       "        0.49720106, 0.62219758, 0.49720001, 0.72219906, 0.55159554,\n",
       "        0.63179755, 0.61399884, 0.61339855, 0.51659942, 0.5840023 ,\n",
       "        0.55880318, 0.67280011, 0.49939828, 0.6011981 , 0.47399945,\n",
       "        0.65019999, 0.46459899, 0.56999884, 0.45840111, 0.58339853,\n",
       "        0.47320318, 0.66260033, 0.60300198, 0.69610758, 0.53332543,\n",
       "        0.7571981 , 0.63120275, 0.69718099, 0.51700053, 0.6575964 ,\n",
       "        0.51780009, 0.59240026, 0.47799778, 0.6569984 , 0.56020107,\n",
       "        0.68879614, 0.59280243, 0.717802  , 0.52720146, 0.74000177,\n",
       "        0.53379598, 0.80479226, 0.48320303, 0.55380001, 0.49759798,\n",
       "        0.59540401, 0.47079945, 0.62800083, 0.46779857, 0.65419679,\n",
       "        0.53100214, 0.61959834, 0.47800126, 0.63859754, 0.46239471,\n",
       "        0.55839834, 0.66259885, 0.79167695, 0.69475675, 0.6078074 ,\n",
       "        0.47479901, 0.61691608, 0.52052846, 0.59252014, 0.47773256,\n",
       "        0.73139997, 0.60520172, 0.68579745, 0.50079918, 0.69700422,\n",
       "        0.55359654, 0.69240341, 0.47439718, 0.66400027, 0.61720052,\n",
       "        0.73957911, 0.54188237, 0.6751018 , 0.52446952, 0.59445605,\n",
       "        0.50255671, 0.57882838, 0.46747427, 0.59428091, 0.45700011,\n",
       "        0.58962903, 0.46625714, 0.59929686, 0.45686665, 0.58428211,\n",
       "        0.50311618, 0.56604986, 0.45942874, 0.65052066, 0.57528653,\n",
       "        0.75949268, 0.47874269, 0.60219898, 0.53460031, 0.72419705,\n",
       "        0.48980031, 0.6208015 , 0.52379804, 0.66259761, 0.4846004 ,\n",
       "        0.57399964, 0.48039584, 0.69259577, 0.50420051, 0.69419804,\n",
       "        0.53299923, 0.69259977, 0.53539677, 0.65698314, 0.54939904,\n",
       "        0.69400086, 0.52599769, 0.67300076, 0.58910937, 0.64939861,\n",
       "        0.56619897, 0.72359924, 0.78219852, 0.69408808]),\n",
       " 'std_fit_time': array([0.03813382, 0.05840711, 0.04085613, 0.03250442, 0.03139378,\n",
       "        0.03560433, 0.01580587, 0.06306686, 0.0193187 , 0.03159112,\n",
       "        0.05819481, 0.03048666, 0.02367816, 0.0443415 , 0.00980623,\n",
       "        0.01058878, 0.00968623, 0.10866229, 0.02438625, 0.00936571,\n",
       "        0.01843811, 0.01270901, 0.0281178 , 0.01423183, 0.01908696,\n",
       "        0.05605974, 0.03486682, 0.03912877, 0.01292468, 0.01971475,\n",
       "        0.04096959, 0.03491039, 0.12993085, 0.05672092, 0.03247035,\n",
       "        0.03961299, 0.01292361, 0.01807298, 0.01791563, 0.02363148,\n",
       "        0.02956598, 0.01202561, 0.01519825, 0.03184291, 0.01469455,\n",
       "        0.03174361, 0.04316408, 0.01908767, 0.01600833, 0.02682297,\n",
       "        0.02148162, 0.02428714, 0.01227186, 0.02524348, 0.01565243,\n",
       "        0.01972512, 0.02990451, 0.04087392, 0.00520455, 0.02098131,\n",
       "        0.02059487, 0.02214651, 0.0286585 , 0.02876454, 0.02350304,\n",
       "        0.01613004, 0.01551115, 0.03352595, 0.03268676, 0.0232042 ,\n",
       "        0.0088405 , 0.01069658, 0.04297957, 0.03921738, 0.02373193,\n",
       "        0.02782729, 0.01177059, 0.01460185, 0.04825976, 0.00892309,\n",
       "        0.01006097, 0.03015628, 0.01465191, 0.00893036, 0.04834763,\n",
       "        0.02981559, 0.04039737, 0.03919748, 0.01896606, 0.02760132,\n",
       "        0.0199891 , 0.0136627 , 0.00458669, 0.03955483, 0.01861797,\n",
       "        0.01937978, 0.01013027, 0.01139522, 0.00708506, 0.01440529,\n",
       "        0.05133416, 0.01635361, 0.01123178, 0.04797423, 0.04349638,\n",
       "        0.06051438, 0.01343956, 0.0114276 , 0.05844742, 0.0130587 ,\n",
       "        0.02886558, 0.02919622, 0.0332838 , 0.0506349 , 0.01913795,\n",
       "        0.03129957, 0.03730357, 0.00775897, 0.02269339, 0.094428  ,\n",
       "        0.01358795, 0.10239265, 0.04164431, 0.03734034, 0.05986134,\n",
       "        0.01112565, 0.03888541, 0.0127176 , 0.02864273, 0.0598871 ,\n",
       "        0.01115393, 0.04417093, 0.04426671, 0.07005492, 0.05790628,\n",
       "        0.16327833, 0.05419237, 0.04296249, 0.04042992, 0.11792769,\n",
       "        0.02590539, 0.07110646, 0.09944625, 0.01588695, 0.03423948,\n",
       "        0.0533202 , 0.03636276, 0.02193831, 0.01213705, 0.00895775,\n",
       "        0.01875601, 0.00913213, 0.02096487, 0.10087516, 0.01411117,\n",
       "        0.07910515, 0.07294435, 0.03152644, 0.01779899, 0.060838  ,\n",
       "        0.05975046, 0.00447196, 0.00194094, 0.04640139, 0.05188521,\n",
       "        0.07148213, 0.04511663, 0.07807085, 0.01540616, 0.00463432,\n",
       "        0.01097875, 0.0176701 , 0.01821404, 0.05008086, 0.02619523,\n",
       "        0.03972367, 0.02731775, 0.05011922, 0.00722676, 0.031911  ,\n",
       "        0.03624864, 0.04588618, 0.08025089, 0.11056984, 0.02993419,\n",
       "        0.04219086, 0.0482681 , 0.04873624, 0.02441819, 0.14096555,\n",
       "        0.01917231, 0.12120687, 0.02023319, 0.09437455, 0.00581696,\n",
       "        0.00633461, 0.03934665, 0.15347441, 0.03904817, 0.11135536,\n",
       "        0.00392721, 0.03195869, 0.01899292, 0.04857203, 0.02048937,\n",
       "        0.00702015, 0.06953429, 0.0899017 , 0.01564348, 0.01278429,\n",
       "        0.15061865, 0.11852318, 0.00708042, 0.01047675, 0.00531827,\n",
       "        0.07518587, 0.04829032, 0.04544592, 0.03992088, 0.04384767,\n",
       "        0.11698569, 0.08743814, 0.04854036, 0.12071059, 0.05696768,\n",
       "        0.1032865 , 0.00639367, 0.01118308, 0.04007135, 0.11598204,\n",
       "        0.02337403, 0.04769602, 0.11855549, 0.06373944, 0.0682831 ,\n",
       "        0.08365824, 0.00495967, 0.0602334 , 0.04114209, 0.04862751,\n",
       "        0.04542209, 0.06412676, 0.01688739, 0.03632481, 0.0559707 ,\n",
       "        0.07949886, 0.02383024, 0.01947013, 0.02987658, 0.01944168,\n",
       "        0.02440182, 0.05292623, 0.04650457, 0.08198095, 0.03041469,\n",
       "        0.05031634, 0.08654324, 0.2113074 , 0.10694181, 0.04306536,\n",
       "        0.02322267, 0.05395231, 0.06024516, 0.07656507, 0.14963255,\n",
       "        0.03468324, 0.07878204, 0.03566983, 0.01996481, 0.00653027,\n",
       "        0.01417975, 0.03089634, 0.08673074, 0.00971401, 0.1002208 ,\n",
       "        0.06841676, 0.0656875 , 0.03262273, 0.04094966, 0.07862427,\n",
       "        0.00757683, 0.04722114, 0.17742365, 0.11378944, 0.02153575,\n",
       "        0.04804959, 0.05139211, 0.00623201, 0.02368769, 0.05963043,\n",
       "        0.00445409, 0.10440356, 0.08596214, 0.04895524, 0.04311181,\n",
       "        0.03152698, 0.02323401, 0.02224749, 0.01380219, 0.11632812,\n",
       "        0.03346461, 0.08487676, 0.12058026, 0.02482307, 0.0099857 ,\n",
       "        0.01048699, 0.0160437 , 0.04406832, 0.0226407 , 0.08138452,\n",
       "        0.05326672, 0.03420354, 0.02444932, 0.01565367, 0.04519505,\n",
       "        0.05038159, 0.04727286, 0.02164445, 0.02525473, 0.05448176,\n",
       "        0.01012745, 0.01257263, 0.0224872 , 0.05574006, 0.02754805,\n",
       "        0.04981286, 0.02542647, 0.1789894 , 0.08334006, 0.02190392,\n",
       "        0.04188717, 0.02444541, 0.01201086, 0.04545091, 0.02911339,\n",
       "        0.01543161, 0.0162254 , 0.0385263 , 0.01067615, 0.01379508,\n",
       "        0.00778538, 0.01704054, 0.01882902, 0.02260744, 0.01471372,\n",
       "        0.0203215 , 0.01179084, 0.04554019, 0.05110296, 0.04664753,\n",
       "        0.02547092, 0.0681081 , 0.03485308, 0.01680282, 0.05139988,\n",
       "        0.15028048, 0.16542039, 0.06017874, 0.02170622, 0.03476568,\n",
       "        0.04890503, 0.03813776, 0.04297011, 0.03794777, 0.03830273,\n",
       "        0.05280362, 0.09489851, 0.01729581, 0.02788165, 0.00888519,\n",
       "        0.00825836, 0.07665328, 0.03308478, 0.0308799 , 0.01357027,\n",
       "        0.02439918, 0.00840346, 0.05438842, 0.01238165, 0.02894321,\n",
       "        0.01100041, 0.01284433, 0.01295251, 0.06764763, 0.03709501,\n",
       "        0.03602057, 0.14669219, 0.02595375, 0.02595957, 0.00734932,\n",
       "        0.04269021, 0.05637485, 0.02170072, 0.01116001, 0.00969232,\n",
       "        0.05704001, 0.00515983, 0.00874098, 0.01070995, 0.01474553,\n",
       "        0.02155689, 0.03184036, 0.04890992, 0.04012932, 0.0263268 ,\n",
       "        0.07146011, 0.04048371, 0.05988612, 0.02020605, 0.04399536,\n",
       "        0.0407166 , 0.00595404, 0.00912255, 0.07850496, 0.05359838,\n",
       "        0.05288873, 0.04900808, 0.03052446, 0.03382349, 0.11292383,\n",
       "        0.0589531 , 0.13067208, 0.04329189, 0.02295757, 0.05120746,\n",
       "        0.03520591, 0.02164803, 0.02886797, 0.01739247, 0.09843873,\n",
       "        0.0502574 , 0.04863577, 0.04963748, 0.10647442, 0.01762586,\n",
       "        0.02438557, 0.09843394, 0.16738954, 0.03264018, 0.01567909,\n",
       "        0.00661133, 0.03847478, 0.03548201, 0.00427861, 0.01891876,\n",
       "        0.1237674 , 0.07227635, 0.10270856, 0.04541971, 0.06591175,\n",
       "        0.03007275, 0.08264243, 0.01000964, 0.10984598, 0.05987054,\n",
       "        0.03892328, 0.02129488, 0.03043923, 0.02411953, 0.0382947 ,\n",
       "        0.0407185 , 0.0114705 , 0.0152645 , 0.01752068, 0.00340485,\n",
       "        0.01384995, 0.00725297, 0.01885187, 0.00976877, 0.00918706,\n",
       "        0.03913695, 0.01105785, 0.01622058, 0.0458334 , 0.02402955,\n",
       "        0.05263927, 0.01779854, 0.01010965, 0.05490532, 0.07374768,\n",
       "        0.02778867, 0.02650045, 0.03851736, 0.03675568, 0.03404446,\n",
       "        0.00718367, 0.00412772, 0.11594623, 0.01768   , 0.07284119,\n",
       "        0.01953792, 0.0278035 , 0.04476633, 0.01877288, 0.04115323,\n",
       "        0.057082  , 0.0197726 , 0.07852813, 0.07320047, 0.02234625,\n",
       "        0.03822346, 0.06820153, 0.12278144, 0.04024471]),\n",
       " 'mean_score_time': array([0.03819251, 0.04880271, 0.03780031, 0.04539762, 0.03699651,\n",
       "        0.04840078, 0.03439913, 0.04460135, 0.03620043, 0.04339852,\n",
       "        0.03539739, 0.04499998, 0.03640127, 0.0445982 , 0.03619895,\n",
       "        0.04660206, 0.03679557, 0.0489994 , 0.03639932, 0.04499793,\n",
       "        0.03660054, 0.04420156, 0.0360002 , 0.0449976 , 0.0351995 ,\n",
       "        0.04839988, 0.03719773, 0.04540138, 0.03580136, 0.04759812,\n",
       "        0.03699856, 0.04900174, 0.03899674, 0.04560332, 0.03640318,\n",
       "        0.04979997, 0.03919954, 0.04480081, 0.0366015 , 0.04600463,\n",
       "        0.03559823, 0.04440522, 0.03720422, 0.04479804, 0.04060302,\n",
       "        0.04479952, 0.036799  , 0.0447998 , 0.03620329, 0.0458004 ,\n",
       "        0.03599949, 0.04500222, 0.03519998, 0.04490361, 0.0358016 ,\n",
       "        0.05019741, 0.03620024, 0.04619966, 0.03599782, 0.04419756,\n",
       "        0.03720026, 0.04460201, 0.03640199, 0.04640079, 0.03679996,\n",
       "        0.04499927, 0.03560162, 0.0457983 , 0.03619981, 0.04419718,\n",
       "        0.03660178, 0.0463975 , 0.0368011 , 0.04799924, 0.0363986 ,\n",
       "        0.04619918, 0.03700304, 0.04519615, 0.03720255, 0.04700036,\n",
       "        0.03579731, 0.0452004 , 0.0349998 , 0.04520235, 0.03459964,\n",
       "        0.04320297, 0.03740125, 0.0449985 , 0.03679967, 0.04560103,\n",
       "        0.03660278, 0.04340057, 0.03539953, 0.04479976, 0.03559871,\n",
       "        0.0444025 , 0.03639946, 0.04459901, 0.03699603, 0.10000362,\n",
       "        0.03680143, 0.0438005 , 0.0360003 , 0.05419602, 0.03780074,\n",
       "        0.04440012, 0.03560033, 0.04280076, 0.03679724, 0.04519882,\n",
       "        0.03620005, 0.04560094, 0.03699942, 0.0484005 , 0.03540211,\n",
       "        0.04400196, 0.03819938, 0.04480214, 0.0364006 , 0.04780293,\n",
       "        0.0372025 , 0.04919863, 0.03860173, 0.04799938, 0.04160023,\n",
       "        0.04439988, 0.03660088, 0.04600043, 0.04200215, 0.04680014,\n",
       "        0.03820071, 0.04679809, 0.03759985, 0.04680257, 0.04499936,\n",
       "        0.05159941, 0.04640083, 0.04679785, 0.03879862, 0.05059814,\n",
       "        0.03800497, 0.05380278, 0.04139705, 0.04959927, 0.0392036 ,\n",
       "        0.04719996, 0.03640027, 0.04699931, 0.03740172, 0.04620104,\n",
       "        0.03759913, 0.04560256, 0.0365983 , 0.04799433, 0.03839889,\n",
       "        0.05339785, 0.04159818, 0.04640098, 0.04059753, 0.04999919,\n",
       "        0.0441999 , 0.04640055, 0.03679919, 0.04899964, 0.04140496,\n",
       "        0.04930167, 0.03765545, 0.0497992 , 0.03679566, 0.04440098,\n",
       "        0.03560205, 0.04479928, 0.0368031 , 0.04460316, 0.03560429,\n",
       "        0.04985533, 0.04090986, 0.04520268, 0.0362021 , 0.0446012 ,\n",
       "        0.03639922, 0.04979925, 0.0484005 , 0.06899595, 0.03880353,\n",
       "        0.05179949, 0.03860297, 0.04899912, 0.03580227, 0.05500255,\n",
       "        0.03780222, 0.05100365, 0.04440327, 0.04780011, 0.03679948,\n",
       "        0.04724402, 0.04320593, 0.0532002 , 0.04403114, 0.04839997,\n",
       "        0.03920484, 0.04522438, 0.0396174 , 0.05100012, 0.03838282,\n",
       "        0.04680862, 0.04459572, 0.04741201, 0.04200182, 0.05060878,\n",
       "        0.04760423, 0.04600425, 0.08643999, 0.04721761, 0.03680558,\n",
       "        0.05840192, 0.03900752, 0.05019889, 0.03779874, 0.04939933,\n",
       "        0.04019847, 0.04859858, 0.03880177, 0.04931316, 0.04479942,\n",
       "        0.05339518, 0.03820524, 0.04801712, 0.03920679, 0.0574245 ,\n",
       "        0.03940277, 0.04880471, 0.05037322, 0.06399813, 0.05759921,\n",
       "        0.06139627, 0.04020181, 0.04979782, 0.03859897, 0.04600186,\n",
       "        0.03839812, 0.0559967 , 0.04119787, 0.04519739, 0.03660145,\n",
       "        0.04939799, 0.03840227, 0.04600205, 0.04020114, 0.04520135,\n",
       "        0.03859735, 0.04519973, 0.03819623, 0.04719625, 0.03619537,\n",
       "        0.04919853, 0.04000502, 0.06219974, 0.04038372, 0.04740939,\n",
       "        0.03564115, 0.05120897, 0.05079803, 0.05200953, 0.03880625,\n",
       "        0.04721441, 0.0429987 , 0.04419909, 0.03519993, 0.04400191,\n",
       "        0.03700495, 0.04940166, 0.04040098, 0.04980159, 0.04460444,\n",
       "        0.048     , 0.04139857, 0.045401  , 0.03680024, 0.04740081,\n",
       "        0.03620048, 0.04639964, 0.04139748, 0.04979858, 0.03660078,\n",
       "        0.05139852, 0.03799672, 0.0450016 , 0.03740077, 0.04659801,\n",
       "        0.03660264, 0.05539994, 0.03759708, 0.04480095, 0.03720169,\n",
       "        0.04740143, 0.03679962, 0.04859977, 0.03799791, 0.04780488,\n",
       "        0.04260149, 0.06320047, 0.06760135, 0.04480362, 0.03539939,\n",
       "        0.04519725, 0.03680129, 0.04340048, 0.03779993, 0.04940448,\n",
       "        0.0430028 , 0.04599948, 0.03800397, 0.04559903, 0.08739972,\n",
       "        0.04599791, 0.03699775, 0.04600091, 0.04099898, 0.05060349,\n",
       "        0.03799887, 0.04540129, 0.03759894, 0.04559951, 0.04079847,\n",
       "        0.05940003, 0.03859944, 0.06140261, 0.04359674, 0.04720569,\n",
       "        0.03799124, 0.04719501, 0.03719954, 0.04659534, 0.03579946,\n",
       "        0.04480052, 0.03719859, 0.04919882, 0.03680253, 0.04439859,\n",
       "        0.03639989, 0.04699965, 0.03740087, 0.04620109, 0.0359992 ,\n",
       "        0.04479671, 0.03619885, 0.0442039 , 0.0385963 , 0.04960179,\n",
       "        0.03919802, 0.0459991 , 0.03619852, 0.04599934, 0.04220028,\n",
       "        0.05219769, 0.04440093, 0.04660263, 0.03759942, 0.04780297,\n",
       "        0.03759832, 0.04820094, 0.03719721, 0.04639759, 0.03879929,\n",
       "        0.05360255, 0.03779697, 0.04780016, 0.03619766, 0.04540148,\n",
       "        0.03659554, 0.0488019 , 0.03720179, 0.04539857, 0.03799949,\n",
       "        0.04519944, 0.03699956, 0.04740047, 0.03659954, 0.04579644,\n",
       "        0.036198  , 0.04680467, 0.03679886, 0.05360093, 0.03660216,\n",
       "        0.04720402, 0.03960061, 0.04559956, 0.04400239, 0.04699941,\n",
       "        0.03759713, 0.0580009 , 0.03659873, 0.04480243, 0.03539929,\n",
       "        0.04519978, 0.03660011, 0.04440093, 0.03620048, 0.04679933,\n",
       "        0.03759699, 0.0492012 , 0.0383997 , 0.0509974 , 0.03699827,\n",
       "        0.04620113, 0.04659815, 0.04839854, 0.03759952, 0.04679856,\n",
       "        0.0379992 , 0.04659867, 0.0372014 , 0.04799867, 0.04239678,\n",
       "        0.04619961, 0.04120007, 0.05140176, 0.03700085, 0.04599724,\n",
       "        0.04440179, 0.05720329, 0.03679705, 0.04640188, 0.0386014 ,\n",
       "        0.04799786, 0.0364007 , 0.04539986, 0.03820677, 0.04620109,\n",
       "        0.03719687, 0.04620018, 0.03600016, 0.04780126, 0.03640227,\n",
       "        0.04940333, 0.04359937, 0.05240431, 0.05219755, 0.04459729,\n",
       "        0.03740096, 0.04540005, 0.03879771, 0.04500494, 0.03660178,\n",
       "        0.05019984, 0.04800053, 0.05360193, 0.03719845, 0.04980135,\n",
       "        0.03700171, 0.04979496, 0.0372025 , 0.0497993 , 0.04079933,\n",
       "        0.0482275 , 0.03699331, 0.0534059 , 0.03844175, 0.0454319 ,\n",
       "        0.03540235, 0.04660716, 0.08361726, 0.04339952, 0.03480058,\n",
       "        0.04399943, 0.03580637, 0.04460812, 0.03699965, 0.04560542,\n",
       "        0.03720293, 0.04519792, 0.03722744, 0.05420389, 0.03720217,\n",
       "        0.05137854, 0.03660302, 0.04420123, 0.03860078, 0.05760422,\n",
       "        0.0376008 , 0.04719958, 0.03840137, 0.04560022, 0.03840113,\n",
       "        0.04619918, 0.03620057, 0.04619913, 0.0369988 , 0.05200362,\n",
       "        0.03639984, 0.0463995 , 0.03719759, 0.04580011, 0.03760018,\n",
       "        0.04599514, 0.03740506, 0.04699883, 0.04199891, 0.0455976 ,\n",
       "        0.03839736, 0.06600041, 0.05417156, 0.04700308]),\n",
       " 'std_score_time': array([0.0039725 , 0.00278819, 0.00312416, 0.00149908, 0.00141546,\n",
       "        0.00534907, 0.00048834, 0.00149711, 0.00146743, 0.0019596 ,\n",
       "        0.00101629, 0.00167047, 0.00049398, 0.00162168, 0.00193594,\n",
       "        0.00265501, 0.00132741, 0.00501707, 0.00135667, 0.00167563,\n",
       "        0.00135795, 0.00116349, 0.00209774, 0.00141915, 0.00097776,\n",
       "        0.00338577, 0.00147011, 0.00206018, 0.00040268, 0.00241386,\n",
       "        0.00141448, 0.00596491, 0.00252813, 0.00185433, 0.0013575 ,\n",
       "        0.00754718, 0.00160259, 0.00160006, 0.00101963, 0.00283052,\n",
       "        0.00079761, 0.00079758, 0.00116398, 0.00098054, 0.00773802,\n",
       "        0.00160113, 0.00159825, 0.00097699, 0.00097887, 0.00160121,\n",
       "        0.0015496 , 0.00141662, 0.00039967, 0.00284226, 0.00075042,\n",
       "        0.00560011, 0.00172054, 0.00116511, 0.00089234, 0.00116623,\n",
       "        0.00159749, 0.00185567, 0.00101881, 0.00332332, 0.00263801,\n",
       "        0.00209844, 0.00080174, 0.00331415, 0.00147338, 0.00039585,\n",
       "        0.00185768, 0.0017424 , 0.00147092, 0.00126423, 0.00101622,\n",
       "        0.00097673, 0.0014159 , 0.00193683, 0.00146966, 0.00424075,\n",
       "        0.00074736, 0.00204048, 0.0010958 , 0.00248269, 0.00048967,\n",
       "        0.00074914, 0.00079952, 0.00227801, 0.00203785, 0.00162547,\n",
       "        0.00294332, 0.00135907, 0.00195946, 0.0020404 , 0.00135517,\n",
       "        0.00205905, 0.0017441 , 0.00205782, 0.00167041, 0.09394053,\n",
       "        0.00193756, 0.00116821, 0.00089447, 0.01641887, 0.00256247,\n",
       "        0.00080096, 0.00135491, 0.00074708, 0.00132608, 0.00074797,\n",
       "        0.0019389 , 0.0013579 , 0.0025244 , 0.00688449, 0.00102047,\n",
       "        0.00109498, 0.00074688, 0.00132611, 0.00135721, 0.00183526,\n",
       "        0.00074989, 0.00636864, 0.00215522, 0.00340715, 0.01020905,\n",
       "        0.00224341, 0.00119879, 0.00167032, 0.00867336, 0.00278826,\n",
       "        0.00193668, 0.00097901, 0.00080531, 0.0014686 , 0.01322182,\n",
       "        0.00872757, 0.00862016, 0.00194005, 0.00426405, 0.00873412,\n",
       "        0.00155109, 0.0087049 , 0.00574772, 0.00427608, 0.00342964,\n",
       "        0.00147299, 0.00048827, 0.0045602 , 0.00185613, 0.00159994,\n",
       "        0.00326163, 0.00079996, 0.0013543 , 0.0024432 , 0.00287255,\n",
       "        0.01070582, 0.00589049, 0.00174416, 0.005819  , 0.00569403,\n",
       "        0.01343493, 0.00135863, 0.00074438, 0.00701324, 0.00683272,\n",
       "        0.00360851, 0.00127301, 0.00278469, 0.00116685, 0.00174343,\n",
       "        0.00080053, 0.00204001, 0.0019412 , 0.00120321, 0.00081144,\n",
       "        0.006026  , 0.00379606, 0.00213417, 0.0007495 , 0.00102021,\n",
       "        0.00102379, 0.00354361, 0.00854883, 0.01172962, 0.00348183,\n",
       "        0.0126259 , 0.00300107, 0.00260936, 0.00074488, 0.00536039,\n",
       "        0.00248471, 0.0023743 , 0.00534712, 0.00286112, 0.00116766,\n",
       "        0.00192594, 0.00770151, 0.0070566 , 0.00188915, 0.00233505,\n",
       "        0.00639964, 0.00212955, 0.00164312, 0.00551441, 0.00257323,\n",
       "        0.00318355, 0.00206073, 0.00206882, 0.00218819, 0.0017502 ,\n",
       "        0.00661891, 0.00109594, 0.09937855, 0.00147745, 0.00146981,\n",
       "        0.00804207, 0.00274821, 0.00396924, 0.00172264, 0.00403155,\n",
       "        0.00312419, 0.00344104, 0.00278543, 0.00633919, 0.00640006,\n",
       "        0.00546016, 0.00116507, 0.00108468, 0.0023104 , 0.0096429 ,\n",
       "        0.00196042, 0.00160066, 0.01273397, 0.01251021, 0.02801104,\n",
       "        0.01749806, 0.00324409, 0.01159892, 0.00431599, 0.0020976 ,\n",
       "        0.00393043, 0.01311467, 0.00646023, 0.00146661, 0.0010235 ,\n",
       "        0.00679663, 0.00250024, 0.00189702, 0.00746625, 0.00116249,\n",
       "        0.00174921, 0.00240025, 0.00193488, 0.00231287, 0.00116784,\n",
       "        0.00849462, 0.00328528, 0.02241895, 0.00406006, 0.00232888,\n",
       "        0.00096104, 0.008076  , 0.01925172, 0.00597264, 0.00247842,\n",
       "        0.00364928, 0.01108068, 0.00146964, 0.00074838, 0.00109715,\n",
       "        0.00189741, 0.00854724, 0.00571551, 0.00519074, 0.01143423,\n",
       "        0.00384868, 0.00659098, 0.00135893, 0.00116669, 0.00233725,\n",
       "        0.00147105, 0.00149608, 0.00796445, 0.00869864, 0.00162108,\n",
       "        0.00933234, 0.00126528, 0.0022815 , 0.00206027, 0.00119962,\n",
       "        0.00185365, 0.01116538, 0.00135653, 0.00147149, 0.00132701,\n",
       "        0.00185655, 0.00194003, 0.00135495, 0.00228025, 0.0028558 ,\n",
       "        0.00783555, 0.01404517, 0.0308363 , 0.00098395, 0.00048924,\n",
       "        0.00160116, 0.00213655, 0.00048905, 0.00231678, 0.0061561 ,\n",
       "        0.00918458, 0.00357741, 0.00296889, 0.00162759, 0.09981588,\n",
       "        0.00219071, 0.0026051 , 0.00218693, 0.00399913, 0.00567762,\n",
       "        0.00404834, 0.00162172, 0.00162443, 0.00205716, 0.0049994 ,\n",
       "        0.02411781, 0.00265285, 0.01639982, 0.0082602 , 0.00320036,\n",
       "        0.00165907, 0.00231055, 0.00193892, 0.00135357, 0.00039754,\n",
       "        0.00116843, 0.00097917, 0.00507705, 0.00146906, 0.00173977,\n",
       "        0.00079904, 0.00167309, 0.00206152, 0.00386851, 0.00252783,\n",
       "        0.00222603, 0.00097753, 0.00116775, 0.00080189, 0.00338386,\n",
       "        0.0030544 , 0.0010993 , 0.00074824, 0.00155096, 0.00846773,\n",
       "        0.00818359, 0.01290451, 0.00232938, 0.00119944, 0.00549352,\n",
       "        0.00195772, 0.00461482, 0.00172141, 0.00135563, 0.0039182 ,\n",
       "        0.01294279, 0.00147386, 0.00292611, 0.00160003, 0.00149793,\n",
       "        0.00079582, 0.00203965, 0.00213732, 0.001745  , 0.00141455,\n",
       "        0.00193809, 0.00126324, 0.00205801, 0.00079973, 0.00074885,\n",
       "        0.00147083, 0.00204032, 0.001719  , 0.0111485 , 0.00120029,\n",
       "        0.00160191, 0.00431983, 0.00215376, 0.01253821, 0.00089448,\n",
       "        0.0016226 , 0.02355283, 0.0010177 , 0.00116794, 0.00048768,\n",
       "        0.00171979, 0.00162467, 0.001201  , 0.00116272, 0.00146908,\n",
       "        0.00149479, 0.00292075, 0.00102409, 0.01253863, 0.00089337,\n",
       "        0.0018342 , 0.00747301, 0.00150124, 0.00185438, 0.00325156,\n",
       "        0.00362963, 0.0021554 , 0.00147059, 0.00209622, 0.00646515,\n",
       "        0.00213508, 0.00256154, 0.00320341, 0.00109559, 0.0017914 ,\n",
       "        0.00628446, 0.00652027, 0.00146995, 0.00280302, 0.00313644,\n",
       "        0.00210204, 0.00102054, 0.00300973, 0.00325215, 0.00147058,\n",
       "        0.00193814, 0.00172063, 0.00089571, 0.00767875, 0.00102243,\n",
       "        0.00900427, 0.0103063 , 0.00872942, 0.00725208, 0.00119596,\n",
       "        0.00162238, 0.00174248, 0.00664747, 0.001794  , 0.00135866,\n",
       "        0.00652685, 0.0088796 , 0.01221016, 0.0013265 , 0.00604863,\n",
       "        0.00253047, 0.00881722, 0.00222592, 0.01161688, 0.00556334,\n",
       "        0.00327987, 0.00125526, 0.01682659, 0.00149149, 0.00118457,\n",
       "        0.00049083, 0.00049442, 0.09522235, 0.00048735, 0.00040082,\n",
       "        0.00109215, 0.00075292, 0.00185625, 0.00181823, 0.00162724,\n",
       "        0.0022276 , 0.00193804, 0.00261696, 0.01174864, 0.00160221,\n",
       "        0.0033167 , 0.00205939, 0.00146921, 0.00338368, 0.01465032,\n",
       "        0.00241818, 0.00172365, 0.00195992, 0.00149667, 0.00631432,\n",
       "        0.00278776, 0.00159922, 0.00159895, 0.00141469, 0.0073471 ,\n",
       "        0.00048629, 0.00162757, 0.00074853, 0.00193772, 0.00174189,\n",
       "        0.00141816, 0.00102094, 0.00126019, 0.00460673, 0.00185549,\n",
       "        0.00349524, 0.02343273, 0.01459265, 0.00252987]),\n",
       " 'param_bootstrap': masked_array(data=[True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 3, 3, 3, 3, 3, 3,\n",
       "                    3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 3, 3, 3, 3, 3, 3,\n",
       "                    3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_features': masked_array(data=['sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2',\n",
       "                    'log2', 'log2', 'log2', 'log2', 'log2', 'sqrt', 'sqrt',\n",
       "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2', 'log2', 'log2',\n",
       "                    'log2', 'log2', 'log2', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
       "                    'sqrt', 'sqrt', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
       "                    'log2', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
       "                    'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'sqrt',\n",
       "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2', 'log2',\n",
       "                    'log2', 'log2', 'log2', 'log2', 'sqrt', 'sqrt', 'sqrt',\n",
       "                    'sqrt', 'sqrt', 'sqrt', 'log2', 'log2', 'log2', 'log2',\n",
       "                    'log2', 'log2', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
       "                    'sqrt', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
       "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2',\n",
       "                    'log2', 'log2', 'log2', 'log2', 'log2', 'sqrt', 'sqrt',\n",
       "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2', 'log2', 'log2',\n",
       "                    'log2', 'log2', 'log2', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
       "                    'sqrt', 'sqrt', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
       "                    'log2', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
       "                    'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'sqrt',\n",
       "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2', 'log2',\n",
       "                    'log2', 'log2', 'log2', 'log2', 'sqrt', 'sqrt', 'sqrt',\n",
       "                    'sqrt', 'sqrt', 'sqrt', 'log2', 'log2', 'log2', 'log2',\n",
       "                    'log2', 'log2', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
       "                    'sqrt', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
       "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2',\n",
       "                    'log2', 'log2', 'log2', 'log2', 'log2', 'sqrt', 'sqrt',\n",
       "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2', 'log2', 'log2',\n",
       "                    'log2', 'log2', 'log2', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
       "                    'sqrt', 'sqrt', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
       "                    'log2', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
       "                    'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'sqrt',\n",
       "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2', 'log2',\n",
       "                    'log2', 'log2', 'log2', 'log2', 'sqrt', 'sqrt', 'sqrt',\n",
       "                    'sqrt', 'sqrt', 'sqrt', 'log2', 'log2', 'log2', 'log2',\n",
       "                    'log2', 'log2', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
       "                    'sqrt', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
       "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2',\n",
       "                    'log2', 'log2', 'log2', 'log2', 'log2', 'sqrt', 'sqrt',\n",
       "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2', 'log2', 'log2',\n",
       "                    'log2', 'log2', 'log2', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
       "                    'sqrt', 'sqrt', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
       "                    'log2', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
       "                    'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'sqrt',\n",
       "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2', 'log2',\n",
       "                    'log2', 'log2', 'log2', 'log2', 'sqrt', 'sqrt', 'sqrt',\n",
       "                    'sqrt', 'sqrt', 'sqrt', 'log2', 'log2', 'log2', 'log2',\n",
       "                    'log2', 'log2', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
       "                    'sqrt', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
       "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2',\n",
       "                    'log2', 'log2', 'log2', 'log2', 'log2', 'sqrt', 'sqrt',\n",
       "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2', 'log2', 'log2',\n",
       "                    'log2', 'log2', 'log2', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
       "                    'sqrt', 'sqrt', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
       "                    'log2', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
       "                    'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'sqrt',\n",
       "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2', 'log2',\n",
       "                    'log2', 'log2', 'log2', 'log2', 'sqrt', 'sqrt', 'sqrt',\n",
       "                    'sqrt', 'sqrt', 'sqrt', 'log2', 'log2', 'log2', 'log2',\n",
       "                    'log2', 'log2', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
       "                    'sqrt', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
       "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2',\n",
       "                    'log2', 'log2', 'log2', 'log2', 'log2', 'sqrt', 'sqrt',\n",
       "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2', 'log2', 'log2',\n",
       "                    'log2', 'log2', 'log2', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
       "                    'sqrt', 'sqrt', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
       "                    'log2', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
       "                    'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'sqrt',\n",
       "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2', 'log2',\n",
       "                    'log2', 'log2', 'log2', 'log2', 'sqrt', 'sqrt', 'sqrt',\n",
       "                    'sqrt', 'sqrt', 'sqrt', 'log2', 'log2', 'log2', 'log2',\n",
       "                    'log2', 'log2', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
       "                    'sqrt', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_split': masked_array(data=[1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3,\n",
       "                    1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3,\n",
       "                    1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3,\n",
       "                    1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3,\n",
       "                    1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3,\n",
       "                    1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3,\n",
       "                    1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3,\n",
       "                    1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3,\n",
       "                    1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3,\n",
       "                    1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3,\n",
       "                    1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3,\n",
       "                    1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3,\n",
       "                    1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3,\n",
       "                    1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3,\n",
       "                    1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3,\n",
       "                    1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3,\n",
       "                    1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3,\n",
       "                    1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3,\n",
       "                    1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3,\n",
       "                    1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3,\n",
       "                    1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3,\n",
       "                    1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3,\n",
       "                    1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3,\n",
       "                    1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3,\n",
       "                    1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3,\n",
       "                    1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3,\n",
       "                    1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3,\n",
       "                    1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[400, 500, 400, 500, 400, 500, 400, 500, 400, 500, 400,\n",
       "                    500, 400, 500, 400, 500, 400, 500, 400, 500, 400, 500,\n",
       "                    400, 500, 400, 500, 400, 500, 400, 500, 400, 500, 400,\n",
       "                    500, 400, 500, 400, 500, 400, 500, 400, 500, 400, 500,\n",
       "                    400, 500, 400, 500, 400, 500, 400, 500, 400, 500, 400,\n",
       "                    500, 400, 500, 400, 500, 400, 500, 400, 500, 400, 500,\n",
       "                    400, 500, 400, 500, 400, 500, 400, 500, 400, 500, 400,\n",
       "                    500, 400, 500, 400, 500, 400, 500, 400, 500, 400, 500,\n",
       "                    400, 500, 400, 500, 400, 500, 400, 500, 400, 500, 400,\n",
       "                    500, 400, 500, 400, 500, 400, 500, 400, 500, 400, 500,\n",
       "                    400, 500, 400, 500, 400, 500, 400, 500, 400, 500, 400,\n",
       "                    500, 400, 500, 400, 500, 400, 500, 400, 500, 400, 500,\n",
       "                    400, 500, 400, 500, 400, 500, 400, 500, 400, 500, 400,\n",
       "                    500, 400, 500, 400, 500, 400, 500, 400, 500, 400, 500,\n",
       "                    400, 500, 400, 500, 400, 500, 400, 500, 400, 500, 400,\n",
       "                    500, 400, 500, 400, 500, 400, 500, 400, 500, 400, 500,\n",
       "                    400, 500, 400, 500, 400, 500, 400, 500, 400, 500, 400,\n",
       "                    500, 400, 500, 400, 500, 400, 500, 400, 500, 400, 500,\n",
       "                    400, 500, 400, 500, 400, 500, 400, 500, 400, 500, 400,\n",
       "                    500, 400, 500, 400, 500, 400, 500, 400, 500, 400, 500,\n",
       "                    400, 500, 400, 500, 400, 500, 400, 500, 400, 500, 400,\n",
       "                    500, 400, 500, 400, 500, 400, 500, 400, 500, 400, 500,\n",
       "                    400, 500, 400, 500, 400, 500, 400, 500, 400, 500, 400,\n",
       "                    500, 400, 500, 400, 500, 400, 500, 400, 500, 400, 500,\n",
       "                    400, 500, 400, 500, 400, 500, 400, 500, 400, 500, 400,\n",
       "                    500, 400, 500, 400, 500, 400, 500, 400, 500, 400, 500,\n",
       "                    400, 500, 400, 500, 400, 500, 400, 500, 400, 500, 400,\n",
       "                    500, 400, 500, 400, 500, 400, 500, 400, 500, 400, 500,\n",
       "                    400, 500, 400, 500, 400, 500, 400, 500, 400, 500, 400,\n",
       "                    500, 400, 500, 400, 500, 400, 500, 400, 500, 400, 500,\n",
       "                    400, 500, 400, 500, 400, 500, 400, 500, 400, 500, 400,\n",
       "                    500, 400, 500, 400, 500, 400, 500, 400, 500, 400, 500,\n",
       "                    400, 500, 400, 500, 400, 500, 400, 500, 400, 500, 400,\n",
       "                    500, 400, 500, 400, 500, 400, 500, 400, 500, 400, 500,\n",
       "                    400, 500, 400, 500, 400, 500, 400, 500, 400, 500, 400,\n",
       "                    500, 400, 500, 400, 500, 400, 500, 400, 500, 400, 500,\n",
       "                    400, 500, 400, 500, 400, 500, 400, 500, 400, 500, 400,\n",
       "                    500, 400, 500, 400, 500, 400, 500, 400, 500, 400, 500,\n",
       "                    400, 500, 400, 500, 400, 500, 400, 500, 400, 500, 400,\n",
       "                    500, 400, 500, 400, 500, 400, 500, 400, 500, 400, 500,\n",
       "                    400, 500, 400, 500, 400, 500, 400, 500, 400, 500, 400,\n",
       "                    500, 400, 500, 400, 500, 400, 500, 400, 500, 400, 500,\n",
       "                    400, 500, 400, 500, 400, 500, 400, 500, 400, 500, 400,\n",
       "                    500, 400, 500, 400, 500, 400, 500, 400, 500, 400, 500,\n",
       "                    400, 500, 400, 500, 400, 500, 400, 500, 400, 500, 400,\n",
       "                    500, 400, 500, 400, 500, 400, 500, 400, 500],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': True,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'bootstrap': False,\n",
       "   'criterion': 'log_loss',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500}],\n",
       " 'split0_test_score': array([0.65863636, 0.65863636, 0.65863636, 0.63652174, 0.65863636,\n",
       "        0.65863636, 0.65613445, 0.80974747, 0.80724556, 0.80974747,\n",
       "        0.80974747, 0.80724556, 0.83077498, 0.67966387, 0.83077498,\n",
       "        0.83077498, 0.65863636, 0.80974747, 0.83077498, 0.83077498,\n",
       "        0.82888889, 0.83077498, 0.82888889, 0.82888889, 0.7997619 ,\n",
       "        0.70181818, 0.77077498, 0.7997619 , 0.67515152, 0.77077498,\n",
       "        0.76888889, 0.73730994, 0.83077498, 0.78601307, 0.82888889,\n",
       "        0.73934641, 0.73934641, 0.77077498, 0.77077498, 0.73934641,\n",
       "        0.7397619 , 0.7997619 , 0.73934641, 0.73934641, 0.755     ,\n",
       "        0.78601307, 0.73934641, 0.78601307, 0.70833333, 0.80920635,\n",
       "        0.7397619 , 0.61378788, 0.76181818, 0.7397619 , 0.73934641,\n",
       "        0.73934641, 0.73934641, 0.73934641, 0.73934641, 0.73934641,\n",
       "        0.755     , 0.85292929, 0.78601307, 0.73934641, 0.62521645,\n",
       "        0.77077498, 0.73934641, 0.73934641, 0.78601307, 0.73934641,\n",
       "        0.73934641, 0.73934641, 0.63688312, 0.755     , 0.73934641,\n",
       "        0.76253968, 0.7397619 , 0.66823529, 0.73934641, 0.70833333,\n",
       "        0.76253968, 0.80920635, 0.73934641, 0.755     , 0.67777778,\n",
       "        0.67777778, 0.65863636, 0.67777778, 0.65613445, 0.67777778,\n",
       "        0.82888889, 0.82888889, 0.82888889, 0.82888889, 0.82888889,\n",
       "        0.82888889, 0.67966387, 0.67966387, 0.82888889, 0.82888889,\n",
       "        0.83077498, 0.82888889, 0.82888889, 0.82888889, 0.82888889,\n",
       "        0.82888889, 0.82888889, 0.82888889, 0.83077498, 0.77077498,\n",
       "        0.83077498, 0.83077498, 0.83077498, 0.82888889, 0.82888889,\n",
       "        0.82888889, 0.76888889, 0.82888889, 0.82888889, 0.83077498,\n",
       "        0.83077498, 0.67966387, 0.64156863, 0.7397619 , 0.83077498,\n",
       "        0.83077498, 0.78601307, 0.78601307, 0.73934641, 0.78601307,\n",
       "        0.73730994, 0.78397661, 0.73934641, 0.78601307, 0.83077498,\n",
       "        0.64156863, 0.76888889, 0.83077498, 0.73934641, 0.78601307,\n",
       "        0.73934641, 0.82888889, 0.78601307, 0.82888889, 0.73934641,\n",
       "        0.73934641, 0.70833333, 0.78601307, 0.77077498, 0.73934641,\n",
       "        0.78601307, 0.78601307, 0.78601307, 0.78601307, 0.78397661,\n",
       "        0.82888889, 0.66823529, 0.83077498, 0.78601307, 0.64156863,\n",
       "        0.83077498, 0.6529972 , 0.78601307, 0.78601307, 0.78601307,\n",
       "        0.78601307, 0.83077498, 0.73730994, 0.65613445, 0.65613445,\n",
       "        0.70603175, 0.65613445, 0.65863636, 0.67966387, 0.82888889,\n",
       "        0.80724556, 0.82888889, 0.82888889, 0.80724556, 0.82888889,\n",
       "        0.82888889, 0.82888889, 0.67966387, 0.82888889, 0.67777778,\n",
       "        0.67777778, 0.82888889, 0.82888889, 0.82888889, 0.82888889,\n",
       "        0.82888889, 0.82888889, 0.77077498, 0.82888889, 0.7997619 ,\n",
       "        0.82888889, 0.77077498, 0.6529972 , 0.76888889, 0.82888889,\n",
       "        0.82888889, 0.82888889, 0.82888889, 0.82888889, 0.73934641,\n",
       "        0.73934641, 0.77077498, 0.78601307, 0.7397619 , 0.83077498,\n",
       "        0.73934641, 0.78397661, 0.78397661, 0.83077498, 0.78397661,\n",
       "        0.78601307, 0.77077498, 0.6529972 , 0.78601307, 0.83077498,\n",
       "        0.7997619 , 0.65016043, 0.78601307, 0.73730994, 0.73934641,\n",
       "        0.78601307, 0.78601307, 0.82888889, 0.69142857, 0.78601307,\n",
       "        0.77077498, 0.77077498, 0.78601307, 0.83077498, 0.78601307,\n",
       "        0.78601307, 0.78601307, 0.78601307, 0.82888889, 0.78601307,\n",
       "        0.76253968, 0.77077498, 0.73934641, 0.78601307, 0.83077498,\n",
       "        0.77077498, 0.78397661, 0.83077498, 0.78601307, 0.78601307,\n",
       "        0.73934641, 0.73730994, 0.65863636, 0.65863636, 0.65863636,\n",
       "        0.65863636, 0.65863636, 0.65863636, 0.82888889, 0.82888889,\n",
       "        0.82888889, 0.82888889, 0.82888889, 0.82888889, 0.82888889,\n",
       "        0.83077498, 0.80974747, 0.80974747, 0.80974747, 0.83077498,\n",
       "        0.82888889, 0.82888889, 0.82888889, 0.82888889, 0.82888889,\n",
       "        0.82888889, 0.77077498, 0.73934641, 0.78601307, 0.73934641,\n",
       "        0.73934641, 0.78601307, 0.73934641, 0.73934641, 0.73730994,\n",
       "        0.73934641, 0.73934641, 0.73934641, 0.73934641, 0.73934641,\n",
       "        0.73934641, 0.73934641, 0.73934641, 0.70833333, 0.73934641,\n",
       "        0.73934641, 0.73934641, 0.73934641, 0.73934641, 0.73934641,\n",
       "        0.73934641, 0.73934641, 0.73934641, 0.73934641, 0.73934641,\n",
       "        0.73934641, 0.73934641, 0.73934641, 0.73934641, 0.73934641,\n",
       "        0.73934641, 0.73934641, 0.73934641, 0.73934641, 0.73934641,\n",
       "        0.73934641, 0.73934641, 0.73934641, 0.73934641, 0.73934641,\n",
       "        0.73934641, 0.73934641, 0.73934641, 0.73934641, 0.73934641,\n",
       "        0.73934641, 0.73934641, 0.73934641, 0.73934641, 0.73934641,\n",
       "        0.73934641, 0.73934641, 0.73934641, 0.73934641, 0.73934641,\n",
       "        0.73934641, 0.68430184, 0.67777778, 0.70603175, 0.67777778,\n",
       "        0.70603175, 0.70603175, 0.82888889, 0.82888889, 0.82888889,\n",
       "        0.82888889, 0.82888889, 0.82888889, 0.82888889, 0.82888889,\n",
       "        0.82888889, 0.82888889, 0.82888889, 0.82888889, 0.82888889,\n",
       "        0.82888889, 0.82888889, 0.82888889, 0.82888889, 0.82888889,\n",
       "        0.73730994, 0.77077498, 0.83077498, 0.76888889, 0.82888889,\n",
       "        0.83077498, 0.78601307, 0.78397661, 0.78601307, 0.78601307,\n",
       "        0.78601307, 0.73934641, 0.78601307, 0.73934641, 0.73934641,\n",
       "        0.73934641, 0.73934641, 0.73934641, 0.73934641, 0.78601307,\n",
       "        0.73934641, 0.78601307, 0.78601307, 0.78601307, 0.73934641,\n",
       "        0.73934641, 0.73934641, 0.73934641, 0.73934641, 0.78601307,\n",
       "        0.73934641, 0.73934641, 0.78601307, 0.73934641, 0.73934641,\n",
       "        0.73934641, 0.78601307, 0.73934641, 0.73934641, 0.73934641,\n",
       "        0.73934641, 0.73934641, 0.78601307, 0.78601307, 0.73934641,\n",
       "        0.78601307, 0.73934641, 0.73934641, 0.73934641, 0.73934641,\n",
       "        0.78601307, 0.73934641, 0.73934641, 0.73934641, 0.78601307,\n",
       "        0.73934641, 0.73934641, 0.78601307, 0.73934641, 0.73934641,\n",
       "        0.65613445, 0.70603175, 0.67777778, 0.70603175, 0.70603175,\n",
       "        0.67777778, 0.82888889, 0.82888889, 0.82888889, 0.82888889,\n",
       "        0.82888889, 0.82888889, 0.82888889, 0.82888889, 0.82888889,\n",
       "        0.82888889, 0.82888889, 0.82888889, 0.82888889, 0.82888889,\n",
       "        0.82888889, 0.82888889, 0.82888889, 0.82888889, 0.77077498,\n",
       "        0.83077498, 0.77077498, 0.76888889, 0.76888889, 0.77077498,\n",
       "        0.78601307, 0.78601307, 0.73730994, 0.78601307, 0.78601307,\n",
       "        0.78601307, 0.73934641, 0.73934641, 0.78601307, 0.73934641,\n",
       "        0.73934641, 0.73934641, 0.73934641, 0.73934641, 0.73934641,\n",
       "        0.73934641, 0.78601307, 0.78601307, 0.73934641, 0.73934641,\n",
       "        0.73934641, 0.73934641, 0.73934641, 0.78601307, 0.78601307,\n",
       "        0.73934641, 0.73934641, 0.78601307, 0.73934641, 0.78601307,\n",
       "        0.73934641, 0.73934641, 0.73934641, 0.73934641, 0.73934641,\n",
       "        0.73934641, 0.78601307, 0.78601307, 0.78601307, 0.73934641,\n",
       "        0.78601307, 0.78601307, 0.73934641, 0.73934641, 0.73934641,\n",
       "        0.73934641, 0.73934641, 0.73934641, 0.73934641, 0.73934641,\n",
       "        0.73934641, 0.78601307, 0.73934641, 0.73934641]),\n",
       " 'split1_test_score': array([0.646     , 0.646     , 0.646     , 0.66833333, 0.62208791,\n",
       "        0.66833333, 0.69812253, 0.85288443, 0.83310415, 0.79761905,\n",
       "        0.69812253, 0.69812253, 0.63878788, 0.68953964, 0.68953964,\n",
       "        0.66833333, 0.63878788, 0.646     , 0.82273292, 0.84642857,\n",
       "        0.84642857, 0.82273292, 0.84642857, 0.87481538, 0.63463768,\n",
       "        0.64285714, 0.63463768, 0.79354978, 0.69166667, 0.66175889,\n",
       "        0.84642857, 0.84642857, 0.84642857, 0.84642857, 0.84642857,\n",
       "        0.84642857, 0.66833333, 0.69166667, 0.69166667, 0.66797101,\n",
       "        0.61025641, 0.66797101, 0.84642857, 0.82273292, 0.84642857,\n",
       "        0.82273292, 0.84642857, 0.84642857, 0.69166667, 0.66797101,\n",
       "        0.66797101, 0.66797101, 0.66384615, 0.66384615, 0.84642857,\n",
       "        0.82273292, 0.66797101, 0.84642857, 0.84642857, 0.81860806,\n",
       "        0.66797101, 0.64285714, 0.82273292, 0.69166667, 0.64285714,\n",
       "        0.64285714, 0.82273292, 0.82273292, 0.82273292, 0.84642857,\n",
       "        0.84642857, 0.84642857, 0.66797101, 0.66797101, 0.66797101,\n",
       "        0.66797101, 0.66797101, 0.66797101, 0.84642857, 0.82273292,\n",
       "        0.84642857, 0.84642857, 0.84642857, 0.84642857, 0.66833333,\n",
       "        0.62208791, 0.646     , 0.66833333, 0.646     , 0.66833333,\n",
       "        0.82435786, 0.82435786, 0.79354978, 0.87481538, 0.82435786,\n",
       "        0.84430155, 0.84430155, 0.68953964, 0.68953964, 0.68953964,\n",
       "        0.68953964, 0.66175889, 0.87481538, 0.84642857, 0.84642857,\n",
       "        0.84642857, 0.84642857, 0.84642857, 0.66175889, 0.68953964,\n",
       "        0.68953964, 0.68953964, 0.66833333, 0.69812253, 0.87481538,\n",
       "        0.81860806, 0.84642857, 0.84642857, 0.81860806, 0.81860806,\n",
       "        0.63878788, 0.68953964, 0.60952381, 0.69166667, 0.69166667,\n",
       "        0.67515152, 0.84642857, 0.81860806, 0.81860806, 0.81860806,\n",
       "        0.84642857, 0.84642857, 0.63878788, 0.66175889, 0.82273292,\n",
       "        0.69166667, 0.66384615, 0.63800764, 0.82273292, 0.84642857,\n",
       "        0.84642857, 0.81860806, 0.87481538, 0.81860806, 0.69166667,\n",
       "        0.69812253, 0.69166667, 0.81860806, 0.69166667, 0.63463768,\n",
       "        0.84642857, 0.81860806, 0.81860806, 0.81860806, 0.81860806,\n",
       "        0.84642857, 0.63463768, 0.69166667, 0.64285714, 0.81860806,\n",
       "        0.84642857, 0.66797101, 0.84642857, 0.81860806, 0.84642857,\n",
       "        0.81860806, 0.84642857, 0.81860806, 0.66833333, 0.66833333,\n",
       "        0.63878788, 0.646     , 0.646     , 0.66833333, 0.8165208 ,\n",
       "        0.84430155, 0.82309524, 0.82435786, 0.84642857, 0.84430155,\n",
       "        0.66175889, 0.68953964, 0.66833333, 0.68953964, 0.66833333,\n",
       "        0.68953964, 0.8165208 , 0.87481538, 0.84642857, 0.87481538,\n",
       "        0.87481538, 0.87481538, 0.66175889, 0.66384615, 0.68953964,\n",
       "        0.68953964, 0.68953964, 0.68953964, 0.84642857, 0.87481538,\n",
       "        0.87481538, 0.84642857, 0.87481538, 0.87481538, 0.66833333,\n",
       "        0.72005348, 0.63463768, 0.63463768, 0.69166667, 0.60952381,\n",
       "        0.84642857, 0.81860806, 0.81860806, 0.81860806, 0.81860806,\n",
       "        0.81860806, 0.78939959, 0.69166667, 0.66384615, 0.66175889,\n",
       "        0.69166667, 0.66384615, 0.81860806, 0.81860806, 0.79276955,\n",
       "        0.84642857, 0.81860806, 0.81860806, 0.76428571, 0.69166667,\n",
       "        0.66797101, 0.69166667, 0.63878788, 0.63878788, 0.81860806,\n",
       "        0.79276955, 0.79276955, 0.84642857, 0.81860806, 0.81860806,\n",
       "        0.66384615, 0.66797101, 0.61212121, 0.60952381, 0.66384615,\n",
       "        0.66797101, 0.84642857, 0.84642857, 0.81860806, 0.81860806,\n",
       "        0.81860806, 0.84642857, 0.63878788, 0.61431169, 0.63878788,\n",
       "        0.61431169, 0.61431169, 0.61431169, 0.74534161, 0.71904762,\n",
       "        0.71904762, 0.71603759, 0.75340022, 0.74299034, 0.7915208 ,\n",
       "        0.63463768, 0.73717216, 0.66175889, 0.63463768, 0.63463768,\n",
       "        0.77142857, 0.77142857, 0.77142857, 0.79908425, 0.77142857,\n",
       "        0.82137862, 0.69166667, 0.63463768, 0.63463768, 0.78939959,\n",
       "        0.81860806, 0.63463768, 0.84908425, 0.84908425, 0.84908425,\n",
       "        0.87857143, 0.84908425, 0.88717949, 0.81860806, 0.81860806,\n",
       "        0.66384615, 0.81860806, 0.81860806, 0.81860806, 0.90842883,\n",
       "        0.87857143, 0.91714286, 0.87857143, 0.87857143, 0.87857143,\n",
       "        0.66384615, 0.66384615, 0.81      , 0.66384615, 0.81860806,\n",
       "        0.66384615, 0.87857143, 0.87857143, 0.87857143, 0.87857143,\n",
       "        0.87857143, 0.87857143, 0.69166667, 0.69166667, 0.81860806,\n",
       "        0.66384615, 0.69166667, 0.66384615, 0.87857143, 0.87857143,\n",
       "        0.89809524, 0.87857143, 0.87857143, 0.87857143, 0.66384615,\n",
       "        0.66384615, 0.81860806, 0.66384615, 0.81860806, 0.69166667,\n",
       "        0.87857143, 0.87857143, 0.87857143, 0.91714286, 0.87857143,\n",
       "        0.84908425, 0.62208791, 0.646     , 0.82309524, 0.646     ,\n",
       "        0.646     , 0.66833333, 0.8007619 , 0.82435786, 0.82435786,\n",
       "        0.80542125, 0.8007619 , 0.8007619 , 0.82309524, 0.82309524,\n",
       "        0.82309524, 0.82309524, 0.82309524, 0.82309524, 0.82991342,\n",
       "        0.8007619 , 0.8007619 , 0.82991342, 0.8007619 , 0.8007619 ,\n",
       "        0.82309524, 0.82309524, 0.82309524, 0.82309524, 0.82309524,\n",
       "        0.82309524, 0.87481538, 0.85288443, 0.85288443, 0.85288443,\n",
       "        0.85288443, 0.85288443, 0.82309524, 0.82309524, 0.85288443,\n",
       "        0.85288443, 0.82309524, 0.82309524, 0.85288443, 0.85288443,\n",
       "        0.85288443, 0.85288443, 0.85288443, 0.85288443, 0.82309524,\n",
       "        0.85288443, 0.82309524, 0.82309524, 0.82309524, 0.85288443,\n",
       "        0.85288443, 0.85288443, 0.93773292, 0.85288443, 0.85288443,\n",
       "        0.85288443, 0.85288443, 0.82309524, 0.85288443, 0.85288443,\n",
       "        0.82309524, 0.85288443, 0.85288443, 0.85288443, 0.85288443,\n",
       "        0.85288443, 0.85288443, 0.85288443, 0.85288443, 0.85288443,\n",
       "        0.82309524, 0.85288443, 0.85288443, 0.82309524, 0.85288443,\n",
       "        0.85288443, 0.85288443, 0.93773292, 0.85288443, 0.85288443,\n",
       "        0.646     , 0.646     , 0.646     , 0.8007619 , 0.646     ,\n",
       "        0.646     , 0.7847619 , 0.82309524, 0.80542125, 0.8007619 ,\n",
       "        0.8007619 , 0.80542125, 0.8007619 , 0.82309524, 0.8007619 ,\n",
       "        0.8007619 , 0.8007619 , 0.82309524, 0.82991342, 0.82309524,\n",
       "        0.8007619 , 0.8007619 , 0.8007619 , 0.8007619 , 0.82309524,\n",
       "        0.82309524, 0.82309524, 0.82309524, 0.82309524, 0.82309524,\n",
       "        0.85288443, 0.85288443, 0.85288443, 0.82991342, 0.82991342,\n",
       "        0.82991342, 0.82309524, 0.82309524, 0.85288443, 0.82309524,\n",
       "        0.82309524, 0.82309524, 0.85288443, 0.93773292, 0.82991342,\n",
       "        0.85288443, 0.85288443, 0.85288443, 0.82309524, 0.85288443,\n",
       "        0.85288443, 0.82309524, 0.82309524, 0.82309524, 0.85288443,\n",
       "        0.85288443, 0.85288443, 0.93773292, 0.93773292, 0.85288443,\n",
       "        0.82309524, 0.82309524, 0.85288443, 0.85288443, 0.85288443,\n",
       "        0.82309524, 0.85288443, 0.85288443, 0.85288443, 0.85288443,\n",
       "        0.85288443, 0.93773292, 0.85288443, 0.82309524, 0.82309524,\n",
       "        0.85288443, 0.85288443, 0.85288443, 0.85288443, 0.85288443,\n",
       "        0.93773292, 0.85288443, 0.85288443, 0.93773292]),\n",
       " 'split2_test_score': array([0.59823529, 0.58823529, 0.59823529, 0.59823529, 0.59823529,\n",
       "        0.58823529, 0.63823529, 0.63823529, 0.63823529, 0.63823529,\n",
       "        0.63823529, 0.63823529, 0.628815  , 0.628815  , 0.628815  ,\n",
       "        0.628815  , 0.628815  , 0.66338681, 0.67214834, 0.81338681,\n",
       "        0.67214834, 0.66338681, 0.81338681, 0.67214834, 0.66338681,\n",
       "        0.66338681, 0.66338681, 0.66338681, 0.66338681, 0.66338681,\n",
       "        0.75338681, 0.63672014, 0.63672014, 0.79292929, 0.66338681,\n",
       "        0.693863  , 0.63672014, 0.63845174, 0.63845174, 0.63672014,\n",
       "        0.66338681, 0.75338681, 0.843863  , 0.67204482, 0.67515152,\n",
       "        0.64548167, 0.67214834, 0.63672014, 0.63672014, 0.63672014,\n",
       "        0.67204482, 0.6129972 , 0.66338681, 0.66338681, 0.75338681,\n",
       "        0.63672014, 0.75338681, 0.63672014, 0.66338681, 0.75338681,\n",
       "        0.693863  , 0.63672014, 0.63672014, 0.75338681, 0.75338681,\n",
       "        0.81338681, 0.75338681, 0.67204482, 0.75338681, 0.63672014,\n",
       "        0.66338681, 0.75338681, 0.63672014, 0.693863  , 0.693863  ,\n",
       "        0.63672014, 0.693863  , 0.63672014, 0.75338681, 0.81338681,\n",
       "        0.70187166, 0.75338681, 0.67515152, 0.66338681, 0.59823529,\n",
       "        0.59823529, 0.59823529, 0.59823529, 0.59823529, 0.59823529,\n",
       "        0.67214834, 0.63823529, 0.63823529, 0.67214834, 0.63823529,\n",
       "        0.63823529, 0.63823529, 0.778815  , 0.628815  , 0.628815  ,\n",
       "        0.63823529, 0.63823529, 0.81338681, 0.843863  , 0.81338681,\n",
       "        0.843863  , 0.67214834, 0.67214834, 0.63672014, 0.75338681,\n",
       "        0.81338681, 0.81338681, 0.81338681, 0.66338681, 0.78871148,\n",
       "        0.75338681, 0.79292929, 0.78871148, 0.67214834, 0.81338681,\n",
       "        0.76368984, 0.75338681, 0.843863  , 0.75338681, 0.81338681,\n",
       "        0.81338681, 0.81338681, 0.843863  , 0.78871148, 0.75338681,\n",
       "        0.843863  , 0.64548167, 0.63672014, 0.81338681, 0.64548167,\n",
       "        0.75338681, 0.63672014, 0.81338681, 0.79292929, 0.78871148,\n",
       "        0.75338681, 0.78871148, 0.75338681, 0.843863  , 0.81338681,\n",
       "        0.78871148, 0.75338681, 0.75338681, 0.81338681, 0.75338681,\n",
       "        0.64548167, 0.75338681, 0.75338681, 0.75338681, 0.843863  ,\n",
       "        0.81338681, 0.78871148, 0.78871148, 0.63672014, 0.78871148,\n",
       "        0.78845174, 0.843863  , 0.843863  , 0.78871148, 0.78871148,\n",
       "        0.78871148, 0.81338681, 0.81338681, 0.59823529, 0.59823529,\n",
       "        0.63823529, 0.59823529, 0.63823529, 0.59823529, 0.63823529,\n",
       "        0.67214834, 0.63823529, 0.63823529, 0.63823529, 0.67214834,\n",
       "        0.628815  , 0.628815  , 0.628815  , 0.63823529, 0.628815  ,\n",
       "        0.628815  , 0.81338681, 0.843863  , 0.67214834, 0.81338681,\n",
       "        0.67214834, 0.70187166, 0.81338681, 0.81338681, 0.81338681,\n",
       "        0.81338681, 0.66338681, 0.843863  , 0.85292929, 0.843863  ,\n",
       "        0.843863  , 0.843863  , 0.81338681, 0.81338681, 0.81338681,\n",
       "        0.75338681, 0.78871148, 0.75338681, 0.81338681, 0.81338681,\n",
       "        0.843863  , 0.75338681, 0.75338681, 0.75338681, 0.78871148,\n",
       "        0.75338681, 0.81338681, 0.75338681, 0.63672014, 0.78871148,\n",
       "        0.81338681, 0.66338681, 0.78871148, 0.843863  , 0.843863  ,\n",
       "        0.78871148, 0.68005348, 0.70187166, 0.67204482, 0.75338681,\n",
       "        0.75338681, 0.75338681, 0.693863  , 0.75338681, 0.75338681,\n",
       "        0.79292929, 0.843863  , 0.843863  , 0.75338681, 0.75338681,\n",
       "        0.81338681, 0.75338681, 0.75338681, 0.75338681, 0.81338681,\n",
       "        0.63672014, 0.78871148, 0.78871148, 0.75338681, 0.78871148,\n",
       "        0.75338681, 0.88340548, 0.63823529, 0.63823529, 0.63823529,\n",
       "        0.63823529, 0.59823529, 0.63823529, 0.63823529, 0.63823529,\n",
       "        0.63823529, 0.63823529, 0.63823529, 0.63823529, 0.63823529,\n",
       "        0.63823529, 0.63823529, 0.63823529, 0.67214834, 0.63823529,\n",
       "        0.71169082, 0.67214834, 0.71169082, 0.67214834, 0.71169082,\n",
       "        0.67214834, 0.61475703, 0.843863  , 0.843863  , 0.843863  ,\n",
       "        0.64548167, 0.70187166, 0.69466089, 0.66141414, 0.66141414,\n",
       "        0.74141414, 0.70187166, 0.70187166, 0.76368984, 0.81823529,\n",
       "        0.78871148, 0.72966387, 0.76368984, 0.81823529, 0.66141414,\n",
       "        0.66141414, 0.69466089, 0.66141414, 0.69466089, 0.66141414,\n",
       "        0.76368984, 0.76368984, 0.76368984, 0.76368984, 0.76368984,\n",
       "        0.72966387, 0.69466089, 0.69466089, 0.69466089, 0.66141414,\n",
       "        0.69466089, 0.69466089, 0.76368984, 0.76368984, 0.76368984,\n",
       "        0.76368984, 0.65511841, 0.76368984, 0.66141414, 0.69466089,\n",
       "        0.69466089, 0.69466089, 0.66141414, 0.69466089, 0.76368984,\n",
       "        0.65511841, 0.76368984, 0.76368984, 0.78871148, 0.76368984,\n",
       "        0.69466089, 0.69466089, 0.66141414, 0.69466089, 0.66141414,\n",
       "        0.69466089, 0.63823529, 0.67777778, 0.67777778, 0.67777778,\n",
       "        0.63823529, 0.67777778, 0.71169082, 0.71169082, 0.71169082,\n",
       "        0.71169082, 0.71169082, 0.71169082, 0.85292929, 0.71169082,\n",
       "        0.63823529, 0.81835749, 0.71169082, 0.85292929, 0.74141414,\n",
       "        0.74141414, 0.74141414, 0.74141414, 0.74141414, 0.74141414,\n",
       "        0.843863  , 0.88340548, 0.88340548, 0.843863  , 0.88340548,\n",
       "        0.88340548, 0.88340548, 0.71959596, 0.71959596, 0.82825397,\n",
       "        0.71959596, 0.74141414, 0.843863  , 0.88340548, 0.82825397,\n",
       "        0.82825397, 0.81823529, 0.843863  , 0.74141414, 0.71959596,\n",
       "        0.71959596, 0.82825397, 0.88340548, 0.82825397, 0.88340548,\n",
       "        0.82825397, 0.67204482, 0.82825397, 0.88340548, 0.82825397,\n",
       "        0.82825397, 0.71959596, 0.71959596, 0.71959596, 0.71959596,\n",
       "        0.71959596, 0.88340548, 0.82825397, 0.80323232, 0.82825397,\n",
       "        0.88340548, 0.82825397, 0.71959596, 0.71959596, 0.71959596,\n",
       "        0.82825397, 0.82825397, 0.71959596, 0.80323232, 0.80323232,\n",
       "        0.80323232, 0.82825397, 0.82825397, 0.73229437, 0.71959596,\n",
       "        0.82825397, 0.71959596, 0.82825397, 0.71959596, 0.71959596,\n",
       "        0.67777778, 0.67777778, 0.67214834, 0.67777778, 0.67777778,\n",
       "        0.67777778, 0.71169082, 0.71169082, 0.67777778, 0.71169082,\n",
       "        0.67777778, 0.71169082, 0.67777778, 0.85292929, 0.67214834,\n",
       "        0.67214834, 0.70181818, 0.70181818, 0.74141414, 0.74141414,\n",
       "        0.74141414, 0.74141414, 0.88340548, 0.88340548, 0.79292929,\n",
       "        0.88340548, 0.88340548, 0.88340548, 0.88340548, 0.88340548,\n",
       "        0.74141414, 0.74141414, 0.74141414, 0.88340548, 0.71959596,\n",
       "        0.88340548, 0.71047619, 0.88340548, 0.82825397, 0.82825397,\n",
       "        0.82825397, 0.88340548, 0.82825397, 0.82825397, 0.82825397,\n",
       "        0.71959596, 0.71959596, 0.71959596, 0.82825397, 0.88340548,\n",
       "        0.88340548, 0.82825397, 0.80323232, 0.82825397, 0.71959596,\n",
       "        0.82825397, 0.82825397, 0.82825397, 0.82825397, 0.71959596,\n",
       "        0.82825397, 0.82825397, 0.88340548, 0.80323232, 0.82825397,\n",
       "        0.82825397, 0.82825397, 0.82825397, 0.71959596, 0.71959596,\n",
       "        0.71959596, 0.71959596, 0.82825397, 0.82825397, 0.78871148,\n",
       "        0.80323232, 0.76368984, 0.82825397, 0.71959596, 0.82825397,\n",
       "        0.82825397, 0.71959596, 0.82825397, 0.71959596]),\n",
       " 'split3_test_score': array([0.60545455, 0.60545455, 0.60545455, 0.60545455, 0.60545455,\n",
       "        0.60545455, 0.60545455, 0.60545455, 0.60545455, 0.60545455,\n",
       "        0.60545455, 0.60545455, 0.60545455, 0.60545455, 0.60545455,\n",
       "        0.64571429, 0.60545455, 0.60545455, 0.68      , 0.68      ,\n",
       "        0.64571429, 0.68      , 0.68      , 0.68      , 0.68      ,\n",
       "        0.68      , 0.64571429, 0.68      , 0.64571429, 0.68      ,\n",
       "        0.68      , 0.68      , 0.68      , 0.68      , 0.68      ,\n",
       "        0.68      , 0.68      , 0.68      , 0.68      , 0.68      ,\n",
       "        0.68      , 0.68      , 0.68      , 0.68      , 0.68      ,\n",
       "        0.68      , 0.68      , 0.68      , 0.68      , 0.68      ,\n",
       "        0.68      , 0.68      , 0.68      , 0.68      , 0.68      ,\n",
       "        0.68      , 0.68      , 0.68      , 0.68      , 0.68      ,\n",
       "        0.68      , 0.68      , 0.68      , 0.68      , 0.68      ,\n",
       "        0.68      , 0.68      , 0.68      , 0.68      , 0.68      ,\n",
       "        0.68      , 0.68      , 0.68      , 0.68      , 0.68      ,\n",
       "        0.68      , 0.68      , 0.68      , 0.68      , 0.68      ,\n",
       "        0.68      , 0.6738756 , 0.68      , 0.68      , 0.61341615,\n",
       "        0.60545455, 0.60545455, 0.60545455, 0.60545455, 0.60545455,\n",
       "        0.60545455, 0.60545455, 0.60545455, 0.60545455, 0.60545455,\n",
       "        0.60545455, 0.60545455, 0.60545455, 0.60545455, 0.60545455,\n",
       "        0.60545455, 0.60545455, 0.68      , 0.68      , 0.68      ,\n",
       "        0.68      , 0.68      , 0.68      , 0.68      , 0.64571429,\n",
       "        0.64571429, 0.68      , 0.68      , 0.64571429, 0.68      ,\n",
       "        0.68      , 0.68      , 0.68      , 0.68      , 0.68      ,\n",
       "        0.68      , 0.68      , 0.68      , 0.68      , 0.68      ,\n",
       "        0.68      , 0.68      , 0.68      , 0.68      , 0.68      ,\n",
       "        0.68      , 0.68      , 0.68      , 0.68      , 0.68      ,\n",
       "        0.68      , 0.68      , 0.68      , 0.68      , 0.68      ,\n",
       "        0.68      , 0.68      , 0.68      , 0.68      , 0.68      ,\n",
       "        0.68      , 0.68      , 0.68      , 0.68      , 0.68      ,\n",
       "        0.68      , 0.68      , 0.68      , 0.68      , 0.68      ,\n",
       "        0.68      , 0.68      , 0.68      , 0.68      , 0.68      ,\n",
       "        0.68      , 0.68      , 0.68      , 0.68      , 0.64571429,\n",
       "        0.68      , 0.68      , 0.68      , 0.60545455, 0.60545455,\n",
       "        0.60545455, 0.60545455, 0.60545455, 0.60545455, 0.60545455,\n",
       "        0.60545455, 0.60545455, 0.60545455, 0.60545455, 0.60545455,\n",
       "        0.60545455, 0.60545455, 0.60545455, 0.60545455, 0.60545455,\n",
       "        0.60545455, 0.64571429, 0.68      , 0.64571429, 0.68      ,\n",
       "        0.68      , 0.68      , 0.68      , 0.68      , 0.68      ,\n",
       "        0.68      , 0.64571429, 0.60545455, 0.68      , 0.68      ,\n",
       "        0.68      , 0.68      , 0.68      , 0.68      , 0.68      ,\n",
       "        0.68      , 0.68      , 0.68      , 0.68      , 0.68      ,\n",
       "        0.68      , 0.68      , 0.68      , 0.68      , 0.68      ,\n",
       "        0.68      , 0.68      , 0.64571429, 0.68      , 0.68      ,\n",
       "        0.68      , 0.68      , 0.68      , 0.68      , 0.68      ,\n",
       "        0.68      , 0.68      , 0.68      , 0.68      , 0.68      ,\n",
       "        0.68      , 0.68      , 0.68      , 0.68      , 0.68      ,\n",
       "        0.68      , 0.68      , 0.68      , 0.68      , 0.68      ,\n",
       "        0.68      , 0.68      , 0.68      , 0.68      , 0.68      ,\n",
       "        0.68      , 0.68      , 0.68      , 0.68      , 0.68      ,\n",
       "        0.68      , 0.68      , 0.60545455, 0.60545455, 0.60545455,\n",
       "        0.60545455, 0.60545455, 0.60545455, 0.60545455, 0.60545455,\n",
       "        0.60545455, 0.60545455, 0.60545455, 0.60545455, 0.60545455,\n",
       "        0.60545455, 0.60545455, 0.60545455, 0.60545455, 0.60545455,\n",
       "        0.64571429, 0.64571429, 0.68      , 0.64571429, 0.64571429,\n",
       "        0.68      , 0.64571429, 0.64571429, 0.64571429, 0.64571429,\n",
       "        0.64571429, 0.64571429, 0.68      , 0.68      , 0.68      ,\n",
       "        0.68      , 0.68      , 0.68      , 0.68      , 0.68      ,\n",
       "        0.68      , 0.68      , 0.68      , 0.68      , 0.6738756 ,\n",
       "        0.6738756 , 0.68      , 0.6738756 , 0.6738756 , 0.68      ,\n",
       "        0.6738756 , 0.6738756 , 0.6738756 , 0.6738756 , 0.6738756 ,\n",
       "        0.68      , 0.6738756 , 0.6738756 , 0.6738756 , 0.6738756 ,\n",
       "        0.6738756 , 0.6738756 , 0.6738756 , 0.6738756 , 0.6738756 ,\n",
       "        0.6738756 , 0.6738756 , 0.6738756 , 0.6738756 , 0.6738756 ,\n",
       "        0.6738756 , 0.6738756 , 0.6738756 , 0.6738756 , 0.6738756 ,\n",
       "        0.6738756 , 0.6738756 , 0.6738756 , 0.6738756 , 0.6738756 ,\n",
       "        0.6738756 , 0.6738756 , 0.6738756 , 0.6738756 , 0.6738756 ,\n",
       "        0.6738756 , 0.60545455, 0.60545455, 0.60545455, 0.60545455,\n",
       "        0.60545455, 0.60545455, 0.60545455, 0.61341615, 0.60545455,\n",
       "        0.61341615, 0.60545455, 0.60545455, 0.60545455, 0.60545455,\n",
       "        0.60545455, 0.60545455, 0.60545455, 0.60545455, 0.64571429,\n",
       "        0.68      , 0.64571429, 0.68      , 0.68      , 0.68      ,\n",
       "        0.64571429, 0.64571429, 0.64571429, 0.64571429, 0.64571429,\n",
       "        0.64571429, 0.68      , 0.68      , 0.68      , 0.68      ,\n",
       "        0.68      , 0.68      , 0.68      , 0.64571429, 0.68      ,\n",
       "        0.64571429, 0.64571429, 0.68      , 0.68      , 0.68      ,\n",
       "        0.68      , 0.68      , 0.68      , 0.68      , 0.68      ,\n",
       "        0.68      , 0.6738756 , 0.68      , 0.68      , 0.68      ,\n",
       "        0.68      , 0.68      , 0.68      , 0.68      , 0.68      ,\n",
       "        0.68      , 0.68      , 0.6738756 , 0.6738756 , 0.68      ,\n",
       "        0.64571429, 0.68      , 0.68      , 0.68      , 0.68      ,\n",
       "        0.68      , 0.68      , 0.68      , 0.6738756 , 0.6738756 ,\n",
       "        0.6738756 , 0.6738756 , 0.68      , 0.64571429, 0.68      ,\n",
       "        0.68      , 0.68      , 0.68      , 0.68      , 0.68      ,\n",
       "        0.60545455, 0.60545455, 0.60545455, 0.60545455, 0.60545455,\n",
       "        0.60545455, 0.61341615, 0.60545455, 0.60545455, 0.60545455,\n",
       "        0.61341615, 0.61341615, 0.60545455, 0.60545455, 0.60545455,\n",
       "        0.60545455, 0.60545455, 0.60545455, 0.64571429, 0.64571429,\n",
       "        0.64571429, 0.68      , 0.68      , 0.68      , 0.64571429,\n",
       "        0.64571429, 0.64571429, 0.64571429, 0.64571429, 0.64571429,\n",
       "        0.68      , 0.68      , 0.68      , 0.68      , 0.68      ,\n",
       "        0.68      , 0.68      , 0.68      , 0.64571429, 0.68      ,\n",
       "        0.68      , 0.64571429, 0.68      , 0.68      , 0.68      ,\n",
       "        0.68      , 0.68      , 0.68      , 0.64571429, 0.6738756 ,\n",
       "        0.68      , 0.68      , 0.68      , 0.68      , 0.6738756 ,\n",
       "        0.68      , 0.68      , 0.68      , 0.68      , 0.68      ,\n",
       "        0.6738756 , 0.6738756 , 0.6738756 , 0.68      , 0.68      ,\n",
       "        0.68      , 0.68      , 0.68      , 0.68      , 0.68      ,\n",
       "        0.68      , 0.68      , 0.6738756 , 0.64080201, 0.6738756 ,\n",
       "        0.6738756 , 0.6738756 , 0.68      , 0.68      , 0.68      ,\n",
       "        0.68      , 0.68      , 0.68      , 0.68      ]),\n",
       " 'split4_test_score': array([0.61984127, 0.61984127, 0.61984127, 0.61984127, 0.61984127,\n",
       "        0.61984127, 0.61984127, 0.61984127, 0.61984127, 0.61984127,\n",
       "        0.61984127, 0.61984127, 0.61984127, 0.61984127, 0.66555556,\n",
       "        0.61206349, 0.66555556, 0.61984127, 0.61984127, 0.61984127,\n",
       "        0.61984127, 0.61239316, 0.61239316, 0.61984127, 0.66555556,\n",
       "        0.66555556, 0.61984127, 0.66555556, 0.66555556, 0.61984127,\n",
       "        0.61239316, 0.61239316, 0.61239316, 0.61239316, 0.61984127,\n",
       "        0.61984127, 0.66555556, 0.66555556, 0.66555556, 0.66555556,\n",
       "        0.61984127, 0.61984127, 0.61239316, 0.61239316, 0.61239316,\n",
       "        0.61239316, 0.61239316, 0.61239316, 0.66555556, 0.66555556,\n",
       "        0.66555556, 0.61984127, 0.66555556, 0.66555556, 0.61239316,\n",
       "        0.61239316, 0.61239316, 0.61239316, 0.61984127, 0.61239316,\n",
       "        0.61984127, 0.66555556, 0.66555556, 0.66555556, 0.6557265 ,\n",
       "        0.61984127, 0.61239316, 0.61239316, 0.61239316, 0.61239316,\n",
       "        0.61239316, 0.61239316, 0.66555556, 0.66555556, 0.61206349,\n",
       "        0.66555556, 0.61984127, 0.66555556, 0.61239316, 0.61239316,\n",
       "        0.61239316, 0.61239316, 0.61239316, 0.61239316, 0.66555556,\n",
       "        0.61984127, 0.61984127, 0.61984127, 0.61984127, 0.61984127,\n",
       "        0.61984127, 0.60247073, 0.61984127, 0.60247073, 0.64495425,\n",
       "        0.61984127, 0.61984127, 0.66555556, 0.61984127, 0.61984127,\n",
       "        0.61984127, 0.66555556, 0.61984127, 0.61984127, 0.61984127,\n",
       "        0.61984127, 0.61984127, 0.61984127, 0.66555556, 0.61984127,\n",
       "        0.66555556, 0.61984127, 0.66555556, 0.61984127, 0.61239316,\n",
       "        0.61239316, 0.61984127, 0.61984127, 0.61984127, 0.61984127,\n",
       "        0.66555556, 0.61984127, 0.66555556, 0.61984127, 0.66555556,\n",
       "        0.61239316, 0.61239316, 0.61984127, 0.61239316, 0.61239316,\n",
       "        0.61239316, 0.61984127, 0.61984127, 0.61984127, 0.66555556,\n",
       "        0.61984127, 0.61984127, 0.61984127, 0.61239316, 0.61984127,\n",
       "        0.61984127, 0.61239316, 0.61239316, 0.61239316, 0.61984127,\n",
       "        0.6557265 , 0.66555556, 0.66555556, 0.6557265 , 0.61984127,\n",
       "        0.61239316, 0.61984127, 0.61239316, 0.61239316, 0.61239316,\n",
       "        0.61984127, 0.66555556, 0.61984127, 0.61984127, 0.66555556,\n",
       "        0.61984127, 0.61984127, 0.61239316, 0.61239316, 0.61239316,\n",
       "        0.61239316, 0.61239316, 0.61239316, 0.61984127, 0.61984127,\n",
       "        0.61984127, 0.61984127, 0.61984127, 0.61984127, 0.61984127,\n",
       "        0.61984127, 0.61984127, 0.60247073, 0.61984127, 0.61984127,\n",
       "        0.66555556, 0.61984127, 0.61984127, 0.61984127, 0.61984127,\n",
       "        0.61984127, 0.61984127, 0.61984127, 0.61984127, 0.61984127,\n",
       "        0.61984127, 0.61984127, 0.61984127, 0.66555556, 0.61984127,\n",
       "        0.66555556, 0.61984127, 0.66555556, 0.61984127, 0.61984127,\n",
       "        0.61984127, 0.61239316, 0.61984127, 0.61984127, 0.66555556,\n",
       "        0.66555556, 0.66555556, 0.66555556, 0.66555556, 0.66555556,\n",
       "        0.61239316, 0.61984127, 0.61239316, 0.61239316, 0.61239316,\n",
       "        0.61984127, 0.61984127, 0.66555556, 0.61984127, 0.66555556,\n",
       "        0.66555556, 0.66555556, 0.61984127, 0.61239316, 0.61239316,\n",
       "        0.61239316, 0.61239316, 0.61239316, 0.61984127, 0.66555556,\n",
       "        0.66555556, 0.61984127, 0.61984127, 0.61984127, 0.61239316,\n",
       "        0.61239316, 0.61239316, 0.61239316, 0.61239316, 0.61239316,\n",
       "        0.66555556, 0.66555556, 0.61984127, 0.61984127, 0.61984127,\n",
       "        0.66555556, 0.61239316, 0.61984127, 0.61984127, 0.61984127,\n",
       "        0.61239316, 0.61239316, 0.65461538, 0.65461538, 0.65461538,\n",
       "        0.70017094, 0.66239316, 0.65461538, 0.66239316, 0.66239316,\n",
       "        0.66239316, 0.66239316, 0.66239316, 0.66239316, 0.66555556,\n",
       "        0.66555556, 0.65461538, 0.66555556, 0.66555556, 0.66555556,\n",
       "        0.66239316, 0.66239316, 0.66239316, 0.66239316, 0.66239316,\n",
       "        0.66239316, 0.66555556, 0.66555556, 0.61206349, 0.66555556,\n",
       "        0.66555556, 0.66555556, 0.66239316, 0.66239316, 0.66239316,\n",
       "        0.66239316, 0.66239316, 0.66239316, 0.66555556, 0.66555556,\n",
       "        0.61206349, 0.66555556, 0.66555556, 0.66555556, 0.66239316,\n",
       "        0.66239316, 0.66239316, 0.66239316, 0.66239316, 0.66239316,\n",
       "        0.66555556, 0.66555556, 0.66555556, 0.66555556, 0.66555556,\n",
       "        0.66555556, 0.61984127, 0.66239316, 0.66239316, 0.66239316,\n",
       "        0.66239316, 0.66239316, 0.66555556, 0.66555556, 0.66555556,\n",
       "        0.66555556, 0.66555556, 0.66555556, 0.66239316, 0.66239316,\n",
       "        0.66239316, 0.61984127, 0.66239316, 0.66239316, 0.66555556,\n",
       "        0.66555556, 0.66555556, 0.66555556, 0.66555556, 0.66555556,\n",
       "        0.66239316, 0.66239316, 0.66239316, 0.66239316, 0.66239316,\n",
       "        0.61984127, 0.66239316, 0.66555556, 0.66555556, 0.66555556,\n",
       "        0.66555556, 0.66555556, 0.64495425, 0.64495425, 0.64495425,\n",
       "        0.64495425, 0.66239316, 0.64495425, 0.66555556, 0.66555556,\n",
       "        0.61984127, 0.66555556, 0.66555556, 0.66555556, 0.66239316,\n",
       "        0.66239316, 0.66239316, 0.66239316, 0.66239316, 0.66239316,\n",
       "        0.66555556, 0.66555556, 0.66555556, 0.66555556, 0.66555556,\n",
       "        0.66555556, 0.66239316, 0.66239316, 0.66239316, 0.66239316,\n",
       "        0.66239316, 0.66239316, 0.66555556, 0.66555556, 0.66555556,\n",
       "        0.66555556, 0.66555556, 0.66555556, 0.66239316, 0.66239316,\n",
       "        0.61984127, 0.66239316, 0.66239316, 0.66239316, 0.61984127,\n",
       "        0.66555556, 0.66555556, 0.66555556, 0.66555556, 0.66555556,\n",
       "        0.66239316, 0.61984127, 0.66239316, 0.66239316, 0.66239316,\n",
       "        0.66239316, 0.66555556, 0.66555556, 0.66555556, 0.66555556,\n",
       "        0.66555556, 0.66555556, 0.66239316, 0.66239316, 0.66239316,\n",
       "        0.66239316, 0.66239316, 0.66239316, 0.66555556, 0.66555556,\n",
       "        0.66555556, 0.66555556, 0.61984127, 0.61984127, 0.66239316,\n",
       "        0.61984127, 0.66239316, 0.66239316, 0.66239316, 0.66239316,\n",
       "        0.66239316, 0.61984127, 0.70017094, 0.70017094, 0.66239316,\n",
       "        0.61984127, 0.64495425, 0.64495425, 0.64495425, 0.64495425,\n",
       "        0.61784314, 0.64495425, 0.66555556, 0.66555556, 0.66555556,\n",
       "        0.66555556, 0.66555556, 0.66555556, 0.66239316, 0.66239316,\n",
       "        0.66239316, 0.66239316, 0.66239316, 0.66239316, 0.66555556,\n",
       "        0.66555556, 0.66555556, 0.66555556, 0.66555556, 0.66555556,\n",
       "        0.66239316, 0.66239316, 0.66239316, 0.66239316, 0.66239316,\n",
       "        0.66239316, 0.66555556, 0.66555556, 0.61984127, 0.66555556,\n",
       "        0.66555556, 0.66555556, 0.66239316, 0.66239316, 0.66239316,\n",
       "        0.66239316, 0.61984127, 0.66239316, 0.66555556, 0.66555556,\n",
       "        0.66555556, 0.66555556, 0.66555556, 0.66555556, 0.66239316,\n",
       "        0.66239316, 0.66239316, 0.61984127, 0.66239316, 0.66239316,\n",
       "        0.66555556, 0.66555556, 0.61984127, 0.66555556, 0.61984127,\n",
       "        0.66555556, 0.66239316, 0.66239316, 0.66239316, 0.66239316,\n",
       "        0.66239316, 0.66239316, 0.66555556, 0.66555556, 0.66555556,\n",
       "        0.66555556, 0.66555556, 0.66555556, 0.66239316, 0.66239316,\n",
       "        0.66239316, 0.66239316, 0.61984127, 0.66239316]),\n",
       " 'mean_test_score': array([0.62563349, 0.62363349, 0.62563349, 0.62567724, 0.62085108,\n",
       "        0.62810016, 0.64355762, 0.7052326 , 0.70077617, 0.69417953,\n",
       "        0.67428022, 0.67377984, 0.66473474, 0.64466287, 0.68402794,\n",
       "        0.67714022, 0.63944987, 0.66888602, 0.7250995 , 0.75808633,\n",
       "        0.72260427, 0.72185757, 0.75621949, 0.73513878, 0.68866839,\n",
       "        0.67072354, 0.666871  , 0.72045081, 0.66829497, 0.67915239,\n",
       "        0.73221949, 0.70257036, 0.72126337, 0.74355282, 0.72770911,\n",
       "        0.71589585, 0.67799109, 0.68928979, 0.68928979, 0.67791862,\n",
       "        0.66264928, 0.7041922 , 0.74440623, 0.70530346, 0.71379465,\n",
       "        0.70932416, 0.7100633 , 0.71231099, 0.67645514, 0.69189061,\n",
       "        0.68506666, 0.63891947, 0.68692134, 0.68251008, 0.72631099,\n",
       "        0.69823853, 0.69061948, 0.70297766, 0.70980061, 0.72074689,\n",
       "        0.68333506, 0.69561243, 0.71820434, 0.70599109, 0.67143738,\n",
       "        0.70537204, 0.72157186, 0.70530346, 0.73090519, 0.70297766,\n",
       "        0.70831099, 0.72631099, 0.65742597, 0.69247791, 0.67864878,\n",
       "        0.68255728, 0.68028744, 0.6636964 , 0.72631099, 0.72736924,\n",
       "        0.72064661, 0.7390581 , 0.71066393, 0.71144171, 0.64466362,\n",
       "        0.62467936, 0.62563349, 0.63392844, 0.62513311, 0.63392844,\n",
       "        0.71013818, 0.69988146, 0.69719396, 0.71675558, 0.70837817,\n",
       "        0.70734431, 0.6774993 , 0.68380572, 0.67450787, 0.67450787,\n",
       "        0.67676915, 0.67997864, 0.76338647, 0.76380435, 0.75770911,\n",
       "        0.76380435, 0.72946141, 0.72946141, 0.69496191, 0.6958514 ,\n",
       "        0.72899425, 0.72670854, 0.73161013, 0.69119076, 0.75696178,\n",
       "        0.73865538, 0.7416176 , 0.75277404, 0.72389731, 0.75252222,\n",
       "        0.71576165, 0.68448632, 0.6881022 , 0.69693133, 0.7362768 ,\n",
       "        0.72234129, 0.74764432, 0.74966508, 0.72781182, 0.73008022,\n",
       "        0.74399894, 0.71514562, 0.66293914, 0.71220001, 0.72890902,\n",
       "        0.67729267, 0.67385929, 0.71640214, 0.72948036, 0.74419888,\n",
       "        0.72780061, 0.74572032, 0.74132168, 0.75675062, 0.70884823,\n",
       "        0.71238138, 0.69978847, 0.7407127 , 0.72231099, 0.68544243,\n",
       "        0.7140633 , 0.73156984, 0.73008022, 0.73008022, 0.74776817,\n",
       "        0.75770911, 0.687428  , 0.72219888, 0.67308633, 0.71888875,\n",
       "        0.75309931, 0.6929345 , 0.75373956, 0.73714516, 0.73585212,\n",
       "        0.73714516, 0.7565967 , 0.73233959, 0.62959978, 0.62959978,\n",
       "        0.64167015, 0.62513311, 0.63363349, 0.63430566, 0.70178816,\n",
       "        0.70979825, 0.70310305, 0.69988146, 0.70344105, 0.71412692,\n",
       "        0.67809458, 0.67450787, 0.6404216 , 0.67639193, 0.64004439,\n",
       "        0.64428565, 0.74487041, 0.76948171, 0.72260427, 0.76338647,\n",
       "        0.73513878, 0.74108344, 0.70915239, 0.73033548, 0.72050593,\n",
       "        0.73547418, 0.6778514 , 0.69148199, 0.7536176 , 0.76948171,\n",
       "        0.76948171, 0.76231472, 0.76338647, 0.76338647, 0.71332442,\n",
       "        0.71166845, 0.70793594, 0.70391862, 0.71807419, 0.71984823,\n",
       "        0.74440623, 0.73116255, 0.72967293, 0.7390326 , 0.73673786,\n",
       "        0.73156984, 0.73468053, 0.6818641 , 0.67728413, 0.72536018,\n",
       "        0.73007419, 0.66458979, 0.73863478, 0.73843483, 0.73367442,\n",
       "        0.74270926, 0.71541355, 0.72835235, 0.68552007, 0.71532442,\n",
       "        0.70753767, 0.70313394, 0.68370104, 0.70455819, 0.73008022,\n",
       "        0.73282102, 0.74300776, 0.75373956, 0.73865538, 0.73008022,\n",
       "        0.71706564, 0.70753767, 0.68093914, 0.68975299, 0.72156984,\n",
       "        0.68420434, 0.74230197, 0.75315126, 0.73156984, 0.73863478,\n",
       "        0.72074689, 0.75190743, 0.63914589, 0.63425066, 0.63914589,\n",
       "        0.64336177, 0.62780621, 0.63425066, 0.6960627 , 0.6908039 ,\n",
       "        0.6908039 , 0.6902019 , 0.69767442, 0.69559245, 0.70593102,\n",
       "        0.67493161, 0.68904497, 0.67615035, 0.67750872, 0.67493161,\n",
       "        0.72402315, 0.71611465, 0.73088029, 0.72164578, 0.72402315,\n",
       "        0.7329618 , 0.6776937 , 0.70582339, 0.70445831, 0.73677577,\n",
       "        0.7029412 , 0.68675845, 0.72509694, 0.71844759, 0.7180403 ,\n",
       "        0.74034503, 0.72653909, 0.73415814, 0.73343997, 0.74434906,\n",
       "        0.69679351, 0.72663478, 0.73343997, 0.73814645, 0.72909163,\n",
       "        0.72312015, 0.73870866, 0.72312015, 0.7297695 , 0.72434503,\n",
       "        0.70126271, 0.70126271, 0.73049348, 0.70126271, 0.73221509,\n",
       "        0.6956824 , 0.72125912, 0.7297695 , 0.7297695 , 0.72312015,\n",
       "        0.7297695 , 0.7297695 , 0.70682681, 0.70682681, 0.73221509,\n",
       "        0.70126271, 0.68511253, 0.70126271, 0.72312015, 0.7297695 ,\n",
       "        0.73367426, 0.72125912, 0.72312015, 0.7297695 , 0.70126271,\n",
       "        0.67954842, 0.73221509, 0.70126271, 0.73721942, 0.70682681,\n",
       "        0.7297695 , 0.7297695 , 0.72312015, 0.73748378, 0.72312015,\n",
       "        0.71536168, 0.64249455, 0.65451313, 0.69558297, 0.65451313,\n",
       "        0.65225543, 0.66463059, 0.71835008, 0.72466159, 0.72306927,\n",
       "        0.72087427, 0.72183786, 0.71835008, 0.7551847 , 0.72693701,\n",
       "        0.70310305, 0.74827034, 0.72693701, 0.7551847 , 0.74166478,\n",
       "        0.74269162, 0.73583448, 0.74852192, 0.74269162, 0.74269162,\n",
       "        0.7431076 , 0.75770911, 0.76970911, 0.74942339, 0.76933189,\n",
       "        0.76970911, 0.77732542, 0.73977003, 0.74017733, 0.76190893,\n",
       "        0.74017733, 0.73520763, 0.75970537, 0.75142339, 0.75320807,\n",
       "        0.74635093, 0.73838936, 0.75037204, 0.73520763, 0.74017733,\n",
       "        0.72233361, 0.76190893, 0.77293923, 0.76190893, 0.74913768,\n",
       "        0.75320807, 0.71478352, 0.74725023, 0.75828054, 0.76254141,\n",
       "        0.75257559, 0.72233361, 0.75714702, 0.73084399, 0.73084399,\n",
       "        0.73084399, 0.77357171, 0.74602535, 0.74697886, 0.75320807,\n",
       "        0.75142339, 0.75320807, 0.74017733, 0.74017733, 0.73084399,\n",
       "        0.76190893, 0.75257559, 0.73084399, 0.74697886, 0.74697886,\n",
       "        0.75035436, 0.75198319, 0.74406522, 0.71205831, 0.74017733,\n",
       "        0.74406522, 0.73084399, 0.77887862, 0.73084399, 0.73084399,\n",
       "        0.64955199, 0.65102107, 0.66031032, 0.69803938, 0.65953145,\n",
       "        0.64537027, 0.7167424 , 0.72281675, 0.71249934, 0.71835008,\n",
       "        0.70773757, 0.72087427, 0.71568773, 0.7551847 , 0.71456185,\n",
       "        0.71456185, 0.72049582, 0.72496248, 0.74166478, 0.74030114,\n",
       "        0.73583448, 0.74269162, 0.77108989, 0.77108989, 0.73961387,\n",
       "        0.76970911, 0.75770911, 0.75733189, 0.75733189, 0.75770911,\n",
       "        0.74454096, 0.74454096, 0.73480034, 0.76834503, 0.73558312,\n",
       "        0.76834503, 0.72369468, 0.75828054, 0.74654141, 0.74725023,\n",
       "        0.74725023, 0.75142339, 0.75257559, 0.76954529, 0.74798139,\n",
       "        0.73084399, 0.73166695, 0.74017733, 0.74039309, 0.7630135 ,\n",
       "        0.76423838, 0.74725023, 0.7422459 , 0.75658357, 0.73895245,\n",
       "        0.75257559, 0.75257559, 0.77036825, 0.76954529, 0.74017733,\n",
       "        0.74602535, 0.74602535, 0.75387064, 0.74820374, 0.74406522,\n",
       "        0.74725023, 0.76190893, 0.76190893, 0.74017733, 0.73084399,\n",
       "        0.74017733, 0.75714702, 0.75198319, 0.73941063, 0.73811686,\n",
       "        0.74697886, 0.73907037, 0.75320807, 0.73084399, 0.75257559,\n",
       "        0.76954529, 0.74017733, 0.74406522, 0.74781369]),\n",
       " 'std_test_score': array([0.02321803, 0.02578119, 0.02321803, 0.02503287, 0.02087489,\n",
       "        0.03072917, 0.03218118, 0.10436513, 0.09838136, 0.090093  ,\n",
       "        0.07472569, 0.07381978, 0.08374054, 0.03359629, 0.07890316,\n",
       "        0.07904315, 0.02153532, 0.07324602, 0.08557649, 0.09094537,\n",
       "        0.09554788, 0.08853494, 0.09293228, 0.0985903 , 0.05746232,\n",
       "        0.01954483, 0.05386384, 0.06251363, 0.01506473, 0.04992858,\n",
       "        0.07990199, 0.083522  , 0.09834843, 0.08493073, 0.0920659 ,\n",
       "        0.07561635, 0.03382223, 0.04445134, 0.04445134, 0.03384323,\n",
       "        0.04653061, 0.06413423, 0.09154389, 0.07117208, 0.08025867,\n",
       "        0.08133157, 0.07916286, 0.08962262, 0.0243222 , 0.06035533,\n",
       "        0.027784  , 0.02897979, 0.03794806, 0.02927651, 0.0780426 ,\n",
       "        0.07573017, 0.05110603, 0.0836952 , 0.07832644, 0.06984118,\n",
       "        0.04364708, 0.08018377, 0.07265726, 0.03427737, 0.0446969 ,\n",
       "        0.07458163, 0.07100689, 0.07117208, 0.07564532, 0.0836952 ,\n",
       "        0.08007445, 0.0780426 , 0.01753633, 0.03283909, 0.04114636,\n",
       "        0.04244193, 0.03879955, 0.01439344, 0.0780426 , 0.08039771,\n",
       "        0.07911964, 0.08596194, 0.07888381, 0.08151963, 0.03232729,\n",
       "        0.02799445, 0.02321803, 0.03283191, 0.02251778, 0.03283191,\n",
       "        0.09767629, 0.10425242, 0.09434371, 0.11401362, 0.09747822,\n",
       "        0.10615529, 0.08704508, 0.05576517, 0.08234572, 0.08234572,\n",
       "        0.08208812, 0.07747334, 0.09671146, 0.09510067, 0.09064652,\n",
       "        0.09510067, 0.09090097, 0.09090097, 0.0693229 , 0.05874517,\n",
       "        0.07745722, 0.08164162, 0.07423188, 0.07340401, 0.09684444,\n",
       "        0.08262461, 0.0812258 , 0.08811734, 0.08417357, 0.08609185,\n",
       "        0.07106291, 0.04241504, 0.08145595, 0.04749514, 0.07075945,\n",
       "        0.08503576, 0.08765979, 0.08562126, 0.07442205, 0.07465538,\n",
       "        0.09157003, 0.08619062, 0.04302857, 0.07456329, 0.08067896,\n",
       "        0.04600246, 0.05189578, 0.08863632, 0.07612735, 0.0821791 ,\n",
       "        0.07589555, 0.08505665, 0.08982913, 0.0931113 , 0.06466548,\n",
       "        0.04693622, 0.03024975, 0.05935499, 0.05967638, 0.05373329,\n",
       "        0.08820193, 0.07233038, 0.07465538, 0.07465538, 0.08772967,\n",
       "        0.09064652, 0.05281496, 0.07668473, 0.0597856 , 0.07092858,\n",
       "        0.08842496, 0.0781121 , 0.09292082, 0.07811785, 0.09044814,\n",
       "        0.07811785, 0.09322984, 0.07894578, 0.02780766, 0.02780766,\n",
       "        0.03449809, 0.02251778, 0.01888666, 0.03334044, 0.09935049,\n",
       "        0.09796377, 0.10089181, 0.10425242, 0.10204203, 0.10254503,\n",
       "        0.07857233, 0.08234572, 0.02863557, 0.08138084, 0.02812399,\n",
       "        0.03320955, 0.09203434, 0.10055467, 0.09554788, 0.09671146,\n",
       "        0.0985903 , 0.09545936, 0.07174209, 0.07451339, 0.07435238,\n",
       "        0.07053037, 0.05172736, 0.08096632, 0.0916794 , 0.10055467,\n",
       "        0.10055467, 0.09737512, 0.09671146, 0.09671146, 0.05675598,\n",
       "        0.03378192, 0.06070022, 0.05662204, 0.05377743, 0.0869037 ,\n",
       "        0.09154389, 0.07202776, 0.07435407, 0.08303897, 0.07786691,\n",
       "        0.07233038, 0.0730338 , 0.03903246, 0.05823239, 0.07043427,\n",
       "        0.06315471, 0.00947221, 0.0757602 , 0.08584316, 0.08155491,\n",
       "        0.08445574, 0.07583014, 0.08335394, 0.04639977, 0.0463251 ,\n",
       "        0.04513855, 0.054231  , 0.05775808, 0.07800091, 0.07465538,\n",
       "        0.07393126, 0.08429427, 0.09292082, 0.08262461, 0.07465538,\n",
       "        0.0603409 , 0.04513855, 0.05853172, 0.07033457, 0.08457529,\n",
       "        0.04555919, 0.08425058, 0.08844579, 0.07233038, 0.0757602 ,\n",
       "        0.06984118, 0.10106827, 0.01873632, 0.02122282, 0.01873632,\n",
       "        0.03396392, 0.02721358, 0.02122282, 0.08094281, 0.07838407,\n",
       "        0.07838407, 0.07817612, 0.08198156, 0.08066149, 0.0880371 ,\n",
       "        0.08021515, 0.07435012, 0.07014699, 0.07026867, 0.08021515,\n",
       "        0.06830332, 0.07148833, 0.06147743, 0.07645163, 0.06830332,\n",
       "        0.07550192, 0.0528969 , 0.07807783, 0.09267948, 0.07430755,\n",
       "        0.0673474 , 0.05464549, 0.06703395, 0.0712402 , 0.07112528,\n",
       "        0.07592983, 0.06643856, 0.0807071 , 0.05597797, 0.0653419 ,\n",
       "        0.06132926, 0.05391719, 0.05597797, 0.06697397, 0.09417508,\n",
       "        0.08288403, 0.09279023, 0.08288403, 0.07890506, 0.08218958,\n",
       "        0.04188691, 0.04188691, 0.05463365, 0.04188691, 0.05718785,\n",
       "        0.03233696, 0.08753577, 0.07890506, 0.07890506, 0.08288403,\n",
       "        0.07890506, 0.07890506, 0.03823573, 0.03823573, 0.05718785,\n",
       "        0.04188691, 0.02964004, 0.04188691, 0.08288403, 0.07890506,\n",
       "        0.08630799, 0.08753577, 0.08288403, 0.07890506, 0.04188691,\n",
       "        0.03048661, 0.05718785, 0.04188691, 0.0607095 , 0.03823573,\n",
       "        0.07890506, 0.07890506, 0.08288403, 0.09359408, 0.08288403,\n",
       "        0.07711129, 0.02810814, 0.02714274, 0.07170824, 0.02714274,\n",
       "        0.03315057, 0.03287332, 0.08624063, 0.08910637, 0.09112828,\n",
       "        0.08510086, 0.08351124, 0.08624063, 0.10005064, 0.08763414,\n",
       "        0.10089181, 0.09407275, 0.08763414, 0.10005064, 0.0785957 ,\n",
       "        0.06508739, 0.07269264, 0.07105964, 0.06508739, 0.06508739,\n",
       "        0.08010376, 0.09086337, 0.09563332, 0.08064078, 0.09539513,\n",
       "        0.09563332, 0.09328924, 0.0703075 , 0.07056782, 0.07729383,\n",
       "        0.07056782, 0.06671328, 0.07349831, 0.09082916, 0.07589703,\n",
       "        0.08338128, 0.07408753, 0.07252151, 0.06671328, 0.07056782,\n",
       "        0.07698995, 0.07729383, 0.08902032, 0.07729383, 0.09496422,\n",
       "        0.07589703, 0.06042882, 0.06866317, 0.08359601, 0.07648563,\n",
       "        0.07663443, 0.07698995, 0.09978432, 0.06687796, 0.06687796,\n",
       "        0.06687796, 0.08824048, 0.06989549, 0.07268086, 0.07589703,\n",
       "        0.09082916, 0.07589703, 0.07056782, 0.07056782, 0.06687796,\n",
       "        0.07729383, 0.07663443, 0.06687796, 0.07268086, 0.07268086,\n",
       "        0.06693085, 0.07710838, 0.08773548, 0.07264826, 0.07056782,\n",
       "        0.08773548, 0.06687796, 0.1010637 , 0.06687796, 0.06687796,\n",
       "        0.02433977, 0.03692098, 0.03239772, 0.06261441, 0.03349868,\n",
       "        0.02948181, 0.0813128 , 0.09084857, 0.08877784, 0.08624063,\n",
       "        0.09078138, 0.08510086, 0.08503396, 0.10005064, 0.08556407,\n",
       "        0.08556407, 0.0834188 , 0.08806557, 0.0785957 , 0.07709762,\n",
       "        0.07269264, 0.06508739, 0.08596312, 0.08596312, 0.07083001,\n",
       "        0.09563332, 0.09086337, 0.09081224, 0.09081224, 0.09086337,\n",
       "        0.06983096, 0.06983096, 0.06669298, 0.08529054, 0.06347161,\n",
       "        0.08529054, 0.05583826, 0.08359601, 0.09566904, 0.06866317,\n",
       "        0.06866317, 0.09082916, 0.07663443, 0.10212316, 0.07096185,\n",
       "        0.06687796, 0.08120018, 0.07056782, 0.0763217 , 0.09008303,\n",
       "        0.0888965 , 0.06866317, 0.06327769, 0.07011089, 0.07164662,\n",
       "        0.07663443, 0.07663443, 0.11174188, 0.10212316, 0.07056782,\n",
       "        0.06989549, 0.06989549, 0.10115042, 0.07148023, 0.08773548,\n",
       "        0.06866317, 0.07729383, 0.07729383, 0.07056782, 0.06687796,\n",
       "        0.07056782, 0.09978432, 0.07710838, 0.07755577, 0.06192695,\n",
       "        0.07268086, 0.06813901, 0.07589703, 0.06687796, 0.07663443,\n",
       "        0.10212316, 0.07056782, 0.08773548, 0.09882572]),\n",
       " 'rank_test_score': array([497, 503, 497, 496, 504, 494, 476, 354, 375, 392, 449, 451, 458,\n",
       "        474, 417, 439, 482, 455, 254,  39, 272, 279,  53, 181, 406, 454,\n",
       "        457, 294, 456, 428, 193, 366, 284, 121, 243, 309, 431, 403, 403,\n",
       "        432, 463, 357, 112, 352, 321, 335, 332, 325, 441, 395, 414, 485,\n",
       "        409, 422, 250, 379, 400, 363, 333, 289, 420, 388, 301, 348, 453,\n",
       "        351, 282, 352, 203, 363, 339, 250, 466, 394, 429, 421, 425, 461,\n",
       "        250, 244, 291, 155, 330, 329, 473, 502, 497, 489, 500, 489, 331,\n",
       "        376, 382, 305, 338, 344, 436, 418, 446, 446, 440, 426,  23,  21,\n",
       "         40,  21, 235, 235, 391, 386, 238, 247, 198, 397,  49, 159, 133,\n",
       "         68, 261,  75, 310, 415, 407, 383, 173, 274,  93,  84, 241, 218,\n",
       "        120, 315, 462, 326, 239, 437, 450, 307, 234, 115, 242, 108, 134,\n",
       "         50, 337, 324, 378, 136, 277, 412, 320, 199, 218, 218,  92,  40,\n",
       "        408, 278, 452, 296,  67, 393,  58, 169, 174, 169,  51, 192, 492,\n",
       "        492, 479, 500, 491, 486, 367, 334, 361, 376, 359, 319, 430, 446,\n",
       "        480, 442, 481, 475, 109,  14, 272,  23, 181, 135, 336, 217, 292,\n",
       "        178, 433, 396,  60,  14,  14,  29,  23,  23, 322, 328, 340, 358,\n",
       "        302, 295, 112, 202, 233, 156, 172, 199, 184, 423, 438, 253, 223,\n",
       "        460, 161, 163, 186, 124, 312, 240, 411, 314, 342, 360, 419, 355,\n",
       "        218, 191, 123,  58, 159, 218, 304, 342, 424, 402, 283, 416, 129,\n",
       "         66, 199, 161, 289,  78, 483, 487, 483, 477, 495, 487, 385, 398,\n",
       "        398, 401, 381, 389, 349, 444, 405, 443, 435, 444, 259, 308, 204,\n",
       "        281, 259, 190, 434, 350, 356, 171, 365, 410, 255, 297, 303, 138,\n",
       "        249, 185, 188, 114, 384, 248, 188, 165, 237, 263, 158, 263, 224,\n",
       "        258, 368, 368, 216, 368, 194, 387, 285, 224, 224, 263, 224, 224,\n",
       "        345, 345, 194, 368, 413, 368, 263, 224, 187, 285, 263, 224, 368,\n",
       "        427, 194, 368, 168, 345, 224, 224, 263, 167, 263, 313, 478, 467,\n",
       "        390, 467, 469, 459, 298, 257, 270, 287, 280, 298,  54, 245, 361,\n",
       "         88, 245,  54, 131, 125, 175,  87, 125, 125, 122,  40,   8,  85,\n",
       "         17,   8,   2, 151, 140,  30, 140, 179,  36,  79,  61, 104, 164,\n",
       "         82, 179, 140, 275,  30,   4,  30,  86,  61, 316,  94,  37,  28,\n",
       "         69, 275,  47, 205, 205, 205,   3, 105,  99,  61,  79,  61, 140,\n",
       "        140, 205,  30,  69, 205,  99,  99,  83,  76, 116, 327, 140, 116,\n",
       "        205,   1, 205, 205, 471, 470, 464, 380, 465, 472, 306, 271, 323,\n",
       "        298, 341, 287, 311,  54, 317, 317, 293, 256, 131, 139, 175, 125,\n",
       "          5,   5, 152,   8,  40,  45,  45,  40, 110, 110, 183,  18, 177,\n",
       "         18, 262,  37, 103,  94,  94,  79,  69,  11,  90, 205, 197, 140,\n",
       "        137,  27,  20,  94, 130,  52, 157,  69,  69,   7,  11, 140, 105,\n",
       "        105,  57,  89, 116,  94,  30,  30, 140, 205, 140,  47,  76, 153,\n",
       "        166,  99, 154,  61, 205,  69,  11, 140, 116,  91]),\n",
       " 'split0_train_score': array([0.81173957, 0.80062846, 0.81011968, 0.81590623, 0.80318287,\n",
       "        0.81011968, 0.83690976, 0.86703964, 0.83969887, 0.86703964,\n",
       "        0.85945408, 0.87094332, 0.91879611, 0.94488003, 0.95401603,\n",
       "        0.94488003, 0.93737813, 0.94770283, 0.95401603, 0.96699634,\n",
       "        0.95401603, 0.96699634, 0.95401603, 0.96699634, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.81685786,\n",
       "        0.86101307, 0.80829765, 0.80318287, 0.79427258, 0.8199757 ,\n",
       "        0.87335762, 0.86813187, 0.86497438, 0.86497438, 0.87012286,\n",
       "        0.85455978, 0.95401603, 0.95401603, 0.95401603, 0.95401603,\n",
       "        0.95401603, 0.95401603, 0.96699634, 0.97411477, 0.97411477,\n",
       "        0.97411477, 0.95401603, 0.97411477, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.79646179, 0.83899986,\n",
       "        0.84761258, 0.80829765, 0.84411465, 0.80162304, 0.86824539,\n",
       "        0.86998039, 0.85455978, 0.8629415 , 0.86497438, 0.87868132,\n",
       "        0.95401603, 0.95401603, 0.95401603, 0.95401603, 0.96231884,\n",
       "        0.95401603, 0.97411477, 0.97411477, 0.97411477, 0.97411477,\n",
       "        0.95401603, 0.95401603, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.85367307, 0.85367307, 0.80829765,\n",
       "        0.84205731, 0.84693489, 0.85367307, 0.86482804, 0.83008765,\n",
       "        0.87628788, 0.87377326, 0.83894546, 0.87913133, 0.94488003,\n",
       "        0.94488003, 0.94488003, 0.92962921, 0.95401603, 0.94488003,\n",
       "        0.97411477, 0.97411477, 0.97411477, 0.97411477, 0.97411477,\n",
       "        0.97411477, 1.        , 1.        , 1.        , 0.99169719,\n",
       "        1.        , 0.99169719, 0.99169719, 0.99169719, 0.99169719,\n",
       "        0.99169719, 0.99169719, 0.99169719, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.81173957, 0.81550929, 0.79805075, 0.81550929,\n",
       "        0.83392602, 0.8206746 , 0.89381349, 0.86204931, 0.90155083,\n",
       "        0.89321814, 0.90155083, 0.89321814, 0.95401603, 0.9411947 ,\n",
       "        0.94869505, 0.95401603, 0.94869505, 0.95401603, 0.94869505,\n",
       "        0.95401603, 0.95401603, 0.97411477, 0.97411477, 0.95401603,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.8206746 , 0.81550929, 0.81550929, 0.8121179 , 0.80695665,\n",
       "        0.8206746 , 0.89321814, 0.86204931, 0.86204931, 0.86204931,\n",
       "        0.89321814, 0.89321814, 0.95401603, 0.95401603, 0.9411947 ,\n",
       "        0.95401603, 0.95401603, 0.95401603, 0.95401603, 0.97411477,\n",
       "        0.96879274, 0.95401603, 0.94869505, 0.95401603, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split1_train_score': array([0.79546485, 0.82887923, 0.83888634, 0.80239708, 0.79238997,\n",
       "        0.83888634, 0.8549542 , 0.83785777, 0.81059719, 0.86297551,\n",
       "        0.83769955, 0.83769955, 0.93511547, 0.92774368, 0.94434548,\n",
       "        0.91996396, 0.91259216, 0.94434548, 0.95693637, 0.94436926,\n",
       "        0.95693637, 0.94981428, 0.95148936, 0.94436926, 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.98241758, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.80239708,\n",
       "        0.82993804, 0.83888634, 0.83888634, 0.80510131, 0.84003795,\n",
       "        0.83730159, 0.85768879, 0.84949245, 0.88773145, 0.84708645,\n",
       "        0.83092859, 0.94434548, 0.91826156, 0.94434548, 0.94434548,\n",
       "        0.93697368, 0.92935079, 0.95148936, 0.97149711, 0.95148936,\n",
       "        0.97529289, 0.95148936, 0.95148936, 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.98241758, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.79662058, 0.80239708,\n",
       "        0.84857882, 0.81208956, 0.79344877, 0.80137538, 0.81298452,\n",
       "        0.80079365, 0.84949245, 0.84949245, 0.86521061, 0.83730159,\n",
       "        0.90496927, 0.93697368, 0.94434548, 0.91090326, 0.92935079,\n",
       "        0.92935079, 0.95693637, 0.94981428, 0.95519521, 0.96231884,\n",
       "        0.95148936, 0.95693637, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.98241758, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.87004499, 0.87004499, 0.87004499,\n",
       "        0.86311276, 0.87004499, 0.87004499, 0.87009617, 0.87922394,\n",
       "        0.87163089, 0.87163089, 0.88737287, 0.88066129, 0.90496927,\n",
       "        0.89584151, 0.92774368, 0.92935079, 0.92935079, 0.93697368,\n",
       "        0.94436926, 0.94436926, 0.96437502, 0.94436926, 0.94436926,\n",
       "        0.94436926, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.82820818, 0.82820818, 0.82820818, 0.83888634,\n",
       "        0.83358634, 0.83888634, 0.83786465, 0.82887923, 0.82887923,\n",
       "        0.82887923, 0.82887923, 0.82887923, 0.93074353, 0.93347252,\n",
       "        0.92017539, 0.93876521, 0.91636003, 0.92549283, 0.9411781 ,\n",
       "        0.9411781 , 0.9411781 , 0.9411781 , 0.9411781 , 0.9411781 ,\n",
       "        1.        , 1.        , 0.99267399, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.82820818, 0.83358634, 0.83888634, 0.83888634, 0.83888634,\n",
       "        0.82820818, 0.82887923, 0.81967366, 0.82609994, 0.82887923,\n",
       "        0.82887923, 0.82887923, 0.93347252, 0.92160752, 0.93347252,\n",
       "        0.91636003, 0.92433972, 0.92549283, 0.93577797, 0.94651413,\n",
       "        0.93577797, 0.9411781 , 0.9411781 , 0.9411781 , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split2_train_score': array([0.87003968, 0.82142018, 0.86071429, 0.85540828, 0.85892857,\n",
       "        0.86071429, 0.89746791, 0.90654611, 0.88214627, 0.86720856,\n",
       "        0.90654611, 0.86720856, 0.94762971, 0.94762971, 0.94233535,\n",
       "        0.94762971, 0.93876521, 0.94762971, 0.98241758, 0.98241758,\n",
       "        0.97513935, 0.98241758, 0.97513935, 0.97513935, 0.98241758,\n",
       "        0.98241758, 0.98241758, 0.98241758, 0.97513935, 0.98241758,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.88914502,\n",
       "        0.85980335, 0.85476651, 0.88814252, 0.88814252, 0.88048934,\n",
       "        0.88253311, 0.91506892, 0.89138073, 0.89138073, 0.8965074 ,\n",
       "        0.8965074 , 0.94762971, 0.94762971, 0.94651413, 0.95401603,\n",
       "        0.94651413, 0.94762971, 0.97411477, 0.97411477, 0.96564127,\n",
       "        0.98241758, 0.97411477, 0.98241758, 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.98241758, 0.98241758, 0.98241758,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.85892857, 0.88383262,\n",
       "        0.88914502, 0.88914502, 0.85476651, 0.88383262, 0.91447421,\n",
       "        0.89944378, 0.91321915, 0.8965074 , 0.8965074 , 0.90916073,\n",
       "        0.95401603, 0.94762971, 0.94651413, 0.94762971, 0.94762971,\n",
       "        0.94762971, 0.97411477, 0.97411477, 0.98241758, 0.98241758,\n",
       "        0.96564127, 0.98241758, 0.98241758, 1.        , 1.        ,\n",
       "        1.        , 0.98241758, 0.98241758, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.80563795, 0.84145494, 0.84145494,\n",
       "        0.8095004 , 0.8041549 , 0.81280395, 0.88048934, 0.90741575,\n",
       "        0.88048934, 0.87521639, 0.88048934, 0.88048934, 0.93876521,\n",
       "        0.93876521, 0.93876521, 0.93876521, 0.93876521, 0.93876521,\n",
       "        0.96656664, 0.96656664, 0.96656664, 0.96656664, 0.96656664,\n",
       "        0.96656664, 0.99267399, 0.99267399, 0.99267399, 0.99267399,\n",
       "        0.99267399, 0.99267399, 0.99169719, 0.99169719, 0.99169719,\n",
       "        0.99169719, 0.99169719, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.87432468, 0.86876477, 0.84607294, 0.83350679,\n",
       "        0.87432468, 0.86366722, 0.8646152 , 0.8646152 , 0.8646152 ,\n",
       "        0.8646152 , 0.85963486, 0.8646152 , 0.94969155, 0.95780134,\n",
       "        0.95877295, 0.95877295, 0.93074353, 0.95877295, 0.96564127,\n",
       "        0.96564127, 0.96564127, 0.96564127, 0.96656664, 0.96564127,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.83886905, 0.86366722, 0.86876477, 0.86366722, 0.84607294,\n",
       "        0.87432468, 0.85467865, 0.86962469, 0.85963486, 0.86962469,\n",
       "        0.85963486, 0.8646152 , 0.95780134, 0.95780134, 0.95877295,\n",
       "        0.95780134, 0.95877295, 0.93876521, 0.96564127, 0.96656664,\n",
       "        0.96564127, 0.96564127, 0.96564127, 0.96656664, 0.99267399,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split3_train_score': array([0.83975335, 0.84802551, 0.84802551, 0.84802551, 0.84802551,\n",
       "        0.84802551, 0.89925186, 0.89517114, 0.89507134, 0.89517114,\n",
       "        0.87258201, 0.88177293, 0.95946276, 0.97411477, 0.95045177,\n",
       "        0.94333333, 0.93579976, 0.97411477, 0.96699634, 0.96699634,\n",
       "        0.96699634, 0.96699634, 0.96699634, 0.94333333, 1.        ,\n",
       "        0.99169719, 0.99169719, 0.99169719, 0.98241758, 0.99169719,\n",
       "        0.99169719, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.84802551,\n",
       "        0.87285657, 0.88703991, 0.84802551, 0.8428501 , 0.85176646,\n",
       "        0.84794083, 0.88709663, 0.88630631, 0.88630631, 0.87789988,\n",
       "        0.88630631, 0.96656664, 0.96656664, 0.96656664, 0.97411477,\n",
       "        0.95045177, 0.96656664, 0.96699634, 0.96699634, 0.96699634,\n",
       "        0.97411477, 0.96699634, 0.96699634, 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.99169719, 0.99169719, 1.        ,\n",
       "        1.        , 1.        , 0.99169719, 1.        , 0.99169719,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.84802551, 0.87995216,\n",
       "        0.88177293, 0.8428501 , 0.84802551, 0.8428501 , 0.87789988,\n",
       "        0.88709663, 0.87789988, 0.89442802, 0.88630631, 0.89517114,\n",
       "        0.97411477, 0.97411477, 0.96656664, 0.96656664, 0.96656664,\n",
       "        0.95045177, 0.97411477, 0.97411477, 0.97411477, 0.96699634,\n",
       "        0.96699634, 0.97411477, 1.        , 0.99169719, 0.99169719,\n",
       "        1.        , 1.        , 0.99169719, 0.99169719, 0.99169719,\n",
       "        1.        , 0.99169719, 1.        , 0.99169719, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.84802551, 0.84802551, 0.8428501 ,\n",
       "        0.84969281, 0.84802551, 0.85481948, 0.87285657, 0.87654718,\n",
       "        0.87275139, 0.88709663, 0.88177293, 0.90476471, 0.95743064,\n",
       "        0.94963695, 0.96656664, 0.94963695, 0.95877295, 0.95743064,\n",
       "        0.97411477, 0.97411477, 0.97411477, 0.96879274, 0.97411477,\n",
       "        0.97411477, 1.        , 0.99169719, 0.99169719, 0.99169719,\n",
       "        0.99169719, 0.99169719, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.86393544, 0.86393544, 0.88886852, 0.86382741,\n",
       "        0.86393544, 0.85860917, 0.87985762, 0.87985762, 0.87985762,\n",
       "        0.88901099, 0.88386251, 0.88901099, 0.96656664, 0.96656664,\n",
       "        0.96656664, 0.96656664, 0.96656664, 0.96656664, 0.97411477,\n",
       "        0.97411477, 0.97411477, 0.97411477, 0.97411477, 0.97411477,\n",
       "        0.99169719, 1.        , 0.99169719, 0.99169719, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.85343377, 0.86393544, 0.85860917, 0.88886852, 0.88901099,\n",
       "        0.85860917, 0.86763271, 0.88901099, 0.87985762, 0.87985762,\n",
       "        0.87479161, 0.87985762, 0.96656664, 0.96656664, 0.96656664,\n",
       "        0.96656664, 0.96656664, 0.96656664, 0.97411477, 0.97411477,\n",
       "        0.97411477, 0.97411477, 0.97411477, 0.97411477, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split4_train_score': array([0.87932186, 0.83976199, 0.86171998, 0.81447254, 0.84676924,\n",
       "        0.8540424 , 0.89774506, 0.90626253, 0.88227216, 0.90573427,\n",
       "        0.91347267, 0.90808858, 0.98441948, 0.98441948, 0.96954694,\n",
       "        0.98441948, 0.98441948, 0.98441948, 0.98441948, 0.97724316,\n",
       "        0.98441948, 0.98441948, 0.98441948, 0.98441948, 0.98441948,\n",
       "        0.98441948, 0.98441948, 0.98441948, 0.98441948, 0.98441948,\n",
       "        1.        , 1.        , 0.98441948, 1.        , 0.98441948,\n",
       "        0.98441948, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.88459659,\n",
       "        0.88985806, 0.87493249, 0.85112383, 0.88689845, 0.90328105,\n",
       "        0.90056047, 0.88665248, 0.90289453, 0.89101957, 0.90875457,\n",
       "        0.93781311, 0.96954694, 0.96954694, 0.98441948, 0.98441948,\n",
       "        0.98441948, 0.96756548, 0.98441948, 0.98441948, 0.98441948,\n",
       "        0.98441948, 0.98441948, 0.98441948, 0.98441948, 0.98441948,\n",
       "        0.98441948, 0.98441948, 0.98441948, 0.98441948, 1.        ,\n",
       "        1.        , 0.98441948, 0.98441948, 0.98441948, 0.98441948,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.98441948,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.88791462, 0.83297305,\n",
       "        0.88007554, 0.89216994, 0.89216994, 0.85905995, 0.91559654,\n",
       "        0.91808858, 0.93781311, 0.91808858, 0.91808858, 0.91808858,\n",
       "        0.97709402, 0.98441948, 0.98441948, 0.98441948, 0.97709402,\n",
       "        0.98441948, 0.98441948, 0.98441948, 0.98441948, 0.97904429,\n",
       "        0.97904429, 0.98441948, 0.98441948, 0.98441948, 0.98441948,\n",
       "        0.98441948, 0.98441948, 0.98441948, 1.        , 0.98441948,\n",
       "        0.98441948, 0.98441948, 1.        , 0.98441948, 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.98441948, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.83625796, 0.8495927 , 0.81227165,\n",
       "        0.8018497 , 0.81591391, 0.85297384, 0.88201511, 0.87278852,\n",
       "        0.88201511, 0.88201511, 0.87278852, 0.89605275, 0.96861898,\n",
       "        0.95918369, 0.98441948, 0.97709402, 0.95918369, 0.96756548,\n",
       "        0.98441948, 0.98441948, 0.98441948, 0.97621435, 0.97904429,\n",
       "        0.98441948, 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.98441948, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.8552221 , 0.85796445, 0.8571185 , 0.85441931,\n",
       "        0.85441931, 0.85441931, 0.89173011, 0.90657345, 0.88505531,\n",
       "        0.92085719, 0.89286759, 0.87061096, 0.97171997, 0.97171997,\n",
       "        0.97171997, 0.97904429, 0.97171997, 0.98441948, 0.97904429,\n",
       "        0.97904429, 0.97904429, 0.97904429, 0.97904429, 0.97904429,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.8552221 , 0.85441931, 0.8552221 , 0.86478338, 0.86478338,\n",
       "        0.872899  , 0.93917273, 0.9156507 , 0.92375068, 0.87722329,\n",
       "        0.85562962, 0.91588621, 0.98441948, 0.98441948, 0.98441948,\n",
       "        0.97904429, 0.97709402, 0.97904429, 0.97904429, 0.97904429,\n",
       "        0.97904429, 0.97904429, 0.97904429, 0.97904429, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'mean_train_score': array([0.83926386, 0.82774307, 0.84389316, 0.82724193, 0.82985923,\n",
       "        0.84235764, 0.87726576, 0.88257544, 0.86195717, 0.87962582,\n",
       "        0.87795088, 0.87314259, 0.94908471, 0.95575753, 0.95213911,\n",
       "        0.9480453 , 0.94179095, 0.95964246, 0.96895716, 0.96760454,\n",
       "        0.96750151, 0.9701288 , 0.96641211, 0.96285155, 0.99336741,\n",
       "        0.99170685, 0.99170685, 0.99170685, 0.9848788 , 0.99170685,\n",
       "        0.99833944, 1.        , 0.9968839 , 1.        , 0.9968839 ,\n",
       "        0.9968839 , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.84820441,\n",
       "        0.86269382, 0.85278458, 0.84587221, 0.84345299, 0.8591101 ,\n",
       "        0.86833872, 0.88292774, 0.87900968, 0.88428249, 0.88007423,\n",
       "        0.88122304, 0.95642096, 0.95120418, 0.95917235, 0.96218236,\n",
       "        0.95447502, 0.95302573, 0.96880326, 0.97422849, 0.96853224,\n",
       "        0.9780719 , 0.9662072 , 0.97188751, 0.9968839 , 0.9968839 ,\n",
       "        0.9968839 , 0.9968839 , 0.98819037, 0.99170685, 0.99648352,\n",
       "        1.        , 0.9968839 , 0.99522333, 0.9968839 , 0.99522333,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.9968839 ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.83759021, 0.84763095,\n",
       "        0.86943698, 0.84891046, 0.84650508, 0.83774822, 0.87784011,\n",
       "        0.87508061, 0.88659687, 0.88429159, 0.88621745, 0.88768067,\n",
       "        0.95284203, 0.95943074, 0.95917235, 0.95270702, 0.956592  ,\n",
       "        0.95317356, 0.97274003, 0.97131562, 0.97405236, 0.97297836,\n",
       "        0.96343746, 0.97038085, 0.99336741, 0.99522333, 0.99522333,\n",
       "        0.9968839 , 0.99336741, 0.98819037, 0.99833944, 0.99522333,\n",
       "        0.9968839 , 0.99522333, 1.        , 0.99522333, 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.9968839 , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.84272789, 0.85255824, 0.83498387,\n",
       "        0.8332426 , 0.83701484, 0.84886307, 0.87405705, 0.87321261,\n",
       "        0.87663492, 0.87794645, 0.87227382, 0.88821988, 0.94293283,\n",
       "        0.93766148, 0.95247501, 0.94489524, 0.94801774, 0.94912301,\n",
       "        0.96871699, 0.96871699, 0.97271814, 0.96601155, 0.96764195,\n",
       "        0.96871699, 0.9985348 , 0.99687424, 0.99687424, 0.99521368,\n",
       "        0.99375813, 0.99521368, 0.99667888, 0.99667888, 0.99667888,\n",
       "        0.99667888, 0.99667888, 0.99833944, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.84668599, 0.84687643, 0.84366378, 0.84122983,\n",
       "        0.85203836, 0.84725133, 0.87357621, 0.86839496, 0.87199164,\n",
       "        0.87931615, 0.873359  , 0.8692669 , 0.95454754, 0.95415103,\n",
       "        0.953186  , 0.95943302, 0.94681704, 0.95785359, 0.9617347 ,\n",
       "        0.96279889, 0.96279889, 0.96681864, 0.96700372, 0.96279889,\n",
       "        0.99833944, 1.        , 0.99687424, 0.99833944, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.83928154, 0.84622352, 0.84739833, 0.85366467, 0.84914206,\n",
       "        0.85094313, 0.87671629, 0.87120187, 0.87027848, 0.86352683,\n",
       "        0.86243069, 0.87649128, 0.9592552 , 0.9568822 , 0.95688526,\n",
       "        0.95475767, 0.95615787, 0.952777  , 0.96171887, 0.96807092,\n",
       "        0.96467421, 0.96279889, 0.9617347 , 0.96298397, 0.9985348 ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'std_train_score': array([0.03233566, 0.01632363, 0.01888671, 0.02065973, 0.02674533,\n",
       "        0.01764631, 0.02621957, 0.0265908 , 0.0317809 , 0.01739621,\n",
       "        0.02853283, 0.02276824, 0.02223018, 0.02062839, 0.00965668,\n",
       "        0.02070766, 0.02338496, 0.01639638, 0.0125845 , 0.01306099,\n",
       "        0.01129858, 0.01255024, 0.01246694, 0.01646755, 0.00814786,\n",
       "        0.00744243, 0.00744243, 0.00744243, 0.00819553, 0.00744243,\n",
       "        0.00332112, 0.        , 0.00623221, 0.        , 0.00623221,\n",
       "        0.00623221, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.03487542,\n",
       "        0.01962294, 0.02771329, 0.02716681, 0.03943245, 0.02952058,\n",
       "        0.02299691, 0.0195971 , 0.01920951, 0.00984447, 0.02137551,\n",
       "        0.03661242, 0.01004105, 0.01832136, 0.01482395, 0.01475401,\n",
       "        0.01601712, 0.01403824, 0.01075527, 0.00572095, 0.0108143 ,\n",
       "        0.00443209, 0.01232947, 0.0119407 , 0.00623221, 0.00623221,\n",
       "        0.00623221, 0.00623221, 0.00682107, 0.00744243, 0.00703297,\n",
       "        0.        , 0.00623221, 0.0062866 , 0.00623221, 0.0062866 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.00623221,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.03596338, 0.03062899,\n",
       "        0.01769253, 0.03614446, 0.03154846, 0.03234811, 0.03759233,\n",
       "        0.04032914, 0.03408988, 0.02474274, 0.02007095, 0.02849976,\n",
       "        0.0258273 , 0.01739517, 0.01482395, 0.02438366, 0.0165833 ,\n",
       "        0.01779148, 0.00885251, 0.01146756, 0.01032525, 0.00743769,\n",
       "        0.00992588, 0.0126844 , 0.00814786, 0.0062866 , 0.0062866 ,\n",
       "        0.00623221, 0.00814786, 0.00682107, 0.00332112, 0.0062866 ,\n",
       "        0.00623221, 0.0062866 , 0.        , 0.0062866 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.00623221, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.02150167, 0.00958804, 0.02263198,\n",
       "        0.02362093, 0.02381452, 0.01910208, 0.00643443, 0.02480747,\n",
       "        0.00409989, 0.00574517, 0.01730175, 0.01034003, 0.02159795,\n",
       "        0.02194927, 0.02037795, 0.01772853, 0.0119197 , 0.01167934,\n",
       "        0.01343336, 0.01343336, 0.00704657, 0.0113683 , 0.01230108,\n",
       "        0.01343336, 0.0029304 , 0.0038407 , 0.0038407 , 0.00392426,\n",
       "        0.00584047, 0.00392426, 0.00406753, 0.00406753, 0.00406753,\n",
       "        0.00406753, 0.00406753, 0.00332112, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.02322494, 0.02109718, 0.0301653 , 0.01680058,\n",
       "        0.01620138, 0.01565987, 0.02066003, 0.02531812, 0.02457385,\n",
       "        0.03089632, 0.02627733, 0.02288274, 0.01435162, 0.01463972,\n",
       "        0.01824079, 0.01335985, 0.02097483, 0.01920653, 0.01456541,\n",
       "        0.0137451 , 0.0137451 , 0.01352595, 0.0135149 , 0.0137451 ,\n",
       "        0.00332112, 0.        , 0.0038407 , 0.00332112, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.01358966, 0.01891152, 0.01861604, 0.02610564, 0.02730711,\n",
       "        0.02245256, 0.03749579, 0.03173098, 0.03188663, 0.01840712,\n",
       "        0.02135617, 0.02915829, 0.01661931, 0.02052049, 0.01816467,\n",
       "        0.02104036, 0.01772279, 0.01909144, 0.01550147, 0.01149286,\n",
       "        0.01515595, 0.0137451 , 0.01456541, 0.01378829, 0.0029304 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ])}"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid Search 2\n",
    "\n",
    "# Usando um grid completo de todos os parâmetros\n",
    "param_grid = {\"max_depth\": range(3,10,1),\n",
    "              \"min_samples_split\": range(1,4),\n",
    "              \"max_features\": ['sqrt', 'log2'],\n",
    "              \"criterion\": ['gini', 'entropy', 'log_loss'],\n",
    "              \"n_estimators\": range(400,600,100),\n",
    "              \"bootstrap\": [True, False]}\n",
    "\n",
    "# Executando o Grid Search\n",
    "grid_search = GridSearchCV(modelo4_multi, param_grid = param_grid, return_train_score = True, scoring = 'f1_macro')\n",
    "start = time.time()\n",
    "grid_search.fit(X_falha_treino, y_falha_treino)\n",
    "\n",
    "print(\"GridSearchCV executou em %.2f segundos para todas as combinações de candidatos a parâmetros do modelo.\"\n",
    "      % (time.time() - start))\n",
    "grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "7ee1211b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 0.0, 'learning_rate': 0.5, 'max_depth': 3}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "fd3983a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41dfbc3",
   "metadata": {},
   "source": [
    "A segunda tentativa de otimização não resultou em uma melhora expressiva da métrica, vamos ver como fica a matriz de confusão e a acurácia do modelo em teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "6913febb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de confusão\n",
      " [[18  1  0  0  0]\n",
      " [ 1 11  0  0  1]\n",
      " [ 2  0  8  5  1]\n",
      " [ 0  0  0  3  0]\n",
      " [ 0  0  0  1  6]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Modelo': 'XGBoost Classifier Grid Search 2',\n",
       " 'Versão': 'Otimizada',\n",
       " 'Precision': 0.7714285714285715,\n",
       " 'Recall': 0.8301330248698668,\n",
       " 'F1 Score': 0.7493333333333332,\n",
       " 'Acurácia': 0.7931034482758621}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsoes_multi = grid_search.predict(X_falha_val)\n",
    "\n",
    "# Avaliação do modelo\n",
    "# Matriz de confusão\n",
    "print('\\nMatriz de confusão\\n', confusion_matrix(y_falha_val, previsoes_multi))\n",
    "\n",
    "# Dicionário de métricas e metadados\n",
    "dict_model =   {'Modelo': 'XGBoost Classifier Grid Search 2',\n",
    "                'Versão': 'Otimizada',\n",
    "                'Precision':precision_score(y_falha_val, previsoes_multi, average = 'macro', zero_division=0),\n",
    "                'Recall':recall_score(y_falha_val, previsoes_multi, average = 'macro', zero_division=0),\n",
    "                'F1 Score':f1_score(y_falha_val, previsoes_multi, average = 'macro', zero_division=0),\n",
    "                'Acurácia':accuracy_score(y_falha_val, previsoes_multi)}\n",
    "\n",
    "dict_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7229dcc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 3, 4, 1, 0, 0, 2, 0, 3, 4, 1, 1, 0, 4, 2, 4, 1, 2, 0, 0, 4,\n",
       "       0, 1, 0, 1, 2, 0, 0, 1, 3, 1, 3, 0, 0, 1, 0, 3, 0, 4, 3, 0, 3, 0,\n",
       "       2, 0, 1, 4, 2, 2, 1, 2, 0, 4, 0, 3, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsoes_multi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7797489",
   "metadata": {},
   "source": [
    "No nosso conjunto de dados de validação, o modelo acertou todas 48 das 58 previsões, atingindo 82,75% de acurácia. Vamos usar esse como o segundo modelo do nosso pipeline para fazer as previsões completas e ver como ficam as métricas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f243d43a",
   "metadata": {},
   "source": [
    "# Avaliação do pipeline completo\n",
    "\n",
    "Ao longo da modelagem, construímos 2 modelos preditivos. Um de classificação binária, para prever se havia ou não falha nas máquinas, e outro de classificação multiclasse, para prever se, dado que o modelo previu que havia uma falha, que tipo de falha ela seria. O segundo modelo ainda pode classificar como \"No Failure\", sendo assim um segundo filtro. \n",
    "\n",
    "Avaliamos cada modelo e suas previsões separadamente, mas é interessante prever "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "70b6872c",
   "metadata": {},
   "outputs": [],
   "source": [
    "?np.where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "2f99132a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_temperature_k</th>\n",
       "      <th>process_temperature_k</th>\n",
       "      <th>rotational_speed_rpm</th>\n",
       "      <th>torque_nm</th>\n",
       "      <th>tool_wear_min</th>\n",
       "      <th>H</th>\n",
       "      <th>L</th>\n",
       "      <th>M</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5089</th>\n",
       "      <td>0.206892</td>\n",
       "      <td>0.948209</td>\n",
       "      <td>0.698529</td>\n",
       "      <td>-1.078106</td>\n",
       "      <td>0.524390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028</th>\n",
       "      <td>0.307330</td>\n",
       "      <td>-0.059381</td>\n",
       "      <td>-0.499925</td>\n",
       "      <td>0.232524</td>\n",
       "      <td>0.686992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>1.060613</td>\n",
       "      <td>0.881037</td>\n",
       "      <td>-0.691228</td>\n",
       "      <td>0.402605</td>\n",
       "      <td>0.174797</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4076</th>\n",
       "      <td>0.457986</td>\n",
       "      <td>0.612346</td>\n",
       "      <td>-0.342382</td>\n",
       "      <td>0.142480</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2330</th>\n",
       "      <td>0.809518</td>\n",
       "      <td>0.343655</td>\n",
       "      <td>0.360936</td>\n",
       "      <td>-0.777961</td>\n",
       "      <td>0.008130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6252</th>\n",
       "      <td>-1.249456</td>\n",
       "      <td>-1.335661</td>\n",
       "      <td>2.785976</td>\n",
       "      <td>-2.338711</td>\n",
       "      <td>0.520325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6532</th>\n",
       "      <td>-0.747267</td>\n",
       "      <td>-0.529589</td>\n",
       "      <td>1.030495</td>\n",
       "      <td>-1.068101</td>\n",
       "      <td>0.691057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6002</th>\n",
       "      <td>-1.400113</td>\n",
       "      <td>-1.335661</td>\n",
       "      <td>0.940470</td>\n",
       "      <td>-1.408264</td>\n",
       "      <td>0.813008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>-1.902302</td>\n",
       "      <td>-2.141734</td>\n",
       "      <td>0.659143</td>\n",
       "      <td>-0.898019</td>\n",
       "      <td>0.552846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>-1.098799</td>\n",
       "      <td>-0.663935</td>\n",
       "      <td>-0.460539</td>\n",
       "      <td>0.112466</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1667 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      air_temperature_k  process_temperature_k  rotational_speed_rpm  \\\n",
       "5089           0.206892               0.948209              0.698529   \n",
       "2028           0.307330              -0.059381             -0.499925   \n",
       "2438           1.060613               0.881037             -0.691228   \n",
       "4076           0.457986               0.612346             -0.342382   \n",
       "2330           0.809518               0.343655              0.360936   \n",
       "...                 ...                    ...                   ...   \n",
       "6252          -1.249456              -1.335661              2.785976   \n",
       "6532          -0.747267              -0.529589              1.030495   \n",
       "6002          -1.400113              -1.335661              0.940470   \n",
       "664           -1.902302              -2.141734              0.659143   \n",
       "454           -1.098799              -0.663935             -0.460539   \n",
       "\n",
       "      torque_nm  tool_wear_min    H    L    M  prediction  \n",
       "5089  -1.078106       0.524390  0.0  1.0  0.0           1  \n",
       "2028   0.232524       0.686992  0.0  0.0  1.0           1  \n",
       "2438   0.402605       0.174797  0.0  1.0  0.0           4  \n",
       "4076   0.142480       0.406504  0.0  1.0  0.0           1  \n",
       "2330  -0.777961       0.008130  1.0  0.0  0.0           1  \n",
       "...         ...            ...  ...  ...  ...         ...  \n",
       "6252  -2.338711       0.520325  0.0  0.0  1.0           1  \n",
       "6532  -1.068101       0.691057  0.0  0.0  1.0           1  \n",
       "6002  -1.408264       0.813008  0.0  1.0  0.0           1  \n",
       "664   -0.898019       0.552846  0.0  1.0  0.0           1  \n",
       "454    0.112466       0.000000  0.0  1.0  0.0           1  \n",
       "\n",
       "[1667 rows x 9 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_bin = modelo3.predict(X_val) # Previsoes do modelo binario\n",
    "\n",
    "validacao_com_prev = X_val.copy()\n",
    "validacao_com_prev['prediction'] = prev_bin\n",
    "\n",
    "prev_falha = X_val[prev_bin == 0] # Registros em que o primeiro modelo previu falha\n",
    "\n",
    "prev_multi = grid_search.predict(prev_falha)# Previsões do modelo multiclasse\n",
    "prev_multi = np.where(prev_multi == 0, prev_multi, prev_multi+1) # Convertendo de volta para o encoding original\n",
    "\n",
    "validacao_com_prev_slice =  prev_falha.copy()\n",
    "validacao_com_prev_slice['prediction'] = prev_multi\n",
    "\n",
    "validacao_com_prev.loc[prev_falha.index] = validacao_com_prev_slice\n",
    "\n",
    "validacao_com_prev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c3084130",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  12,    7,    0,    0,    0,    0],\n",
       "       [   5, 1557,    4,    3,   22,   18],\n",
       "       [   1,    3,    9,    0,    0,    0],\n",
       "       [   2,   12,    0,    2,    0,    0],\n",
       "       [   0,    3,    0,    0,    0,    0],\n",
       "       [   0,    6,    0,    0,    0,    1]], dtype=int64)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matriz de confusão\n",
    "confusion_matrix(y_val,validacao_com_prev['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "cb7e3b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9484103179364127"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_val, validacao_com_prev['prediction'], average = 'weighted', zero_division=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a60de28",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_val, validacao_com_prev['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e620d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c63b6317",
   "metadata": {},
   "source": [
    "Atingimos um F1 Score de 98,47%. Podemos então partir para previsão em novos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6e1e29",
   "metadata": {},
   "source": [
    "# Previsões para o conjunto sem labels\n",
    "\n",
    "O objetivo final da modelagem era utilizar o modelo para prever o tipo de falha em 3333 registros que estão armazenados na variável _df\\_teste_. Para isso, contudo, precisamos aplicar todas as transformações que foram feitas na etapa de pré-processamento, como encoding, padronização e normalização. O LabelEncoding da variável target não é necessário visto que esse conjunto de dados não possui labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "4ab15d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste = pd.read_csv(\"desafio_manutencao_preditiva_teste.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "2a41e892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_temperature_k</th>\n",
       "      <th>process_temperature_k</th>\n",
       "      <th>rotational_speed_rpm</th>\n",
       "      <th>torque_nm</th>\n",
       "      <th>tool_wear_min</th>\n",
       "      <th>H</th>\n",
       "      <th>L</th>\n",
       "      <th>M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.249456</td>\n",
       "      <td>-0.932625</td>\n",
       "      <td>1.435606</td>\n",
       "      <td>-1.338230</td>\n",
       "      <td>0.284553</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.357548</td>\n",
       "      <td>0.343655</td>\n",
       "      <td>-0.010416</td>\n",
       "      <td>0.732764</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.400113</td>\n",
       "      <td>-1.066971</td>\n",
       "      <td>-0.438033</td>\n",
       "      <td>0.202509</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.295297</td>\n",
       "      <td>-0.596762</td>\n",
       "      <td>0.743541</td>\n",
       "      <td>-0.417789</td>\n",
       "      <td>0.276423</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.064991</td>\n",
       "      <td>2.090145</td>\n",
       "      <td>0.068356</td>\n",
       "      <td>-0.918029</td>\n",
       "      <td>0.036585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3328</th>\n",
       "      <td>1.261488</td>\n",
       "      <td>1.284073</td>\n",
       "      <td>-1.304521</td>\n",
       "      <td>1.963354</td>\n",
       "      <td>0.699187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3329</th>\n",
       "      <td>0.357548</td>\n",
       "      <td>0.679519</td>\n",
       "      <td>-0.702481</td>\n",
       "      <td>1.192985</td>\n",
       "      <td>0.369919</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3330</th>\n",
       "      <td>0.407767</td>\n",
       "      <td>0.813864</td>\n",
       "      <td>-0.319876</td>\n",
       "      <td>-0.157664</td>\n",
       "      <td>0.735772</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3331</th>\n",
       "      <td>1.412145</td>\n",
       "      <td>1.485591</td>\n",
       "      <td>-0.162333</td>\n",
       "      <td>-0.357760</td>\n",
       "      <td>0.211382</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3332</th>\n",
       "      <td>0.056235</td>\n",
       "      <td>-0.529589</td>\n",
       "      <td>0.839192</td>\n",
       "      <td>-1.238182</td>\n",
       "      <td>0.386179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3333 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      air_temperature_k  process_temperature_k  rotational_speed_rpm  \\\n",
       "0             -1.249456              -0.932625              1.435606   \n",
       "1              0.357548               0.343655             -0.010416   \n",
       "2             -1.400113              -1.066971             -0.438033   \n",
       "3             -0.295297              -0.596762              0.743541   \n",
       "4              2.064991               2.090145              0.068356   \n",
       "...                 ...                    ...                   ...   \n",
       "3328           1.261488               1.284073             -1.304521   \n",
       "3329           0.357548               0.679519             -0.702481   \n",
       "3330           0.407767               0.813864             -0.319876   \n",
       "3331           1.412145               1.485591             -0.162333   \n",
       "3332           0.056235              -0.529589              0.839192   \n",
       "\n",
       "      torque_nm  tool_wear_min    H    L    M  \n",
       "0     -1.338230       0.284553  0.0  1.0  0.0  \n",
       "1      0.732764       0.780488  0.0  1.0  0.0  \n",
       "2      0.202509       0.166667  0.0  1.0  0.0  \n",
       "3     -0.417789       0.276423  0.0  1.0  0.0  \n",
       "4     -0.918029       0.036585  0.0  1.0  0.0  \n",
       "...         ...            ...  ...  ...  ...  \n",
       "3328   1.963354       0.699187  0.0  1.0  0.0  \n",
       "3329   1.192985       0.369919  0.0  1.0  0.0  \n",
       "3330  -0.157664       0.735772  0.0  1.0  0.0  \n",
       "3331  -0.357760       0.211382  0.0  1.0  0.0  \n",
       "3332  -1.238182       0.386179  0.0  0.0  1.0  \n",
       "\n",
       "[3333 rows x 8 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_teste = df_teste.drop(columns = ['udi', 'product_id'])\n",
    "\n",
    "# One Hot Encoding\n",
    "cat_encoded_teste = onehot.transform(df_teste[[categorical]])\n",
    "df_teste[onehot.categories_[0]] = cat_encoded_teste.toarray()\n",
    "df_teste.drop(columns='type', inplace = True)\n",
    "\n",
    "# Scaling\n",
    "df_teste[scale] = scaler.transform(df_teste[scale])\n",
    "\n",
    "# Normalizing\n",
    "df_teste[normalize] = normalizer.transform(df_teste[normalize])\n",
    "\n",
    "df_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "ad18ea63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Previsões do Modelo de classificação binária\n",
    "previsoes_finais_bin = modelo3.predict(df_teste)\n",
    "previsoes_finais_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "4481c126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_temperature_k</th>\n",
       "      <th>process_temperature_k</th>\n",
       "      <th>rotational_speed_rpm</th>\n",
       "      <th>torque_nm</th>\n",
       "      <th>tool_wear_min</th>\n",
       "      <th>H</th>\n",
       "      <th>L</th>\n",
       "      <th>M</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.249456</td>\n",
       "      <td>-0.932625</td>\n",
       "      <td>1.435606</td>\n",
       "      <td>-1.338230</td>\n",
       "      <td>0.284553</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.357548</td>\n",
       "      <td>0.343655</td>\n",
       "      <td>-0.010416</td>\n",
       "      <td>0.732764</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.400113</td>\n",
       "      <td>-1.066971</td>\n",
       "      <td>-0.438033</td>\n",
       "      <td>0.202509</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.295297</td>\n",
       "      <td>-0.596762</td>\n",
       "      <td>0.743541</td>\n",
       "      <td>-0.417789</td>\n",
       "      <td>0.276423</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.064991</td>\n",
       "      <td>2.090145</td>\n",
       "      <td>0.068356</td>\n",
       "      <td>-0.918029</td>\n",
       "      <td>0.036585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3328</th>\n",
       "      <td>1.261488</td>\n",
       "      <td>1.284073</td>\n",
       "      <td>-1.304521</td>\n",
       "      <td>1.963354</td>\n",
       "      <td>0.699187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3329</th>\n",
       "      <td>0.357548</td>\n",
       "      <td>0.679519</td>\n",
       "      <td>-0.702481</td>\n",
       "      <td>1.192985</td>\n",
       "      <td>0.369919</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3330</th>\n",
       "      <td>0.407767</td>\n",
       "      <td>0.813864</td>\n",
       "      <td>-0.319876</td>\n",
       "      <td>-0.157664</td>\n",
       "      <td>0.735772</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3331</th>\n",
       "      <td>1.412145</td>\n",
       "      <td>1.485591</td>\n",
       "      <td>-0.162333</td>\n",
       "      <td>-0.357760</td>\n",
       "      <td>0.211382</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3332</th>\n",
       "      <td>0.056235</td>\n",
       "      <td>-0.529589</td>\n",
       "      <td>0.839192</td>\n",
       "      <td>-1.238182</td>\n",
       "      <td>0.386179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3333 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      air_temperature_k  process_temperature_k  rotational_speed_rpm  \\\n",
       "0             -1.249456              -0.932625              1.435606   \n",
       "1              0.357548               0.343655             -0.010416   \n",
       "2             -1.400113              -1.066971             -0.438033   \n",
       "3             -0.295297              -0.596762              0.743541   \n",
       "4              2.064991               2.090145              0.068356   \n",
       "...                 ...                    ...                   ...   \n",
       "3328           1.261488               1.284073             -1.304521   \n",
       "3329           0.357548               0.679519             -0.702481   \n",
       "3330           0.407767               0.813864             -0.319876   \n",
       "3331           1.412145               1.485591             -0.162333   \n",
       "3332           0.056235              -0.529589              0.839192   \n",
       "\n",
       "      torque_nm  tool_wear_min    H    L    M  prediction  \n",
       "0     -1.338230       0.284553  0.0  1.0  0.0           1  \n",
       "1      0.732764       0.780488  0.0  1.0  0.0           1  \n",
       "2      0.202509       0.166667  0.0  1.0  0.0           1  \n",
       "3     -0.417789       0.276423  0.0  1.0  0.0           1  \n",
       "4     -0.918029       0.036585  0.0  1.0  0.0           1  \n",
       "...         ...            ...  ...  ...  ...         ...  \n",
       "3328   1.963354       0.699187  0.0  1.0  0.0           1  \n",
       "3329   1.192985       0.369919  0.0  1.0  0.0           1  \n",
       "3330  -0.157664       0.735772  0.0  1.0  0.0           1  \n",
       "3331  -0.357760       0.211382  0.0  1.0  0.0           1  \n",
       "3332  -1.238182       0.386179  0.0  0.0  1.0           1  \n",
       "\n",
       "[3333 rows x 9 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Salvando os resultados intermediários num novo DataFrame\n",
    "df_final = df_teste.copy()\n",
    "df_final['prediction'] = previsoes_finais_bin\n",
    "\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "84e0fb3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_temperature_k</th>\n",
       "      <th>process_temperature_k</th>\n",
       "      <th>rotational_speed_rpm</th>\n",
       "      <th>torque_nm</th>\n",
       "      <th>tool_wear_min</th>\n",
       "      <th>H</th>\n",
       "      <th>L</th>\n",
       "      <th>M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.211270</td>\n",
       "      <td>0.746691</td>\n",
       "      <td>-0.966928</td>\n",
       "      <td>1.433100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1.412145</td>\n",
       "      <td>0.410828</td>\n",
       "      <td>-0.381768</td>\n",
       "      <td>0.102461</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.960175</td>\n",
       "      <td>-0.260899</td>\n",
       "      <td>-0.719360</td>\n",
       "      <td>0.892841</td>\n",
       "      <td>0.906504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>1.060613</td>\n",
       "      <td>0.679519</td>\n",
       "      <td>0.203393</td>\n",
       "      <td>-0.597875</td>\n",
       "      <td>0.873984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>-0.596610</td>\n",
       "      <td>0.410828</td>\n",
       "      <td>1.491871</td>\n",
       "      <td>-1.468293</td>\n",
       "      <td>0.849593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3309</th>\n",
       "      <td>-1.550769</td>\n",
       "      <td>-1.470007</td>\n",
       "      <td>-0.775626</td>\n",
       "      <td>1.703230</td>\n",
       "      <td>0.821138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3310</th>\n",
       "      <td>-1.500550</td>\n",
       "      <td>-1.470007</td>\n",
       "      <td>-1.248255</td>\n",
       "      <td>2.113426</td>\n",
       "      <td>0.813008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3311</th>\n",
       "      <td>1.713458</td>\n",
       "      <td>1.216900</td>\n",
       "      <td>-0.769999</td>\n",
       "      <td>1.293033</td>\n",
       "      <td>0.845528</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3313</th>\n",
       "      <td>2.215647</td>\n",
       "      <td>2.493181</td>\n",
       "      <td>-0.162333</td>\n",
       "      <td>-0.507832</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3315</th>\n",
       "      <td>-0.998362</td>\n",
       "      <td>-0.999798</td>\n",
       "      <td>-0.612456</td>\n",
       "      <td>-0.237702</td>\n",
       "      <td>0.894309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      air_temperature_k  process_temperature_k  rotational_speed_rpm  \\\n",
       "41             1.211270               0.746691             -0.966928   \n",
       "92             1.412145               0.410828             -0.381768   \n",
       "139            0.960175              -0.260899             -0.719360   \n",
       "143            1.060613               0.679519              0.203393   \n",
       "175           -0.596610               0.410828              1.491871   \n",
       "...                 ...                    ...                   ...   \n",
       "3309          -1.550769              -1.470007             -0.775626   \n",
       "3310          -1.500550              -1.470007             -1.248255   \n",
       "3311           1.713458               1.216900             -0.769999   \n",
       "3313           2.215647               2.493181             -0.162333   \n",
       "3315          -0.998362              -0.999798             -0.612456   \n",
       "\n",
       "      torque_nm  tool_wear_min    H    L    M  \n",
       "41     1.433100       0.000000  0.0  0.0  1.0  \n",
       "92     0.102461       0.833333  0.0  1.0  0.0  \n",
       "139    0.892841       0.906504  0.0  1.0  0.0  \n",
       "143   -0.597875       0.873984  0.0  0.0  1.0  \n",
       "175   -1.468293       0.849593  0.0  1.0  0.0  \n",
       "...         ...            ...  ...  ...  ...  \n",
       "3309   1.703230       0.821138  0.0  1.0  0.0  \n",
       "3310   2.113426       0.813008  0.0  1.0  0.0  \n",
       "3311   1.293033       0.845528  0.0  1.0  0.0  \n",
       "3313  -0.507832       0.833333  0.0  1.0  0.0  \n",
       "3315  -0.237702       0.894309  0.0  1.0  0.0  \n",
       "\n",
       "[155 rows x 8 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conjunto de dados cujo modelo de classificação binária previu como falha\n",
    "df_teste2 = df_teste[previsoes_finais_bin == 0]\n",
    "df_teste2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "976cfddc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Previsões do Modelo de classificação multiclasse\n",
    "previsoes_finais = grid_search.predict(df_teste2)\n",
    "previsoes_finais = np.where(previsoes_finais == 0, previsoes_finais, previsoes_finais+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "58b0f08e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_temperature_k</th>\n",
       "      <th>process_temperature_k</th>\n",
       "      <th>rotational_speed_rpm</th>\n",
       "      <th>torque_nm</th>\n",
       "      <th>tool_wear_min</th>\n",
       "      <th>H</th>\n",
       "      <th>L</th>\n",
       "      <th>M</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.211270</td>\n",
       "      <td>0.746691</td>\n",
       "      <td>-0.966928</td>\n",
       "      <td>1.433100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1.412145</td>\n",
       "      <td>0.410828</td>\n",
       "      <td>-0.381768</td>\n",
       "      <td>0.102461</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.960175</td>\n",
       "      <td>-0.260899</td>\n",
       "      <td>-0.719360</td>\n",
       "      <td>0.892841</td>\n",
       "      <td>0.906504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>1.060613</td>\n",
       "      <td>0.679519</td>\n",
       "      <td>0.203393</td>\n",
       "      <td>-0.597875</td>\n",
       "      <td>0.873984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>-0.596610</td>\n",
       "      <td>0.410828</td>\n",
       "      <td>1.491871</td>\n",
       "      <td>-1.468293</td>\n",
       "      <td>0.849593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3309</th>\n",
       "      <td>-1.550769</td>\n",
       "      <td>-1.470007</td>\n",
       "      <td>-0.775626</td>\n",
       "      <td>1.703230</td>\n",
       "      <td>0.821138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3310</th>\n",
       "      <td>-1.500550</td>\n",
       "      <td>-1.470007</td>\n",
       "      <td>-1.248255</td>\n",
       "      <td>2.113426</td>\n",
       "      <td>0.813008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3311</th>\n",
       "      <td>1.713458</td>\n",
       "      <td>1.216900</td>\n",
       "      <td>-0.769999</td>\n",
       "      <td>1.293033</td>\n",
       "      <td>0.845528</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3313</th>\n",
       "      <td>2.215647</td>\n",
       "      <td>2.493181</td>\n",
       "      <td>-0.162333</td>\n",
       "      <td>-0.507832</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3315</th>\n",
       "      <td>-0.998362</td>\n",
       "      <td>-0.999798</td>\n",
       "      <td>-0.612456</td>\n",
       "      <td>-0.237702</td>\n",
       "      <td>0.894309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      air_temperature_k  process_temperature_k  rotational_speed_rpm  \\\n",
       "41             1.211270               0.746691             -0.966928   \n",
       "92             1.412145               0.410828             -0.381768   \n",
       "139            0.960175              -0.260899             -0.719360   \n",
       "143            1.060613               0.679519              0.203393   \n",
       "175           -0.596610               0.410828              1.491871   \n",
       "...                 ...                    ...                   ...   \n",
       "3309          -1.550769              -1.470007             -0.775626   \n",
       "3310          -1.500550              -1.470007             -1.248255   \n",
       "3311           1.713458               1.216900             -0.769999   \n",
       "3313           2.215647               2.493181             -0.162333   \n",
       "3315          -0.998362              -0.999798             -0.612456   \n",
       "\n",
       "      torque_nm  tool_wear_min    H    L    M  prediction  \n",
       "41     1.433100       0.000000  0.0  0.0  1.0           0  \n",
       "92     0.102461       0.833333  0.0  1.0  0.0           5  \n",
       "139    0.892841       0.906504  0.0  1.0  0.0           2  \n",
       "143   -0.597875       0.873984  0.0  0.0  1.0           5  \n",
       "175   -1.468293       0.849593  0.0  1.0  0.0           5  \n",
       "...         ...            ...  ...  ...  ...         ...  \n",
       "3309   1.703230       0.821138  0.0  1.0  0.0           2  \n",
       "3310   2.113426       0.813008  0.0  1.0  0.0           2  \n",
       "3311   1.293033       0.845528  0.0  1.0  0.0           2  \n",
       "3313  -0.507832       0.833333  0.0  1.0  0.0           4  \n",
       "3315  -0.237702       0.894309  0.0  1.0  0.0           5  \n",
       "\n",
       "[155 rows x 9 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_slice = df_teste2.copy()\n",
    "df_final_slice['prediction'] = previsoes_finais\n",
    "\n",
    "df_final_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "7bb54c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.loc[df_final_slice.index] = df_final_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "204932ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_temperature_k</th>\n",
       "      <th>process_temperature_k</th>\n",
       "      <th>rotational_speed_rpm</th>\n",
       "      <th>torque_nm</th>\n",
       "      <th>tool_wear_min</th>\n",
       "      <th>H</th>\n",
       "      <th>L</th>\n",
       "      <th>M</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.249456</td>\n",
       "      <td>-0.932625</td>\n",
       "      <td>1.435606</td>\n",
       "      <td>-1.338230</td>\n",
       "      <td>0.284553</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.357548</td>\n",
       "      <td>0.343655</td>\n",
       "      <td>-0.010416</td>\n",
       "      <td>0.732764</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.400113</td>\n",
       "      <td>-1.066971</td>\n",
       "      <td>-0.438033</td>\n",
       "      <td>0.202509</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.295297</td>\n",
       "      <td>-0.596762</td>\n",
       "      <td>0.743541</td>\n",
       "      <td>-0.417789</td>\n",
       "      <td>0.276423</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.064991</td>\n",
       "      <td>2.090145</td>\n",
       "      <td>0.068356</td>\n",
       "      <td>-0.918029</td>\n",
       "      <td>0.036585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3328</th>\n",
       "      <td>1.261488</td>\n",
       "      <td>1.284073</td>\n",
       "      <td>-1.304521</td>\n",
       "      <td>1.963354</td>\n",
       "      <td>0.699187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3329</th>\n",
       "      <td>0.357548</td>\n",
       "      <td>0.679519</td>\n",
       "      <td>-0.702481</td>\n",
       "      <td>1.192985</td>\n",
       "      <td>0.369919</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3330</th>\n",
       "      <td>0.407767</td>\n",
       "      <td>0.813864</td>\n",
       "      <td>-0.319876</td>\n",
       "      <td>-0.157664</td>\n",
       "      <td>0.735772</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3331</th>\n",
       "      <td>1.412145</td>\n",
       "      <td>1.485591</td>\n",
       "      <td>-0.162333</td>\n",
       "      <td>-0.357760</td>\n",
       "      <td>0.211382</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3332</th>\n",
       "      <td>0.056235</td>\n",
       "      <td>-0.529589</td>\n",
       "      <td>0.839192</td>\n",
       "      <td>-1.238182</td>\n",
       "      <td>0.386179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3333 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      air_temperature_k  process_temperature_k  rotational_speed_rpm  \\\n",
       "0             -1.249456              -0.932625              1.435606   \n",
       "1              0.357548               0.343655             -0.010416   \n",
       "2             -1.400113              -1.066971             -0.438033   \n",
       "3             -0.295297              -0.596762              0.743541   \n",
       "4              2.064991               2.090145              0.068356   \n",
       "...                 ...                    ...                   ...   \n",
       "3328           1.261488               1.284073             -1.304521   \n",
       "3329           0.357548               0.679519             -0.702481   \n",
       "3330           0.407767               0.813864             -0.319876   \n",
       "3331           1.412145               1.485591             -0.162333   \n",
       "3332           0.056235              -0.529589              0.839192   \n",
       "\n",
       "      torque_nm  tool_wear_min    H    L    M  prediction  \n",
       "0     -1.338230       0.284553  0.0  1.0  0.0           1  \n",
       "1      0.732764       0.780488  0.0  1.0  0.0           1  \n",
       "2      0.202509       0.166667  0.0  1.0  0.0           1  \n",
       "3     -0.417789       0.276423  0.0  1.0  0.0           1  \n",
       "4     -0.918029       0.036585  0.0  1.0  0.0           1  \n",
       "...         ...            ...  ...  ...  ...         ...  \n",
       "3328   1.963354       0.699187  0.0  1.0  0.0           1  \n",
       "3329   1.192985       0.369919  0.0  1.0  0.0           1  \n",
       "3330  -0.157664       0.735772  0.0  1.0  0.0           1  \n",
       "3331  -0.357760       0.211382  0.0  1.0  0.0           1  \n",
       "3332  -1.238182       0.386179  0.0  0.0  1.0           1  \n",
       "\n",
       "[3333 rows x 9 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "8fe9cacd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['prediction'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0920cf",
   "metadata": {},
   "source": [
    "# Convertendo os resultados de volta para os labels\n",
    "\n",
    "Quando fizemos o LabelEncoding da variável target, os labels tornaram-se valores numéricos. Para leitura humana, o resultado final tem mais valor sendo transformado de volta para os labels originais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "7533a414",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       No Failure\n",
       "1       No Failure\n",
       "2       No Failure\n",
       "3       No Failure\n",
       "4       No Failure\n",
       "           ...    \n",
       "3328    No Failure\n",
       "3329    No Failure\n",
       "3330    No Failure\n",
       "3331    No Failure\n",
       "3332    No Failure\n",
       "Length: 3333, dtype: object"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsoes_finais_transformadas = pd.Series(le.inverse_transform(df_final['prediction']))\n",
    "previsoes_finais_transformadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "9d63f9e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No Failure                  3178\n",
       "Random Failures               40\n",
       "Heat Dissipation Failure      38\n",
       "Tool Wear Failure             38\n",
       "Overstrain Failure            28\n",
       "Power Failure                 11\n",
       "dtype: int64"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quantidade de previsões de cada tipo\n",
    "previsoes_finais_transformadas.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9e35c8",
   "metadata": {},
   "source": [
    "# Salvando os resultados num arquivo CSV\n",
    "\n",
    "Para finalizar o trabalho, salvamos os resultados finais num arquivo CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "72c1904c",
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes_finais_transformadas = previsoes_finais_transformadas.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "88193801",
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes_finais_transformadas.to_csv(\"predicted.csv\", index = False, header=['rowNumber','predictedValues'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
